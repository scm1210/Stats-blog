{
  "hash": "76f19b421190d00f6963a623f523bd74",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Final Project: Prediciting Head to Head Pokémon Wins with Binary Logistic Regression\"\nsubtitle: \"Princeton University\"\nauthor: \"Steven Mesquiti\"\noutput: \n  tufte::tufte_html:\n    css: \n    tufte_variant: \"envisioned\"\n    highlight: github-dark\n    fig_height: 10\n    fig_width: 16\n    toc: true\n    toc_depth: 1\nexecute: \n  message: false\n  warning: false\nparams: \n    SHOW_SOLS: TRUE\n    TOGGLE: TRUE\njupyter: python3\nformat: html\nengine: knitr\ncategories: [Final-Project, code, analysis]\n---\n\n\n\n## Load packages:\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(pacman)\npacman::p_load(tidyverse, DT, broom, performance,\n               ordinal,car,ggeffects,gofact,brms,\n               emmeans,knirt,MASS,brant,\n               install = TRUE)\n\n\n#### define plot objects and stuff\n\npalette <- c(\n  \"#772e25\", \"#c44536\", \"#ee9b00\", \"#197278\", \"#283d3b\", \n  \"#9CC5A1\", \"#6195C6\", \"#ADA7C9\", \"#4D4861\", \"grey50\",\n  \"#d4a373\", \"#8a5a44\", \"#4a6a74\", \"#5c80a8\", \"#a9c5a0\",\n  \"#7b9b8e\", \"#e1b16a\", \"#a69b7c\", \"#9d94c4\", \"#665c54\"\n)\n\npalette_condition = c(\"#ee9b00\", \"#c44536\",\"#005f73\", \"#283d3b\", \"#9CC5A1\", \"#6195C6\", \"#ADA7C9\", \"#4D4861\")\n\nplot_aes = theme_minimal() +\n  theme(\n    legend.position = \"top\",\n    legend.text = element_text(size = 12),\n    text = element_text(size = 16, family = \"Futura Medium\"),\n    axis.text = element_text(color = \"black\"),\n    axis.ticks.y = element_blank(),\n    plot.title = element_text(size = 20, hjust = 0.5) # Adjusted title size and centering\n  )\n```\n:::\n\n\n\n# GPT Pipeline {.tabset}\n\n## Load Libraries and API Key\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom openai import OpenAI, RateLimitError, APIError, APITimeoutError\nimport pandas as pd \nfrom tqdm.notebook import tqdm\nfrom dotenv import load_dotenv\nimport re\nimport numpy as np\nimport json\nimport argparse\nimport random\nimport time\nimport os\nimport ast\n\nload_dotenv(\"/Users/sm9518/Desktop/Article-Summarizer/.env\") # where i keep my API key... \napi_key = os.getenv(\"OPENAI_API_KEY\")\nif api_key:\n    print(\"API Key loaded successfully!\\n:)\")\nelse:\n    raise ValueError(\"API Key not found.\\nMake sure it is set in the .env file.\")\nmodel=\"gpt-3.5-turbo\" # set model. we dont need anything fancy for this task.\ntemperature=0 # set temp to be rather determinisitic \nSEED = random.seed(42) # set seed for reproducibility\n```\n:::\n\n\n\n## Load Data and Sample\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\ndf = pd.read_csv('/Users/sm9518/Library/CloudStorage/GoogleDrive-sm9518@princeton.edu/My Drive/Classes/Stats-blog/posts/final-project/data/pokedex.csv', index_col=0)\ndf.head()\n\nOG_pokedex = df.iloc[:151].copy() # take the OG 151 pokemon\n\n# build the 20‐matchups per Pokémon\nmatchups = []\nfor challenger in OG_pokedex['name']:\n    pool = [p for p in OG_pokedex['name'] if p != challenger]\n    opponents = random.sample(pool, 20) # give them 20 challengers\n    for opponent in opponents:\n        matchups.append({'challenger': challenger, 'opponent': opponent})\nmatchups_df = pd.DataFrame(matchups)\n\n\n\n# merge challenger metadata\nmatchups_with_meta = (\n    matchups_df\n    .merge(\n        OG_pokedex.add_suffix('_challenger'),\n        left_on='challenger',\n        right_on='name_challenger',\n        how='left'\n    )\n    # drop the redundant name_challenger column if you like\n    .drop(columns=['name_challenger'])\n    # merge opponent metadata\n    .merge(\n        OG_pokedex.add_suffix('_opponent'),\n        left_on='opponent',\n        right_on='name_opponent',\n        how='left'\n    )\n    .drop(columns=['name_opponent'])\n)\n\n# now every row has both challenger_* and opponent_* columns\nmatchups_with_meta.head()\n```\n:::\n\n\n\n## Hit the API to Simuilate Mathcups\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# Initialize OpenAI client\nclient = OpenAI()\n# ---- Utility Functions ---- #\n\ndef safe_parse_types(val):\n    if isinstance(val, list):\n        return val\n    try:\n        return ast.literal_eval(val)\n    except Exception:\n        return [str(val)]\n\ndef format_pokemon_stats(name, row, suffix):\n    types = safe_parse_types(row[f'type{suffix}'])\n    return (\n        f\"{name.title()}:\\n\"\n        f\"- Type: {', '.join(types)}\\n\"\n        f\"- HP: {row[f'hp{suffix}']}\\n\"\n        f\"- Attack: {row[f'attack{suffix}']}\\n\"\n        f\"- Defense: {row[f'defense{suffix}']}\\n\"\n        f\"- Special Attack: {row[f's_attack{suffix}']}\\n\"\n        f\"- Special Defense: {row[f's_defense{suffix}']}\\n\"\n        f\"- Speed: {row[f'speed{suffix}']}\\n\"\n    )\n\n# ---- API Interaction ---- #\n\ndef get_completion(prompt):\n    messages = [{\"role\": \"user\", \"content\": prompt}]\n    response = client.chat.completions.create(\n        model=model,\n        messages=messages,\n        temperature=temperature\n    )\n    return response.choices[0].message.content.strip()\n\ndef get_response(prompt):\n    try:\n        return get_completion(prompt)\n    except RateLimitError as e:\n        retry_time = getattr(e, 'retry_after', 30)\n        print(f\"Rate limit exceeded. Retrying in {retry_time} seconds...\")\n        time.sleep(retry_time)\n        return get_response(prompt)\n    except APIError as e:\n        print(f\"API error occurred: {e}. Retrying in 30 seconds...\")\n        time.sleep(30)\n        return get_response(prompt)\n    except APITimeoutError as e:\n        print(f\"Request timed out: {e}. Retrying in 10 seconds...\")\n        time.sleep(10)\n        return get_response(prompt)\n    except Exception as e:\n        print(f\"Unexpected error: {e}. Retrying in 10 seconds...\")\n        time.sleep(10)\n        return get_response(prompt)\n\n# ---- Simulate One Battle ---- #\n\ndef simulate_battle(row):\n    p1_stats = format_pokemon_stats(row['challenger'], row, '_challenger')\n    p2_stats = format_pokemon_stats(row['opponent'], row, '_opponent')\n\n    prompt = (\n        \"Based on the stats, which Pokémon would win a one-on-one battle?\\n\\n\"\n        f\"{p1_stats}\\nVS\\n\\n{p2_stats}\\n\\n\"\n        \"Only respond with the name of the winning Pokémon.\"\n    )\n\n    response = get_response(prompt)\n    return response.lower()\n\n# ---- Run All Simulations ---- #\n\n# This should be your DataFrame containing all matchups\n# matchups_with_meta = pd.read_csv(...)  # Load your data here\n\nresults = []\n\nfor idx, row in tqdm(matchups_with_meta.iterrows(), total=len(matchups_with_meta), desc=\"Simulating battles\"):\n    print(f\"Simulating battle {idx + 1} of {len(matchups_with_meta)}: {row['challenger']} vs {row['opponent']}\")\n    winner = simulate_battle(row)\n    results.append({\n        \"challenger\": row['challenger'],\n        \"opponent\": row['opponent'],\n        \"winner\": winner\n    })\n    time.sleep(1.5)  # Respect rate limits\n\n# ---- Save Results ---- #\n\nresults_df = pd.DataFrame(results)\nmatchups_with_results = matchups_with_meta.merge(\n    results_df,\n    on=[\"challenger\", \"opponent\"],\n    how=\"left\"\n)\nmatchups_with_results.head()\nmatchups_with_results.to_csv(f\"/Users/sm9518/Library/CloudStorage/GoogleDrive-sm9518@princeton.edu/My Drive/Classes/Stats-blog/posts/final-project/data/pokemon_battle_results_{model}_{SEED}_{temperature}.csv\", index=False)\nprint(f\"\\nDone! Winners saved to pokemon_battle_results_{model}_{SEED}_{temperature}.csv.\")\n```\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}