{
  "hash": "e36c7b12d6d402fae5d77a6b94431060",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Missing Data\"\nsubtitle: \"Psy-504\"\nauthor: \n  - Steven Mesquiti\ninstitute: \"Princeton University\"\ndate: today\nformat: \n  revealjs:\n    theme: [default, styles.scss]\n    highlight-style: github-dark\n    toc: true\n    toc-depth: 1\n    slide-number: true\n    fig-width: 8\n    fig-height: 5\n    transition: slide\ncategories: [Lab, code, analysis, missing-data]\nexecute:\n  message: false\n  warning: false\nparams:\n  SHOW_SOLS: true\n  TOGGLE: true\n---\n\n\n\n\n\n\n\n## Overview\n\n-   Importance of addressing missing data in research\\\n-   Traditional vs. modern methods\\\n-   Focus on:\n    -   Maximum Likelihood (ML)\\\n    -   Multiple Imputation (MI)\\\n-   Benefits of modern methods\\\n-   Demo using a toy dataset\n\n::: notes\nHi! Today im going to be talking to you today about missing data.\\\nMissing data is a common problem in research, and it can have a significant impact on the validity of your results.\\\nIn this presentation, I will discuss the importance of addressing missing data, traditional methods for handling it, and modern techniques like Maximum Likelihood and Multiple Imputation.\\\nI will also attempt to provide a demo using a toy dataset to illustrate these concepts.\\\n\nLet's get started\n:::\n\n------------------------------------------------------------------------\n\n## The Problem of Missing Data {.scrollable}\n\n-   Missing data is common in quantitative research\n-   Traditional methods (e.g., deletion, mean imputation) are often inadequate\n    -   Biased estimates\n    -   Reduced statistical power\n\n::: {style=\"text-align: center;\"}\n![](https://media2.giphy.com/media/v1.Y2lkPTc5MGI3NjExbTA0Ynp6Z21tcm5ubTBudzVzOGNsdnl2bHM0NnJjeXhoZnE5YnF2eiZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/ImHfnm01jqvostvlLP/giphy.gif)\n:::\n\n::: notes\nMissing data are ubiquitous in quantitative research studies.\\\nBecause of its pervasive nature, some methodologists have described missing data as “one of the most important statistical and design problems in research” (methodologist William Shadish, quoted in Azar, 2002, p. 70).\n:::\n\n------------------------------------------------------------------------\n\n## Different `Types` of Missing Data {.scrollable}\n\n-   **Missing Completely at Random (MCAR)**: Missingness is unrelated to observed or unobserved data\n-   **Missing at Random (MAR)**: Missingness is related to observed data but not unobserved data\n-   **Missing Not at Random (MNAR)**: Missingness is related to unobserved data\n\n![](images/missing-data-explanation.png){fig-align=\"center\" width=\"1200\"}\n\n::: notes\nMCAR (Missing Completely at Random):\n- Missingness unrelated to any data.\n- E.g., a student moves districts for unrelated reasons.\n- Analyses remain unbiased—but true MCAR is rare.\n\nMAR (Missing at Random):\n- Missingness depends only on other observed variables.\n- E.g., students who use substances more often skip school—and thus a self‑esteem survey.\n- Can be handled well with multiple imputation or maximum likelihood.\n\nMNAR (Missing Not at Random):\n- Missingness depends on the unobserved value itself.\n- E.g., poor readers skip hard test items because they can’t answer them.\n- Statistically challenging, since the missingness conveys hidden information.\n:::\n\n------------------------------------------------------------------------\n\n## Building and deploying example {.scrollable}\n\n::: panel-tabset\n### Create `Toy` Dataset\n\nFirst, let's create our toy dataset\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(42)\nn <- 1000  # Number of observations\ntoy <- data.frame(\n  x = rnorm(n, mean = 0, sd = 5),  \n  y = rnorm(n, mean = 0, sd = 7),  \n  z = sample(0:3, n, replace = TRUE)\n)\n\n# Introduce missingness in `y`\ntoy$y[sample(1:n, 300)] <- NA  # 300 missing values randomly assigned to `y`\n```\n:::\n\n\n\n### Visualize Missing Data\n\n-   visualize with `gg_miss_var` from the `naniar` package\n-   as you can see we have missing data in the `y` variable\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](Missing_data/fig_unnamed-chunk-3-1.png){fig-align='center' width=768}\n:::\n:::\n\n\n:::\n\n::: notes\nFirst, we'll create our synthetic dataset using hte code provided.\\\nThe dataset contains three variables: `x`, `y`, and `z` where `y` has \\~300 missing values.\\\n\nWhat are some ways in which we can deal with them?\n:::\n\n------------------------------------------------------------------------\n\n## Traditional Missing Data Techniques\n\n-   **Listwise Deletion**: Drops any *row* with NA (e.g., `na.rm = T`)\\\n-   **Mean Imputation**: Replaces missing values with the mean value\\\n-   These are easy to use, but often leads to **biased** results, let's see why\n\n::: notes\nTraditionally, people use things like listwise deletion or mean imputation to deal with missing data.\\\nBut this can create problems because it'll reduce power (if you remove observations from your dataset) and can also introduce bias (if you replace missing values with the mean). Let's see how we'd implement this in R\n:::\n\n------------------------------------------------------------------------\n\n## How to implement Mean Imputation {.scrollable}\n\n-   Here, we are asking R to impute the mean of `y` and replace any missing values with that mean\\\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Mean imputation\ntoy$y_mean <- ifelse(is.na(toy$y), mean(toy$y, na.rm = TRUE), toy$y)\n```\n:::\n\n\n\n------------------------------------------------------------------------\n\n## Visualizing Mean Imputation {.scrollable}\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](Missing_data/fig_unnamed-chunk-5-1.png){fig-align='center' width=768}\n:::\n:::\n\n\n\n::: notes\n-   Visualize the original data and the imputed data to compare the distributions\n-   Notice the thick line at the mean\n:::\n\n------------------------------------------------------------------------\n\n## How does this influence downstream processes? {.scrollable}\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](Missing_data/fig_unnamed-chunk-6-1.png){fig-align='center' width=768}\n:::\n:::\n\n\n\n::: notes\n-   Now, let's see how this affects our regression model.\n-   The difference seems neligible (at least with working with big data) but the mean imputation is biased\n-   In smaller datasets mean imputation can have larger downstream consequences\n:::\n\n------------------------------------------------------------------------\n\n## Modern Method: Multiple Imputation (MI)\n\n-   Imputes multiple plausible values\\\n-   Models missingness using relationships among variables\\\n-   Pools results for accurate estimates and standard errors\\\n-   More robust than traditional methods\n\n------------------------------------------------------------------------\n\n## Multiple Imputation with `MICE` Package {.scrollable}\n\n::: notes\nMice stands for Multiple Imputation with Chained Equations\n:::\n\n::: panel-tabset\n## Code\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Multiple imputation\nimp <- mice(toy[, c(\"x\", \"y\", \"z\")], m = 5, method = \"pmm\", seed = 42,printFlag = F)\nfit_mi <- with(imp, lm(y ~ x + z))\npooled_summary = summary(pool(fit_mi))\n\npooled_summary |> \n  as.data.frame() |>\n  mutate_if(is.numeric, round, 3)  |> \n  DT::datatable(options = list(pageLength = 10, autoWidth = TRUE), \n                rownames = FALSE)\n```\n\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"datatables html-widget html-fill-item\" id=\"htmlwidget-289f59430a0724b372cb\" style=\"width:100%;height:auto;\"></div>\n<script type=\"application/json\" data-for=\"htmlwidget-289f59430a0724b372cb\">{\"x\":{\"filter\":\"none\",\"vertical\":false,\"data\":[[\"(Intercept)\",\"x\",\"z\"],[-0.002,0.059,-0.019],[0.655,0.045,0.297],[-0.003,1.317,-0.063],[8.154,286.893,10.993],[0.998,0.189,0.951]],\"container\":\"<table class=\\\"display\\\">\\n  <thead>\\n    <tr>\\n      <th>term<\\/th>\\n      <th>estimate<\\/th>\\n      <th>std.error<\\/th>\\n      <th>statistic<\\/th>\\n      <th>df<\\/th>\\n      <th>p.value<\\/th>\\n    <\\/tr>\\n  <\\/thead>\\n<\\/table>\",\"options\":{\"pageLength\":10,\"autoWidth\":true,\"columnDefs\":[{\"className\":\"dt-right\",\"targets\":[1,2,3,4,5]},{\"name\":\"term\",\"targets\":0},{\"name\":\"estimate\",\"targets\":1},{\"name\":\"std.error\",\"targets\":2},{\"name\":\"statistic\",\"targets\":3},{\"name\":\"df\",\"targets\":4},{\"name\":\"p.value\",\"targets\":5}],\"order\":[],\"orderClasses\":false},\"selection\":{\"mode\":\"multiple\",\"selected\":null,\"target\":\"row\",\"selectable\":null}},\"evals\":[],\"jsHooks\":[]}</script>\n```\n\n:::\n:::\n\n\n\n## Explanation\n\n**What is this code doing?**\n\n-   Step 1: Use the `mice()` function to create 5 imputed datasets for the variables x, y, and z\n-   Step 2: Fit a linear model (y \\~ x + z) on each imputed dataset using x`with()`.\n-   Step 3: Combine the results across all models using `pool()` to account for variability between imputations\n:::\n\n------------------------------------------------------------------------\n\n## Plotting Imputed Datasets produced from MICE\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](Missing_data/fig_unnamed-chunk-8-1.png){fig-align='center' width=768}\n:::\n:::\n\n\n\n------------------------------------------------------------------------\n\n## Modern Method: Maximum Likelihood (ML) {.scrollable}\n\n-   MLE doesn't fill in missing values.\n\n-   Instead, it finds the parameter values (e.g., mean, regression coefficients) that make the observed data most probable.\n\n-   Based on the log likelihood function – it chooses parameters that minimize the distance between the model and the data.\n\n**Requires:**\n\n-   Assumes MAR\n\n-   Assumes multivariate normality\n\n-   The under the hood math\n\n$$\n\\begin{align}\n\\log L &= \\sum_{i=1}^{N} \\log \\left( \\frac{1}{\\sqrt{2\\pi \\sigma^2}} \\exp\\left( -\\frac{1}{2} \\left( \\frac{y_i - \\mu}{\\sigma} \\right)^2 \\right) \\right)\n\\end{align}\n$$\n\n::: notes\nAssumes multivariate normality and MAR like multiple imputation, but instead of imputing missing values, MLE identifies the parameter values that maximize the log‑likelihood across all available data—complete and incomplete. Conceptually akin to OLS’s minimization of residuals, it uses the log‑likelihood function to select the parameters most likely to have generated the observed sample.\n\nMLE asks, “Which parameter values would make the data we actually observed most probable?”—using whatever data we have, without guessing missing entries.\n:::\n\n------------------------------------------------------------------------\n\n## Using Auxiliary Variables\n\n-   Auxiliary variables can help improve imputation\\\n-   These are variables that are not of primary interest but can help explain the missingness\\\n-   Improves imputation quality and reduces bias\n\n------------------------------------------------------------------------\n\n## Implementation Example {.scrollable}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Add auxiliary variable\ntoy$aux <- toy$x + rnorm(n)\ntoy$y[sample(1:n, 300)] <- NA  # More missingness\n\nimp_aux <- mice(toy[, c(\"x\", \"y\", \"z\", \"aux\")], m = 5, method = \"pmm\", seed = 42,printFlag = F)\nfit_aux <- with(imp_aux, lm(y ~ x + z + aux))\npooled_summary = summary(pool(fit_aux))\npooled_summary |> \n  as.data.frame() |>\n  mutate_if(is.numeric, round, 3)  |> \n  DT::datatable(options = list(pageLength = 10, autoWidth = TRUE), \n                rownames = FALSE)\n```\n\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"datatables html-widget html-fill-item\" id=\"htmlwidget-0db599c720acae7dee6d\" style=\"width:100%;height:auto;\"></div>\n<script type=\"application/json\" data-for=\"htmlwidget-0db599c720acae7dee6d\">{\"x\":{\"filter\":\"none\",\"vertical\":false,\"data\":[[\"(Intercept)\",\"x\",\"z\",\"aux\"],[-0.036,0.222,0.049,-0.221],[0.385,0.234,0.199,0.225],[-0.095,0.95,0.249,-0.985],[114.422,68.312,128.582,87.264],[0.925,0.346,0.804,0.327]],\"container\":\"<table class=\\\"display\\\">\\n  <thead>\\n    <tr>\\n      <th>term<\\/th>\\n      <th>estimate<\\/th>\\n      <th>std.error<\\/th>\\n      <th>statistic<\\/th>\\n      <th>df<\\/th>\\n      <th>p.value<\\/th>\\n    <\\/tr>\\n  <\\/thead>\\n<\\/table>\",\"options\":{\"pageLength\":10,\"autoWidth\":true,\"columnDefs\":[{\"className\":\"dt-right\",\"targets\":[1,2,3,4,5]},{\"name\":\"term\",\"targets\":0},{\"name\":\"estimate\",\"targets\":1},{\"name\":\"std.error\",\"targets\":2},{\"name\":\"statistic\",\"targets\":3},{\"name\":\"df\",\"targets\":4},{\"name\":\"p.value\",\"targets\":5}],\"order\":[],\"orderClasses\":false},\"selection\":{\"mode\":\"multiple\",\"selected\":null,\"target\":\"row\",\"selectable\":null}},\"evals\":[],\"jsHooks\":[]}</script>\n```\n\n:::\n:::\n\n\n\n## Plotting Imputed Datasets produced from MICE with auxiliary variable\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](Missing_data/fig_unnamed-chunk-10-1.png){fig-align='center' width=768}\n:::\n:::\n\n\n\n::: notes\nHere we are testing whether adding the auxiliary variable aux improves your model's estimation of y, especially given the extra missingness. Including helpful predictors like aux can improve the quality of imputations and regression estimates. To do that we compare stuff like fit stats between the two models to see which produces the better fit.\n:::\n\n------------------------------------------------------------------------\n\n## Summary of Key Takeaways\n\n| Method          | Bias    | Variability | Ease of Use     |\n|-----------------|---------|-------------|-----------------|\n| Listwise        | ❌ High | ❌ Reduced  | ✅ Easy         |\n| Mean Imputation | ❌ High | ❌ Too Low  | ✅ Easy         |\n| ML              | ✅ Low  | ✅ Accurate | ⚠ Intermediate  |\n| MI              | ✅ Low  | ✅ Accurate | ⚠️ Intermediate |\n\n------------------------------------------------------------------------\n\n## Conclusion\n\n-   Traditional methods can lead to biased results\\\n-   Modern techniques (ML, MI) use all available data\\\n-   Better estimates, standard errors, and power\\\n-   Use tools like `mice` and `naniar` for effective handling of missing data\n\n------------------------------------------------------------------------\n\n## Package Citations\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n  - Grolemund G, Wickham H (2011). \"Dates and Times Made Easy with lubridate.\" _Journal of Statistical Software_, *40*(3), 1-25. <https://www.jstatsoft.org/v40/i03/>.\n  - Müller K, Wickham H (2023). _tibble: Simple Data Frames_. R package version 3.2.1, <https://CRAN.R-project.org/package=tibble>.\n  - Pedersen T (2024). _patchwork: The Composer of Plots_. R package version 1.3.0, <https://CRAN.R-project.org/package=patchwork>.\n  - R Core Team (2024). _R: A Language and Environment for Statistical Computing_. R Foundation for Statistical Computing, Vienna, Austria. <https://www.R-project.org/>.\n  - Rinker TW, Kurkiewicz D (2018). _pacman: Package Management for R_. version 0.5.0, <http://github.com/trinker/pacman>.\n  - Tiedemann F (2022). _gghalves: Compose Half-Half Plots Using Your Favourite Geoms_. R package version 0.1.4, <https://CRAN.R-project.org/package=gghalves>.\n  - Tierney N, Cook D (2023). \"Expanding Tidy Data Principles to Facilitate Missing Data Exploration, Visualization and Assessment of Imputations.\" _Journal of Statistical Software_, *105*(7), 1-31. doi:10.18637/jss.v105.i07 <https://doi.org/10.18637/jss.v105.i07>.\n  - van Buuren S, Groothuis-Oudshoorn K (2011). \"mice: Multivariate Imputation by Chained Equations in R.\" _Journal of Statistical Software_, *45*(3), 1-67. doi:10.18637/jss.v045.i03 <https://doi.org/10.18637/jss.v045.i03>.\n  - Wickham H (2016). _ggplot2: Elegant Graphics for Data Analysis_. Springer-Verlag New York. ISBN 978-3-319-24277-4, <https://ggplot2.tidyverse.org>.\n  - Wickham H (2023). _forcats: Tools for Working with Categorical Variables (Factors)_. R package version 1.0.0, <https://CRAN.R-project.org/package=forcats>.\n  - Wickham H (2023). _stringr: Simple, Consistent Wrappers for Common String Operations_. R package version 1.5.1, <https://CRAN.R-project.org/package=stringr>.\n  - Wickham H, Averick M, Bryan J, Chang W, McGowan LD, François R, Grolemund G, Hayes A, Henry L, Hester J, Kuhn M, Pedersen TL, Miller E, Bache SM, Müller K, Ooms J, Robinson D, Seidel DP, Spinu V, Takahashi K, Vaughan D, Wilke C, Woo K, Yutani H (2019). \"Welcome to the tidyverse.\" _Journal of Open Source Software_, *4*(43), 1686. doi:10.21105/joss.01686 <https://doi.org/10.21105/joss.01686>.\n  - Wickham H, Bryan J, Barrett M, Teucher A (2024). _usethis: Automate Package and Project Setup_. R package version 3.0.0, <https://CRAN.R-project.org/package=usethis>.\n  - Wickham H, François R, Henry L, Müller K, Vaughan D (2023). _dplyr: A Grammar of Data Manipulation_. R package version 1.1.4, <https://CRAN.R-project.org/package=dplyr>.\n  - Wickham H, Henry L (2025). _purrr: Functional Programming Tools_. R package version 1.0.4, <https://CRAN.R-project.org/package=purrr>.\n  - Wickham H, Hester J, Bryan J (2024). _readr: Read Rectangular Text Data_. R package version 2.1.5, <https://CRAN.R-project.org/package=readr>.\n  - Wickham H, Hester J, Chang W, Bryan J (2022). _devtools: Tools to Make Developing R Packages Easier_. R package version 2.4.5, <https://CRAN.R-project.org/package=devtools>.\n  - Wickham H, Vaughan D, Girlich M (2024). _tidyr: Tidy Messy Data_. R package version 1.3.1, <https://CRAN.R-project.org/package=tidyr>.\n```\n\n\n:::\n:::\n\n\n\n## Thanks for listening!\n\n::: {style=\"text-align: center;\"}\n![](https://media0.giphy.com/media/v1.Y2lkPTc5MGI3NjExNnN5MTBlOTkzMXBidmR2cHJ5dW1hdThhY2kydWJraXo0eTE3bDYxYiZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/3oz8xHEisOJuebgmhq/giphy.gif)\n:::\n\n------------------------------------------------------------------------\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../../site_libs/htmltools-fill-0.5.8.1/fill.css\" rel=\"stylesheet\" />\n<script src=\"../../site_libs/htmlwidgets-1.6.4/htmlwidgets.js\"></script>\n<link href=\"../../site_libs/datatables-css-0.0.0/datatables-crosstalk.css\" rel=\"stylesheet\" />\n<script src=\"../../site_libs/datatables-binding-0.33/datatables.js\"></script>\n<script src=\"../../site_libs/jquery-3.6.0/jquery-3.6.0.min.js\"></script>\n<link href=\"../../site_libs/dt-core-1.13.6/css/jquery.dataTables.min.css\" rel=\"stylesheet\" />\n<link href=\"../../site_libs/dt-core-1.13.6/css/jquery.dataTables.extra.css\" rel=\"stylesheet\" />\n<script src=\"../../site_libs/dt-core-1.13.6/js/jquery.dataTables.min.js\"></script>\n<link href=\"../../site_libs/crosstalk-1.2.1/css/crosstalk.min.css\" rel=\"stylesheet\" />\n<script src=\"../../site_libs/crosstalk-1.2.1/js/crosstalk.min.js\"></script>\n"
      ],
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}