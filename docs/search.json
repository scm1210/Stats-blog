[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Hi!\nMy name is Steven Mesquiti! I‚Äôm a first-year in the Department of Psychology at Princeton University advised by Erik Nook.\nI study how we can use Natural Language Processing techniques and Artifical Intelligence to explain, predict, and improve people‚Äôs Mental Health.\nBefore Princeton, I worked as a Lab Manager for Emily Falk in the Communication Neuroscience Lab at the Univeristy of Pennsylvania. Along the way, I have worked with excessively generous scientists like Jamie Pennebaker, Lyle Ungar, & Angela Duckworth pursing questions at the nexus of Computer Science, Computational Linguistics, and Psychology\nThis is my blog for PSY-504. You can find various assignments that I complete on this website."
  },
  {
    "objectID": "posts/Lab-3/ord_lab_q.html",
    "href": "posts/Lab-3/ord_lab_q.html",
    "title": "Ordinal Regression Lab Answers",
    "section": "",
    "text": "If you are fitting a model, display the model output in a neatly formatted table. (The tidy and kable functions can help!)\nIf you are creating a plot, use clear labels for all axes, titles, etc.\nIf you are using Github, don‚Äôt forget to commit and push your work to to it regularly, at least after each exercise. Write short and informative commit messages. Else, if you are submitting on Canvas, make sure that the version you submit is the latest, and that it runs/knits without any errors.\nWhen you‚Äôre done, we should be able to knit the final version of the QMD in your GitHub as a HTML."
  },
  {
    "objectID": "posts/Lab-3/ord_lab_q.html#instructions",
    "href": "posts/Lab-3/ord_lab_q.html#instructions",
    "title": "Ordinal Regression Lab Answers",
    "section": "",
    "text": "If you are fitting a model, display the model output in a neatly formatted table. (The tidy and kable functions can help!)\nIf you are creating a plot, use clear labels for all axes, titles, etc.\nIf you are using Github, don‚Äôt forget to commit and push your work to to it regularly, at least after each exercise. Write short and informative commit messages. Else, if you are submitting on Canvas, make sure that the version you submit is the latest, and that it runs/knits without any errors.\nWhen you‚Äôre done, we should be able to knit the final version of the QMD in your GitHub as a HTML."
  },
  {
    "objectID": "posts/Lab-3/ord_lab_q.html#load-packages",
    "href": "posts/Lab-3/ord_lab_q.html#load-packages",
    "title": "Ordinal Regression Lab Answers",
    "section": "Load packages:",
    "text": "Load packages:\n\nlibrary(pacman)\npacman::p_load(tidyverse, DT, broom, performance,\n               ordinal,car,ggeffects,gofact,brms,\n               emmeans,knirt,MASS,brant,\n               install = TRUE)\n\n\n#### define plot objects and stuff\n\npalette &lt;- c(\n  \"#772e25\", \"#c44536\", \"#ee9b00\", \"#197278\", \"#283d3b\", \n  \"#9CC5A1\", \"#6195C6\", \"#ADA7C9\", \"#4D4861\", \"grey50\",\n  \"#d4a373\", \"#8a5a44\", \"#4a6a74\", \"#5c80a8\", \"#a9c5a0\",\n  \"#7b9b8e\", \"#e1b16a\", \"#a69b7c\", \"#9d94c4\", \"#665c54\"\n)\n\npalette_condition = c(\"#ee9b00\", \"#c44536\",\"#005f73\", \"#283d3b\", \"#9CC5A1\", \"#6195C6\", \"#ADA7C9\", \"#4D4861\")\n\nplot_aes = theme_minimal() +\n  theme(\n    legend.position = \"top\",\n    legend.text = element_text(size = 12),\n    text = element_text(size = 16, family = \"Futura Medium\"),\n    axis.text = element_text(color = \"black\"),\n    axis.ticks.y = element_blank(),\n    plot.title = element_text(size = 20, hjust = 0.5) # Adjusted title size and centering\n  )"
  },
  {
    "objectID": "posts/Lab-3/ord_lab_q.html#load-data",
    "href": "posts/Lab-3/ord_lab_q.html#load-data",
    "title": "Ordinal Regression Lab Answers",
    "section": "Load data",
    "text": "Load data\n\nMake sure only the top 3 ranks are being used. For some reason, there are missing ranks (my guess is they did not announce rank on TV)\n\n\ngbbo &lt;- read_csv(\"https://raw.githubusercontent.com/suyoghc/PSY-504_Spring-2025/refs/heads/main/Ordinal%20Regression/data/GBBO.csv\")\n\n# Enter code to filter. Think about the data type that would be relevant for Rank\n# gb &lt;- ....\n\n### only use the the first three ranks \ndata = gbbo |&gt; \n  rename(Technical_Rank = `Technical Rank`) |&gt; \n  filter(Technical_Rank &lt; 4) |&gt; \n  mutate(Technical_Rank = factor(Technical_Rank, levels = c(1, 2, 3), ordered = TRUE),\n         Gender = factor(Gender))"
  },
  {
    "objectID": "posts/Lab-3/ord_lab_q.html#explore",
    "href": "posts/Lab-3/ord_lab_q.html#explore",
    "title": "Ordinal Regression Lab Answers",
    "section": "Explore",
    "text": "Explore\n\nPlot two figures showing the percentage of bakers in each rank‚Äî create one for Gender and Age\n\n\ngb &lt;- data %&gt;% \n  mutate(AgeGroup = cut(Age, \n                        breaks = seq(floor(min(Age, na.rm = TRUE)), ceiling(max(Age, na.rm = TRUE)), by = 10),\n                        include.lowest = TRUE, right = FALSE))\n\n# Compute percentages by Age Group\nage_rank &lt;- gb %&gt;%\n  group_by(AgeGroup, `Technical_Rank`) %&gt;%\n  summarise(n = n(), .groups = 'drop') %&gt;%\n  mutate(perc = n / sum(n) * 100)\n\n# Compute percentages by Gender\ngender_rank &lt;- gb %&gt;%\n  group_by(Gender, `Technical_Rank`) %&gt;%\n  summarise(n = n(), .groups = 'drop') %&gt;%\n  mutate(perc = n / sum(n) * 100)\n\n# Plot for Age Group\nggplot(age_rank, aes(x = AgeGroup, y = perc, fill = factor(`Technical_Rank`))) +\n  geom_bar(stat = \"identity\", position = position_dodge(width = 0.8)) +\n  scale_y_continuous(labels = scales::percent_format(scale = 1)) +\n  scale_fill_manual(values = palette_condition) +\n  labs(title = \"Percentage of Bakers in Each Technical Rank by Age Group\",\n       x = \"Age Group\",\n       y = \"Percentage\",\n       fill = \"Technical Rank\") +\n  plot_aes +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n# Plot for Gender\nggplot(gender_rank, aes(x = Gender, y = perc, fill = factor(`Technical_Rank`))) +\n  geom_bar(stat = \"identity\", position = position_dodge(width = 0.8)) +\n  scale_y_continuous(labels = scales::percent_format(scale = 1)) +\n  scale_fill_manual(values = palette_condition) +\n  labs(title = \"Percentage of Bakers in Each Technical Rank by Gender\",\n       x = \"Gender\",\n       y = \"Percentage\",\n       fill = \"Technical Rank\") +\n  plot_aes"
  },
  {
    "objectID": "posts/Lab-3/ord_lab_q.html#ordinal-analysis",
    "href": "posts/Lab-3/ord_lab_q.html#ordinal-analysis",
    "title": "Ordinal Regression Lab Answers",
    "section": "Ordinal Analysis",
    "text": "Ordinal Analysis\n\nIf you haven‚Äôt already, convert the outcome variable to an ordered factor. What does the order here represent?\n\ndata = gbbo |&gt; \n  rename(Technical_Rank = `Technical Rank`) |&gt; \n  filter(Technical_Rank &lt; 4) |&gt; \n  mutate(Technical_Rank = factor(Technical_Rank, levels = c(1, 2, 3), ordered = TRUE),\n  Gender = factor(Gender)) \n\n\nThe order represents their placement in a technical bake-off.\n\n\nConvert input variables to categorical factors as appropriate.\n\n# Factorizing gender\nGender = factor(Gender)\n\nRun a ordinal logistic regression model against all relevant input variables. Interpret the effects for Gender, Age and Gender*Age (even if they are non-significant).\n\n\n# Fit the ordinal logistic regression model\nmodel &lt;- clm(`Technical_Rank` ~ Gender * Age, data = gb)\n\n# Extract results with 95% confidence intervals\nresults &lt;- tidy(model, conf.int = TRUE) %&gt;%\n  rename(Estimate = estimate, `Lower CI` = conf.low, `Upper CI` = conf.high) %&gt;%\n  mutate(\n    Estimate = round(Estimate, 3),\n    `Lower CI` = round(`Lower CI`, 3),\n    `Upper CI` = round(`Upper CI`, 3),\n    p.value = round(2 * (1 - pnorm(abs(statistic))), 3)  # Compute p-values manually and round\n  )\n\n# Display results in an interactive DT table\ndatatable(results, \n          options = list(pageLength = 5, scrollX = TRUE),\n          caption = \"Ordinal Logistic Regression Results with 95% Confidence Intervals\")\n\n\n\n\nsummary(model)\n\nformula: Technical_Rank ~ Gender * Age\ndata:    gb\n\n link  threshold nobs logLik  AIC    niter max.grad cond.H \n logit flexible  309  -336.64 683.28 3(0)  4.04e-08 1.1e+05\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)  \nGenderM     -1.14947    0.67290  -1.708   0.0876 .\nAge         -0.02311    0.01246  -1.855   0.0636 .\nGenderM:Age  0.03879    0.01853   2.093   0.0363 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nThreshold coefficients:\n     Estimate Std. Error z value\n1|2 -1.416692   0.459602  -3.082\n2|3  0.004944   0.452043   0.011\n\n\n\nTest if the interaction is warranted\n\n#Hint: You need to create two models with clm(); one with interaction and one without. #Then you compare them using the anova test using anova()\n::: {.cell}\n\n```{.r .cell-code}\nmodel_interaction &lt;- clm(`Technical_Rank` ~ Gender * Age, data = gb)\n\n# Fit the model without the interaction term\nmodel_main &lt;- clm(`Technical_Rank` ~ Gender + Age, data = gb)\n\n# Compare the two models using ANOVA\nanova_results &lt;- anova(model_main, model_interaction)\nanova_results\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLikelihood ratio tests of cumulative link models:\n \n                  formula:                      link: threshold:\nmodel_main        Technical_Rank ~ Gender + Age logit flexible  \nmodel_interaction Technical_Rank ~ Gender * Age logit flexible  \n\n                  no.par    AIC  logLik LR.stat df Pr(&gt;Chisq)  \nmodel_main             4 685.72 -338.86                        \nmodel_interaction      5 683.28 -336.64   4.437  1    0.03517 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\nwe should use the interaction term since th emodel has significantly better fit\n\n\nUse ggemmeans to create a figure showing the interaction between Gender and Age as a function of rank. Plot predicted probabilities from the model.\n\n\npreds &lt;- ggemmeans(model_interaction, terms = c(\"Age\", \"Gender\"), type = \"fixed\")\n\nggplot(preds, aes(x = x, y = predicted, color = group, fill = group)) +\n  geom_line(size = 1) +  \n  geom_ribbon(aes(ymin = conf.low, ymax = conf.high), alpha = 0.2, linetype = \"dashed\") +  \n  facet_wrap(~response.level, scales = \"free_y\") +  \n  labs(title = \"Predicted Probability of Technical Rank by Age and Gender\",\n       x = \"Age\",\n       y = \"Predicted Probability\",\n       color = \"Gender\",\n       fill = \"Gender\") +  \n  scale_color_manual(values = palette) +  \n  scale_fill_manual(values = palette) +  \n  plot_aes\n\n\n\n\n\n\n\n\n\nLatent Visualization\n\nols_clm = MASS::polr(Technical_Rank~Gender*Age, data=gb)\n\nggeffect(ols_clm, c(\"Age[all]\", \"Gender\"), latent=TRUE) %&gt;% plot() +  scale_color_manual(values = palette) +  \n  scale_fill_manual(values = palette) +  plot_aes \n\n\n\n\n\n\n\n\n\nUse the Brant test to support or reject the hypothesis that the proportional odds assumption holds for your simplified model.\n\n\nbrant(ols_clm)\n\n-------------------------------------------- \nTest for    X2  df  probability \n-------------------------------------------- \nOmnibus     1.29    3   0.73\nGenderM     0.58    1   0.44\nAge     0.06    1   0.8\nGenderM:Age 0.92    1   0.34\n-------------------------------------------- \n\nH0: Parallel Regression Assumption holds\n\n\n\nWe fail to rejecet it proportional odds assumption holds"
  },
  {
    "objectID": "posts/Lab-3/ord_lab_q.html#brms",
    "href": "posts/Lab-3/ord_lab_q.html#brms",
    "title": "Ordinal Regression Lab Answers",
    "section": "brms",
    "text": "brms\n\nBelow is a model implementation using the brms package. We will just use the default priors for this. The exercise is to run this code and note your observations. What are salient differences you observe in how the model fitting takes place With respect to the results, how do you compare the results of the model you fit with clm and the one you fit with brms?\n\n\nmodel_path &lt;- file.path(\"/Users/sm9518/Library/CloudStorage/GoogleDrive-sm9518@princeton.edu/My Drive/Classes/PSY-504/stevens-blog/posts/Lab-3/models/brms_model.rds\")\n\nif (!file.exists(model_path)) {\n  # If the RDS file does not exist, create the model\n  ols2_brm &lt;- brm(Technical_Rank ~ Gender * Age, data = gb, \n                  family = cumulative, cores = 4, chains = 4)\n  \n  # Save the model output to an RDS file\n  saveRDS(ols2_brm, model_path)\n} else {\n  # If the RDS file already exists, load the data from it\n  ols2_brm &lt;- readRDS(model_path)\n}\n\n\nThe results are the same since we are using an uninformative prior and the estimates are similar to that of ML (frequentist estimations)\n\n\nThe conditional_effects function is used to plot predicted probabilities by Gender and Age across each rank.\n\n\nconditional_effects(ols2_brm, categorical = T)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncheck_predictions from the easystats performance package is used for examining model fit (i.e., does the data fit the model being used?).\n\nRun the below code. What do you think?\n\ncheck_predictions(ols2_brm) |&gt;  plot() + plot_aes\n\n\n\n\n\n\n\n\n\nYes, the model appears to fit the data"
  },
  {
    "objectID": "posts/Lab-5/poisson_lab_questions-1.html",
    "href": "posts/Lab-5/poisson_lab_questions-1.html",
    "title": "Poisson Lab Answers",
    "section": "",
    "text": "To complete this lab:\nlibrary(pacman)\npacman::p_load(MASS,tidyverse,emmeans,ggeffects,easystats,performance,knitr, naniar,skimr,install = T)\n\n\npalette &lt;- c(\n  \"#772e25\", \"#c44536\", \"#ee9b00\", \"#197278\", \"#283d3b\", \n  \"#9CC5A1\", \"#6195C6\", \"#ADA7C9\", \"#4D4861\", \"grey50\",\n  \"#d4a373\", \"#8a5a44\", \"#4a6a74\", \"#5c80a8\", \"#a9c5a0\",\n  \"#7b9b8e\", \"#e1b16a\", \"#a69b7c\", \"#9d94c4\", \"#665c54\"\n)\n\npalette_condition = c(\"#ee9b00\", \"#c44536\",\"#005f73\", \"#283d3b\", \"#9CC5A1\", \"#6195C6\", \"#ADA7C9\", \"#4D4861\")\n\nplot_aes = theme_minimal() +\n  theme(\n    legend.position = \"top\",\n    legend.text = element_text(size = 12),\n    text = element_text(size = 16, family = \"Futura Medium\"),\n    axis.text = element_text(color = \"black\"),\n    axis.ticks.y = element_blank(),\n    plot.title = element_text(size = 20, hjust = 0.5) # Adjusted title size and centering\n  )\ndata &lt;- read_delim(\"https://raw.githubusercontent.com/jgeller112/psy504-advanced-stats/main/slides/Poisson/data/2010.csv\")\n\ndata |&gt; \n  head() |&gt; \n  DT::datatable()\n### clean the data \n\ndata_pos &lt;- data %&gt;%\n  dplyr::select(wwwhr, wordsum, age, sex, reliten, polviews, wrkhome) %&gt;%\nreplace_with_na(.,\n             replace = list(wwwhr = c(-1, 998, 999),\n                          wordsum = c(-1, 99),\n                          reliten = c(0, 8, 9), \n             polviews = c(0, 8, 9), \n             wrkhome = c(0,8,9), \n             age=c(0, 98, 99)))\n\ndata_pos |&gt; \n  head() |&gt; \n  DT::datatable()\nQ: Can you explain what might be going on in the above code?\nA: The replace_with_na function is replacing zeros with NAs\nQ: The next step in data cleaning would be to ensure that the data in your code are aligned with the description/ usage context of the variables\ndata_pos &lt;- data_pos |&gt; \n  mutate(sex = factor(ifelse(sex == -1, \"Male\", \n                             ifelse(sex == 1, \"Female\", NA)), \n                      levels = c(\"Male\", \"Female\")),\n         reliten_recode = factor(reliten, levels = 1:5))"
  },
  {
    "objectID": "posts/Lab-5/poisson_lab_questions-1.html#missingness",
    "href": "posts/Lab-5/poisson_lab_questions-1.html#missingness",
    "title": "Poisson Lab Answers",
    "section": "Missingness",
    "text": "Missingness\n\ndata_pos %&gt;%\n  dplyr::select(reliten, reliten_recode)\n\n# A tibble: 2,044 √ó 2\n   reliten reliten_recode\n     &lt;dbl&gt; &lt;fct&gt;         \n 1       1 1             \n 2       4 4             \n 3       1 1             \n 4       1 1             \n 5       1 1             \n 6       4 4             \n 7       3 3             \n 8       1 1             \n 9       1 1             \n10       1 1             \n# ‚Ñπ 2,034 more rows\n\nskimr::skim(data_pos)\n\n\nData summary\n\n\nName\ndata_pos\n\n\nNumber of rows\n2044\n\n\nNumber of columns\n8\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nfactor\n2\n\n\nnumeric\n6\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\nsex\n0\n1.00\nFALSE\n2\nMal: 1153, Fem: 891\n\n\nreliten_recode\n99\n0.95\nFALSE\n4\n2: 747, 1: 707, 4: 363, 3: 128\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nwwwhr\n996\n0.51\n9.79\n13.41\n0\n2\n5\n14\n168\n‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n\n\nwordsum\n657\n0.68\n6.03\n2.07\n0\n5\n6\n7\n10\n‚ñÅ‚ñÉ‚ñá‚ñÖ‚ñÇ\n\n\nage\n3\n1.00\n47.97\n17.68\n18\n33\n47\n61\n89\n‚ñá‚ñá‚ñá‚ñÖ‚ñÉ\n\n\nreliten\n99\n0.95\n2.08\n1.08\n1\n1\n2\n3\n4\n‚ñá‚ñá‚ñÅ‚ñÇ‚ñÉ\n\n\npolviews\n71\n0.97\n4.08\n1.46\n1\n3\n4\n5\n7\n‚ñÉ‚ñÇ‚ñá‚ñÉ‚ñÖ\n\n\nwrkhome\n882\n0.57\n2.26\n1.72\n1\n1\n1\n4\n6\n‚ñá‚ñÅ‚ñÅ‚ñÇ‚ñÅ"
  },
  {
    "objectID": "posts/Lab-5/poisson_lab_questions-1.html#fit-a-poisson-model-to-the-data.",
    "href": "posts/Lab-5/poisson_lab_questions-1.html#fit-a-poisson-model-to-the-data.",
    "title": "Poisson Lab Answers",
    "section": "Fit a Poisson model to the data.",
    "text": "Fit a Poisson model to the data.\n\npoisson_model &lt;- glm(wwwhr ~ wordsum + age + sex + reliten+ polviews + wrkhome, \n                     data = data_pos, \n                     family = poisson(link = \"log\"))\n\nmodel_summary &lt;- summary(poisson_model)$coefficients\nci &lt;- confint(poisson_model)  # Compute confidence intervals\n\n# Create a tidy dataframe\neffects_table &lt;- as.data.frame(model_summary) |&gt; \n  tibble::rownames_to_column(var = \"Predictor\") |&gt; \n  dplyr::mutate(\n    `Estimate` = round(Estimate, 3),\n    `Std. Error` = round(`Std. Error`, 3),\n    `z value` = round(`z value`, 3),\n    `Pr(&gt;|z|)` = round(`Pr(&gt;|z|)`, 3),\n    `CI Lower` = round(ci[,1], 3),\n    `CI Upper` = round(ci[,2], 3)\n  )\n\n# Display the table using kable\nkable(effects_table, format = \"markdown\", caption = \"Poisson Model Coefficients\")\n\n\nPoisson Model Coefficients\n\n\n\n\n\n\n\n\n\n\n\nPredictor\nEstimate\nStd. Error\nz value\nPr(&gt;|z|)\nCI Lower\nCI Upper\n\n\n\n\n(Intercept)\n1.649\n0.082\n20.225\n0\n1.489\n1.809\n\n\nwordsum\n0.100\n0.008\n12.836\n0\n0.084\n0.115\n\n\nage\n-0.016\n0.001\n-15.132\n0\n-0.019\n-0.014\n\n\nsexFemale\n0.259\n0.026\n9.836\n0\n0.208\n0.311\n\n\nreliten\n0.199\n0.012\n16.726\n0\n0.176\n0.222\n\n\npolviews\n-0.036\n0.010\n-3.666\n0\n-0.054\n-0.017\n\n\nwrkhome\n0.078\n0.008\n10.243\n0\n0.063\n0.093"
  },
  {
    "objectID": "posts/Lab-5/poisson_lab_questions-1.html#carry-out-model-checking",
    "href": "posts/Lab-5/poisson_lab_questions-1.html#carry-out-model-checking",
    "title": "Poisson Lab Answers",
    "section": "Carry out model checking",
    "text": "Carry out model checking\nHint: performance package has the function you‚Äôre looking for\n\ncheck_model(poisson_model,plot = T)"
  },
  {
    "objectID": "posts/Lab-5/poisson_lab_questions-1.html#find-any-outliers",
    "href": "posts/Lab-5/poisson_lab_questions-1.html#find-any-outliers",
    "title": "Poisson Lab Answers",
    "section": "Find any outliers",
    "text": "Find any outliers\n\n# Filter the data to remove outliers\ndata_pos_filtered &lt;- data_pos %&gt;%\n  mutate(mean_wwwhr = mean(wwwhr, na.rm = TRUE),\n         sd_wwwhr = sd(wwwhr, na.rm = TRUE)) %&gt;%\n  filter(wwwhr &gt;= (mean_wwwhr - 3 * sd_wwwhr) & wwwhr &lt;= (mean_wwwhr + 3 * sd_wwwhr)) %&gt;%\n  select(-mean_wwwhr, -sd_wwwhr)  # Remove the temporary columns\n\n\n\n\ncheck_outliers(poisson_model)\n\n3 outliers detected: cases 72, 156, 363.\n- Based on the following method and threshold: cook (0.9).\n- For variable: (Whole model)."
  },
  {
    "objectID": "posts/Lab-5/poisson_lab_questions-1.html#refit-the-model-after-excluding-outliers",
    "href": "posts/Lab-5/poisson_lab_questions-1.html#refit-the-model-after-excluding-outliers",
    "title": "Poisson Lab Answers",
    "section": "Refit the model after excluding outliers",
    "text": "Refit the model after excluding outliers\n\npoisson_model_filtered &lt;- glm(wwwhr ~ wordsum + age + sex + reliten+ polviews + wrkhome, \n                     data = data_pos_filtered, \n                     family = poisson(link = \"log\"))\n\nmodel_summary &lt;- summary(poisson_model_filtered)$coefficients\nci &lt;- confint(poisson_model_filtered)  # Compute confidence intervals\n\n# Create a tidy dataframe\neffects_table &lt;- as.data.frame(model_summary) |&gt; \n  tibble::rownames_to_column(var = \"Predictor\") |&gt; \n  dplyr::mutate(\n    `Estimate` = round(Estimate, 3),\n    `Std. Error` = round(`Std. Error`, 3),\n    `z value` = round(`z value`, 3),\n    `Pr(&gt;|z|)` = round(`Pr(&gt;|z|)`, 3),\n    `CI Lower` = round(ci[,1], 3),\n    `CI Upper` = round(ci[,2], 3)\n  )\n\n# Display the table using kable\nkable(effects_table, format = \"markdown\", caption = \"Poisson Model Coefficients (Excluding Outliers)\") \n\n\nPoisson Model Coefficients (Excluding Outliers)\n\n\n\n\n\n\n\n\n\n\n\nPredictor\nEstimate\nStd. Error\nz value\nPr(&gt;|z|)\nCI Lower\nCI Upper\n\n\n\n\n(Intercept)\n1.631\n0.086\n18.885\n0.000\n1.461\n1.800\n\n\nwordsum\n0.091\n0.008\n11.002\n0.000\n0.075\n0.107\n\n\nage\n-0.011\n0.001\n-9.705\n0.000\n-0.013\n-0.009\n\n\nsexFemale\n0.142\n0.028\n5.071\n0.000\n0.087\n0.197\n\n\nreliten\n0.143\n0.013\n11.254\n0.000\n0.118\n0.168\n\n\npolviews\n-0.022\n0.010\n-2.118\n0.034\n-0.042\n-0.002\n\n\nwrkhome\n0.040\n0.008\n4.758\n0.000\n0.023\n0.056\n\n\n\n\n\n\nCheck for Overdispersion\nHint: performance package has the function you‚Äôre looking for\n\ncheck_overdispersion(poisson_model_filtered)\n\n# Overdispersion test\n\n       dispersion ratio =   10.684\n  Pearson's Chi-Squared = 6282.259\n                p-value =  &lt; 0.001\n\n\nWhat do you notice?\n\nThat we are expriencing overdispersion\n\nAnd what‚Äôs a good next step forward?\n\nWe can deal with this using a Negative Binomial regression model instead of a Poisson model.\n\nCan there be another model class that can fit the data? If so, fit this model to the data.\n\nA Negative Binomial regression model\n\n\nnb_model &lt;- glm.nb(wwwhr ~ wordsum + age + sex + reliten_recode + polviews + wrkhome, \n                   data = data_pos_filtered)\n\nmodel_summary &lt;- summary(nb_model)$coefficients\nci &lt;- confint(nb_model)  # Compute confidence intervals\n\n# Create a tidy dataframe\neffects_table &lt;- as.data.frame(model_summary) |&gt; \n  tibble::rownames_to_column(var = \"Predictor\") |&gt; \n  dplyr::mutate(\n    `Estimate` = round(Estimate, 3),\n    `Std. Error` = round(`Std. Error`, 3),\n    `z value` = round(`z value`, 3),\n    `Pr(&gt;|z|)` = round(`Pr(&gt;|z|)`, 3),\n    `CI Lower` = round(ci[,1], 3),\n    `CI Upper` = round(ci[,2], 3)\n  )\n\n# Display the table using kable\nkable(effects_table, format = \"markdown\", caption = \"Negative Binomial (Without Outliers)\") \n\n\nNegative Binomial (Without Outliers)\n\n\n\n\n\n\n\n\n\n\n\nPredictor\nEstimate\nStd. Error\nz value\nPr(&gt;|z|)\nCI Lower\nCI Upper\n\n\n\n\n(Intercept)\n1.720\n0.252\n6.829\n0.000\n1.224\n2.221\n\n\nwordsum\n0.101\n0.025\n3.972\n0.000\n0.049\n0.153\n\n\nage\n-0.012\n0.003\n-3.608\n0.000\n-0.019\n-0.005\n\n\nsexFemale\n0.105\n0.088\n1.201\n0.230\n-0.067\n0.278\n\n\nreliten_recode2\n0.293\n0.106\n2.766\n0.006\n0.085\n0.500\n\n\nreliten_recode3\n0.397\n0.200\n1.984\n0.047\n0.016\n0.806\n\n\nreliten_recode4\n0.478\n0.125\n3.815\n0.000\n0.236\n0.721\n\n\npolviews\n-0.024\n0.032\n-0.740\n0.460\n-0.086\n0.038\n\n\nwrkhome\n0.035\n0.026\n1.330\n0.183\n-0.017\n0.089"
  },
  {
    "objectID": "posts/Lab-5/poisson_lab_questions-1.html#which-one-is-better--your-earlier-model-or-later-model",
    "href": "posts/Lab-5/poisson_lab_questions-1.html#which-one-is-better--your-earlier-model-or-later-model",
    "title": "Poisson Lab Answers",
    "section": "Which one is better- your earlier model, or later model?",
    "text": "Which one is better- your earlier model, or later model?\n\nAIC(poisson_model_filtered, nb_model)\n\n                       df      AIC\npoisson_model_filtered  7 7136.602\nnb_model               10 3808.681\n\n# Alternatively, you can compare the residual deviance and degrees of freedom:\ndeviance_poisson &lt;- deviance(poisson_model_filtered)\ndf_poisson &lt;- df.residual(poisson_model_filtered)\ndeviance_ratio_poisson &lt;- deviance_poisson / df_poisson\n\n# Calculate deviance and degrees of freedom for Negative Binomial model\ndeviance_nb &lt;- deviance(nb_model)\ndf_nb &lt;- df.residual(nb_model)\ndeviance_ratio_nb &lt;- deviance_nb / df_nb\n\n# Check for overdispersion and compare the models\nbetter_model &lt;- ifelse(deviance_ratio_poisson &gt; 1, \n                       \"Negative Binomial Model is better due to overdispersion\", \n                       ifelse(deviance_ratio_poisson &gt; deviance_ratio_nb, \n                              \"Poisson Model is better\", \n                              \"Negative Binomial Model is better\"))\n\n# Print out the results\ncat(\"Deviance-to-DF Ratio for Poisson Model: \", deviance_ratio_poisson, \"\\n\")\n\nDeviance-to-DF Ratio for Poisson Model:  8.721789 \n\ncat(\"Deviance-to-DF Ratio for Negative Binomial Model: \", deviance_ratio_nb, \"\\n\")\n\nDeviance-to-DF Ratio for Negative Binomial Model:  1.129097 \n\ncat(\"Model Comparison: \", better_model)\n\nModel Comparison:  Negative Binomial Model is better due to overdispersion\n\n\n\nThe Negative Binomial model has a much lower AIC (3808.681) compared to the Poisson model (7136.602), suggesting that the Negative Binomial model provides a better fit to the data.\n\n\nBased on deviance, the negative binomial model is better."
  },
  {
    "objectID": "posts/Lab-5/poisson_lab_questions-1.html#what-is-zero-inflation-is-there-zero-inflation-in-your-chosen-model",
    "href": "posts/Lab-5/poisson_lab_questions-1.html#what-is-zero-inflation-is-there-zero-inflation-in-your-chosen-model",
    "title": "Poisson Lab Answers",
    "section": "What is zero inflation? Is there zero-inflation in your chosen model?",
    "text": "What is zero inflation? Is there zero-inflation in your chosen model?\n\nZero-inflation occurs when the data contains an excess number of zero outcomes that cannot be explained by the underlying model, such as a Poisson or Negative Binomial model. In other words, there are more zero values in the data than expected given the distribution (Poisson or Negative Binomial), which can indicate that a separate process is generating these excess zeros.\n\n\nperformance::check_zeroinflation(nb_model)\n\n# Check for zero-inflation\n\n   Observed zeros: 40\n  Predicted zeros: 63\n            Ratio: 1.57"
  },
  {
    "objectID": "posts/Lab-5/poisson_lab_questions-1.html#log-lambda",
    "href": "posts/Lab-5/poisson_lab_questions-1.html#log-lambda",
    "title": "Poisson Lab Answers",
    "section": "Log Lambda",
    "text": "Log Lambda\n\nlambda_poisson &lt;- predict(poisson_model_filtered, type = \"response\")\nlambda_nb &lt;- predict(nb_model, type = \"response\")\n\n# Log transform the lambda values\nlog_lambda_poisson &lt;- log(lambda_poisson)\nlog_lambda_nb &lt;- log(lambda_nb)\n\n# Output the log lambda values for a subset of the data\nhead(data.frame(log_lambda_poisson, log_lambda_nb))\n\n   log_lambda_poisson log_lambda_nb\n1            2.171034      2.079081\n2            2.881145      2.913070\n4            2.115022      2.220856\n8            2.191091      2.252398\n9            1.992306      2.030755\n12           2.578640      2.592963"
  },
  {
    "objectID": "posts/Lab-5/poisson_lab_questions-1.html#mean-count",
    "href": "posts/Lab-5/poisson_lab_questions-1.html#mean-count",
    "title": "Poisson Lab Answers",
    "section": "Mean Count",
    "text": "Mean Count\n\npredicted_counts_poisson &lt;- predict(poisson_model_filtered, type = \"response\")\npredicted_counts_nb &lt;- predict(nb_model, type = \"response\")\n\n# Calculate the mean of predicted counts for each model\nmean_count_poisson &lt;- mean(predicted_counts_poisson, na.rm = TRUE)\nmean_count_nb &lt;- mean(predicted_counts_nb, na.rm = TRUE)\n\n# Output the mean counts\ncat(\"Mean Count (Poisson Model): \", mean_count_poisson, \"\\n\")\n\nMean Count (Poisson Model):  8.821849 \n\ncat(\"Mean Count (Negative Binomial Model): \", mean_count_nb, \"\\n\")\n\nMean Count (Negative Binomial Model):  8.836638"
  },
  {
    "objectID": "posts/Lab-5/poisson_lab_questions-1.html#report-your-conclusions",
    "href": "posts/Lab-5/poisson_lab_questions-1.html#report-your-conclusions",
    "title": "Poisson Lab Answers",
    "section": "Report your conclusions",
    "text": "Report your conclusions\n\nThese results show that, on average, both models predict almost the same number of hours, with the Negative Binomial model giving a slightly higher estimate. This small difference could reflect model nuances, but both models suggest a similar central tendency in internet usage."
  },
  {
    "objectID": "posts/Lab-7/mlm-02.html",
    "href": "posts/Lab-7/mlm-02.html",
    "title": "Lab-7",
    "section": "",
    "text": "When to use them:\n\nNested designs\nRepeated measures\nLongitudinal data\nComplex designs\n\nWhy use them:\n\nCaptures variance occurring between groups and within groups\n\nWhat they are:\n\nLinear model with extra residuals"
  },
  {
    "objectID": "posts/Lab-7/mlm-02.html#multilevel-models",
    "href": "posts/Lab-7/mlm-02.html#multilevel-models",
    "title": "Lab-7",
    "section": "",
    "text": "When to use them:\n\nNested designs\nRepeated measures\nLongitudinal data\nComplex designs\n\nWhy use them:\n\nCaptures variance occurring between groups and within groups\n\nWhat they are:\n\nLinear model with extra residuals"
  },
  {
    "objectID": "posts/Lab-7/mlm-02.html#today",
    "href": "posts/Lab-7/mlm-02.html#today",
    "title": "Lab-7",
    "section": "Today",
    "text": "Today\n\nEverything you need to know to run and report a MLM\n\nOrganizing data for MLM analysis\nEstimation\nFit and interpret multilevel models\nVisualization\nEffect size\nReporting\nPower"
  },
  {
    "objectID": "posts/Lab-7/mlm-02.html#packages",
    "href": "posts/Lab-7/mlm-02.html#packages",
    "title": "Lab-7",
    "section": "Packages",
    "text": "Packages\n\nknitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, cache = FALSE,fig.path = \"Lab-6-figs/fig_\")\noptions(scipen=999)\n\nlibrary(pacman)\n\npacman::p_load(tidyverse, knitr, lme4, lmerTest, broom.mixed, afex, emmeans, ggeffects, easystats,ggeffects,ggrain,easystats,afex, install = T)\noptions(scipen=999) # get rid of sci notation\n\n\n### create plot aesthetics \npalette &lt;- c(\n  \"#772e25\", \"#c44536\", \"#ee9b00\", \"#197278\", \"#283d3b\", \n  \"#9CC5A1\", \"#6195C6\", \"#ADA7C9\", \"#4D4861\", \"grey50\",\n  \"#d4a373\", \"#8a5a44\", \"#4a6a74\", \"#5c80a8\", \"#a9c5a0\",\n  \"#7b9b8e\", \"#e1b16a\", \"#a69b7c\", \"#9d94c4\", \"#665c54\"\n)\n\npalette_condition = c(\"#ee9b00\", \"#c44536\",\"#005f73\", \"#283d3b\", \"#9CC5A1\", \"#6195C6\", \"#ADA7C9\", \"#4D4861\")\nplot_aes = theme_minimal() +\n  theme(\n    legend.position = \"top\",\n    legend.text = element_text(size = 12),\n    text = element_text(size = 16, family = \"Futura Medium\"),\n    axis.text = element_text(color = \"black\"),\n    axis.ticks.y = element_blank(),\n    plot.title = element_text(size = 20, hjust = 0.5) # Adjusted title size and centering\n  )\n\n\nFind the .qmd document here to follow along: https://github.com/suyoghc/PSY-504_Spring-2025/blob/main/Multilevel%20Modeling/mlm-02.qmd"
  },
  {
    "objectID": "posts/Lab-7/mlm-02.html#todays-data",
    "href": "posts/Lab-7/mlm-02.html#todays-data",
    "title": "Lab-7",
    "section": "Today‚Äôs data",
    "text": "Today‚Äôs data\n\nWhat did you say?\n\nPs (N = 31) listened to both clear (NS) and 6 channel vocoded speech (V6)\n\n(https://www.mrc-cbu.cam.ac.uk/personal/matt.davis/vocode/a1_6.wav)\n\nFixed factor: ?\nRandom factor: ?"
  },
  {
    "objectID": "posts/Lab-7/mlm-02.html#todays-data-1",
    "href": "posts/Lab-7/mlm-02.html#todays-data-1",
    "title": "Lab-7",
    "section": "Today‚Äôs data",
    "text": "Today‚Äôs data\n\neye  &lt;- read_csv(\"https://raw.githubusercontent.com/suyoghc/PSY-504_Spring-2025/refs/heads/main/Multilevel%20Modeling/data/vocoded_pupil.csv\") # data for class"
  },
  {
    "objectID": "posts/Lab-7/mlm-02.html#data-organization",
    "href": "posts/Lab-7/mlm-02.html#data-organization",
    "title": "Lab-7",
    "section": "Data organization",
    "text": "Data organization\n\nData Structure\n\nMLM analysis (in R) requires data in long format"
  },
  {
    "objectID": "posts/Lab-7/mlm-02.html#data-organization-1",
    "href": "posts/Lab-7/mlm-02.html#data-organization-1",
    "title": "Lab-7",
    "section": "Data organization",
    "text": "Data organization\n\nLevel 1: trial\nLevel 2: subject\n\n\n\n\n\n\nsubject\ntrial\nvocoded\nmean_pupil\n\n\n\n\nEYE15\n3\nV6\n0.0839555\n\n\nEYE15\n4\nV6\n0.0141083\n\n\nEYE15\n5\nV6\n0.0224967\n\n\nEYE15\n6\nV6\n0.0007424\n\n\nEYE15\n7\nV6\n0.0242540\n\n\nEYE15\n8\nV6\n0.0267617"
  },
  {
    "objectID": "posts/Lab-7/mlm-02.html#centering",
    "href": "posts/Lab-7/mlm-02.html#centering",
    "title": "Lab-7",
    "section": "Centering",
    "text": "Centering\n\n\n\nIn a single-level regression, centering ensures that the zero value for each predictor is meaningful before running the model\nIn MLM, if you have specific questions about within, between, and contextual effects, you need to center!"
  },
  {
    "objectID": "posts/Lab-7/mlm-02.html#group--vs.-grand-mean-centering",
    "href": "posts/Lab-7/mlm-02.html#group--vs.-grand-mean-centering",
    "title": "Lab-7",
    "section": "Group- vs.¬†Grand-Mean Centering",
    "text": "Group- vs.¬†Grand-Mean Centering\n\nGrand-mean centering: \\(x_{ij} - x\\)\n\nVariable represents each observation‚Äôs deviation from everyone‚Äôs norm, regardless of group\n\nGroup-mean centering: \\(x_{ij} - x_j\\)\n\nVariable represents each observation‚Äôs deviation from their group‚Äôs norm (removes group effect)"
  },
  {
    "objectID": "posts/Lab-7/mlm-02.html#group--vs.-grand-mean-centering-1",
    "href": "posts/Lab-7/mlm-02.html#group--vs.-grand-mean-centering-1",
    "title": "Lab-7",
    "section": "Group- vs.¬†Grand-Mean Centering",
    "text": "Group- vs.¬†Grand-Mean Centering\n\n\n\nLevel 1 predictors\n\nGrand-mean centering\n\nInclude means of level 2\n\nAllows us to directly test within-group effect\nCoefficient associated with the Level 2 group mean represents contextual effect\n\n\n\n\n\n\nGroup-mean centering\n\nLevel 1 coefficient will always be with within-group effect, regardless of whether the group means are included at Level 2 or not\nIf level 2 means included, coefficient represents the between-groups effect\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nCan apply to categorical predictors as well (see Yaremych, Preacher, & Hedeker, 2023)"
  },
  {
    "objectID": "posts/Lab-7/mlm-02.html#centering-in-r",
    "href": "posts/Lab-7/mlm-02.html#centering-in-r",
    "title": "Lab-7",
    "section": "Centering in R",
    "text": "Centering in R\n\n# how to group mean center \nd &lt;- d %&gt;% \n  # Grand mean centering (CMC)\n  mutate(iv.gmc = iv-mean(iv)) %&gt;%\n  # group  mean centering (more generally, centering within cluster)\n  group_by(id) %&gt;% \n  mutate(iv.cm = mean(iv),\n         iv.cwc = iv-iv.cm)\n\nlibrary(datawizard) #easystats \n\n#data wizard way\nx &lt;- demean(x, select=c(\"x\"), group=\"ID\") #gets within-group and included cluster means"
  },
  {
    "objectID": "posts/Lab-7/mlm-02.html#maximum-likelihood",
    "href": "posts/Lab-7/mlm-02.html#maximum-likelihood",
    "title": "Lab-7",
    "section": "Maximum Likelihood",
    "text": "Maximum Likelihood\n\n\n\n\nIn MLM we try to maximize the likelihood of the data\n\nNo OLS!"
  },
  {
    "objectID": "posts/Lab-7/mlm-02.html#probability-vs.-likelihood",
    "href": "posts/Lab-7/mlm-02.html#probability-vs.-likelihood",
    "title": "Lab-7",
    "section": "Probability vs.¬†Likelihood",
    "text": "Probability vs.¬†Likelihood\n\nProbability\n\n\nIf I assume a distribution with certain parameters (fixed), what is the probability I see a particular value in the data?\n\n\n\n\nPr‚Å°(ùë¶&gt;0‚îÇùúá=0,ùúé=1)=.50\nPr‚Å°(‚àí1&lt;ùë¶&lt;1‚îÇùúá=0,ùúé=1)=.68\nPr‚Å°(0&lt;ùë¶&lt;1‚îÇùúá=0,ùúé=1)=.34\nPr‚Å°(ùë¶&gt;2‚îÇùúá=0,ùúé=1)=.02"
  },
  {
    "objectID": "posts/Lab-7/mlm-02.html#likelihood",
    "href": "posts/Lab-7/mlm-02.html#likelihood",
    "title": "Lab-7",
    "section": "Likelihood",
    "text": "Likelihood\n\n\n\n\\(L(ùúá,ùúé‚îÇùë•)\\)\nHolding a sample of data constant, which parameter values are more likely?\n\nWhich values have higher likelihood?\n\nHere data is fixed and distribution can change"
  },
  {
    "objectID": "posts/Lab-7/mlm-02.html#likelihood-1",
    "href": "posts/Lab-7/mlm-02.html#likelihood-1",
    "title": "Lab-7",
    "section": "Likelihood",
    "text": "Likelihood"
  },
  {
    "objectID": "posts/Lab-7/mlm-02.html#likelihood-2",
    "href": "posts/Lab-7/mlm-02.html#likelihood-2",
    "title": "Lab-7",
    "section": "Likelihood",
    "text": "Likelihood"
  },
  {
    "objectID": "posts/Lab-7/mlm-02.html#likelihood-3",
    "href": "posts/Lab-7/mlm-02.html#likelihood-3",
    "title": "Lab-7",
    "section": "Likelihood",
    "text": "Likelihood"
  },
  {
    "objectID": "posts/Lab-7/mlm-02.html#likelihood-4",
    "href": "posts/Lab-7/mlm-02.html#likelihood-4",
    "title": "Lab-7",
    "section": "Likelihood",
    "text": "Likelihood"
  },
  {
    "objectID": "posts/Lab-7/mlm-02.html#likelihood-5",
    "href": "posts/Lab-7/mlm-02.html#likelihood-5",
    "title": "Lab-7",
    "section": "Likelihood",
    "text": "Likelihood"
  },
  {
    "objectID": "posts/Lab-7/mlm-02.html#likelihood-6",
    "href": "posts/Lab-7/mlm-02.html#likelihood-6",
    "title": "Lab-7",
    "section": "Likelihood",
    "text": "Likelihood\nInteractive: Understanding Maximum Likelihood Estimation: https://rpsychologist.com/likelihood/"
  },
  {
    "objectID": "posts/Lab-7/mlm-02.html#log-likelihood",
    "href": "posts/Lab-7/mlm-02.html#log-likelihood",
    "title": "Lab-7",
    "section": "Log likelihood",
    "text": "Log likelihood\n\nWith large samples, likelihood values ‚Ñí(ùúá,ùúé‚îÇùë•) get very small very fast\n\nTo make them easier to work with, we usually work with the log-likelihood\n\nMeasure of how well the model fits the data\nHigher values of \\(\\log L\\) are better\n\n\nDeviance = \\(-2logL\\)\n\n\\(-2logL\\) follows a \\(\\chi^2\\) distribution with \\(n (\\text{sample size}) - p (\\text{paramters}) - 1\\) degrees of freedom"
  },
  {
    "objectID": "posts/Lab-7/mlm-02.html#chi2-distribution",
    "href": "posts/Lab-7/mlm-02.html#chi2-distribution",
    "title": "Lab-7",
    "section": "\\(\\chi^2\\) distribution",
    "text": "\\(\\chi^2\\) distribution"
  },
  {
    "objectID": "posts/Lab-7/mlm-02.html#comparing-nested-models",
    "href": "posts/Lab-7/mlm-02.html#comparing-nested-models",
    "title": "Lab-7",
    "section": "Comparing nested models",
    "text": "Comparing nested models\n\nSuppose there are two models:\n\nReduced model includes predictors \\(x_1, \\ldots, x_q\\)\nFull model includes predictors \\(x_1, \\ldots, x_q, x_{q+1}, \\ldots, x_p\\)\n\nWe want to test the hypotheses:\n\n\\(H_0\\): smaller model is better\n\\(H_1\\): Larger model is better\n\nTo do so, we will use the drop-in-deviance test (also known as the nested likelihood ratio test)"
  },
  {
    "objectID": "posts/Lab-7/mlm-02.html#drop-in-deviance-test",
    "href": "posts/Lab-7/mlm-02.html#drop-in-deviance-test",
    "title": "Lab-7",
    "section": "Drop-In-Deviance Test",
    "text": "Drop-In-Deviance Test\n\nHypotheses:\n\n\\(H_0\\): smaller model is better\n\\(H_1\\): Larger model is better\n\nTest Statistic: \\[G = (-2 \\log L_{reduced}) - (-2 \\log L_{full})\\]\nP-value: \\(P(\\chi^2 &gt; G)\\):\n\nCalculated using a \\(\\chi^2\\) distribution\ndf = \\(df_1\\) - \\(df_2\\)"
  },
  {
    "objectID": "posts/Lab-7/mlm-02.html#testing-deviance",
    "href": "posts/Lab-7/mlm-02.html#testing-deviance",
    "title": "Lab-7",
    "section": "Testing deviance",
    "text": "Testing deviance\n\nWe can use the anova function to conduct this test\n\nAdd test = ‚ÄúChisq‚Äù to conduct the drop-in-deviance test\n\nI like test_likelihoodratio from easystats\n\n\nanova(model1, model2, test=\"chisq\")\n\n# test using easystats function\n\ntest_likelihoodratio(model1, model2)"
  },
  {
    "objectID": "posts/Lab-7/mlm-02.html#model-fitting-ml-or-reml",
    "href": "posts/Lab-7/mlm-02.html#model-fitting-ml-or-reml",
    "title": "Lab-7",
    "section": "Model fitting: ML or REML?",
    "text": "Model fitting: ML or REML?\n\nTwo flavors of maximum likelihood\n\nMaximum Likelihood (ML or FIML)\n\nJointly estimate the fixed effects and variance components using all the sample data\nCan be used to draw conclusions about fixed and random effects\nIssue:\n\nResults are biased because fixed effects are estimated without error"
  },
  {
    "objectID": "posts/Lab-7/mlm-02.html#model-fitting-ml-or-reml-1",
    "href": "posts/Lab-7/mlm-02.html#model-fitting-ml-or-reml-1",
    "title": "Lab-7",
    "section": "Model fitting: ML or REML",
    "text": "Model fitting: ML or REML\n\nRestricted Maximum Likelihood (REML)\n\nEstimates the variance components using the sample residuals not the sample data\nIt is conditional on the fixed effects, so it accounts for uncertainty in fixed effects estimates\n\nThis results in unbiased estimates of variance components\nAssociated with error/penalty"
  },
  {
    "objectID": "posts/Lab-7/mlm-02.html#model-fitting-ml-or-reml-2",
    "href": "posts/Lab-7/mlm-02.html#model-fitting-ml-or-reml-2",
    "title": "Lab-7",
    "section": "Model fitting: ML or REML?",
    "text": "Model fitting: ML or REML?\n\nResearch has not determined one method absolutely superior to the other\nREML (REML = TRUE; default in lmer) is preferable when:\n\nThe number of parameters is large\nPrimary objective is to obtain relaible estimates of the variance parameters\nFor REML, likelihood ratio tests can only be used to draw conclusions about variance components\n\nML (REML = FALSE) must be used if you want to compare nested fixed effects models using a likelihood ratio test (e.g., a drop-in-deviance test)"
  },
  {
    "objectID": "posts/Lab-7/mlm-02.html#ml-or-reml",
    "href": "posts/Lab-7/mlm-02.html#ml-or-reml",
    "title": "Lab-7",
    "section": "ML or REML?",
    "text": "ML or REML?\n\nWhat would we use if we wanted to compare the below models?\n\n\nx= lmer(DV ~ IV1 + IV2 + (1|ID))\n\ny= lmer(DV ~ IV1*IV2 + (1|ID))"
  },
  {
    "objectID": "posts/Lab-7/mlm-02.html#ml-or-reml-1",
    "href": "posts/Lab-7/mlm-02.html#ml-or-reml-1",
    "title": "Lab-7",
    "section": "ML or REML?",
    "text": "ML or REML?\n\nWhat would we use if we wanted to compare the below models?\n\n\nx = lmer(DV ~ IV1 + IV2 + (1+IV2|ID))\n\ny = lmer(DV ~ IV1+ IV2 + (1|ID))"
  },
  {
    "objectID": "posts/Lab-7/mlm-02.html#modeling-approach",
    "href": "posts/Lab-7/mlm-02.html#modeling-approach",
    "title": "Lab-7",
    "section": "Modeling approach",
    "text": "Modeling approach\n\nForward/backward approach\n\n\n\nKeep it maximal1\n\nWhatever can vary, should vary\n\nDecreases Type 1 error"
  },
  {
    "objectID": "posts/Lab-7/mlm-02.html#modeling-approach-1",
    "href": "posts/Lab-7/mlm-02.html#modeling-approach-1",
    "title": "Lab-7",
    "section": "Modeling approach",
    "text": "Modeling approach\n\nFull (maximal) model\n\nOnly when there is convergence issues should you remove terms\n\nif non-convergence (pay attention to warning messages in summary output!):\n\nTry different optimizer (afex::all_fit())\n\nSort out random effects\n\nRemove correlations between slopes and intercepts\nRandom slopes\nRandom Intercepts\n\nSort out fixed effects (e.g., interaction)\nOnce you arrive at the final model present it using REML estimation"
  },
  {
    "objectID": "posts/Lab-7/mlm-02.html#modeling-approach-2",
    "href": "posts/Lab-7/mlm-02.html#modeling-approach-2",
    "title": "Lab-7",
    "section": "Modeling approach",
    "text": "Modeling approach\n\nIf your model is singular (check output!!!!)\n\nVariance might be close to 0\nPerfect correlations (1 or -1)\n\nDrop the parameter!"
  },
  {
    "objectID": "posts/Lab-7/mlm-02.html#modeling-approach-3",
    "href": "posts/Lab-7/mlm-02.html#modeling-approach-3",
    "title": "Lab-7",
    "section": "Modeling approach",
    "text": "Modeling approach\n\ndata &lt;- read.csv(\"https://raw.githubusercontent.com/suyoghc/PSY-504_Spring-2025/refs/heads/main/Multilevel%20Modeling/data/heck2011.csv\")\n\nsummary(lmer(math~ses + (1+ses|schcode), data=data))\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: math ~ ses + (1 + ses | schcode)\n   Data: data\n\nREML criterion at convergence: 48190.1\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.8578 -0.5553  0.1290  0.6437  5.7098 \n\nRandom effects:\n Groups   Name        Variance Std.Dev. Corr \n schcode  (Intercept)  3.2042  1.7900        \n          ses          0.7794  0.8828   -1.00\n Residual             62.5855  7.9111        \nNumber of obs: 6871, groups:  schcode, 419\n\nFixed effects:\n             Estimate Std. Error        df t value            Pr(&gt;|t|)    \n(Intercept)   57.6959     0.1315  378.6378  438.78 &lt;0.0000000000000002 ***\nses            3.9602     0.1408 1450.7730   28.12 &lt;0.0000000000000002 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n    (Intr)\nses -0.284\noptimizer (nloptwrap) convergence code: 0 (OK)\nboundary (singular) fit: see help('isSingular')\n\n\n. . .\n\nlmer(math~ses + (1+ses||schcode), data=data) # removes correlation() with double pipes. Does not work with categorical variables"
  },
  {
    "objectID": "posts/Lab-7/mlm-02.html#null-model-unconditional-means",
    "href": "posts/Lab-7/mlm-02.html#null-model-unconditional-means",
    "title": "Lab-7",
    "section": "Null model (unconditional means)",
    "text": "Null model (unconditional means)\nGet ICC\n\nICC is a standardized way of expressing how much variance is due to clustering/group\n\nRanges from 0-1\n\nCan also be interpreted as correlation among observations within cluster/group!\nIf ICC is sufficiently low (i.e., \\(\\rho\\) &lt; .1), then you don‚Äôt have to use MLM! BUT YOU PROBABLY SHOULD üôÇ"
  },
  {
    "objectID": "posts/Lab-7/mlm-02.html#null-model-unconditional-means-1",
    "href": "posts/Lab-7/mlm-02.html#null-model-unconditional-means-1",
    "title": "Lab-7",
    "section": "Null model (unconditional means)",
    "text": "Null model (unconditional means)\n\nlibrary(lme4) # pop linear modeling package\n\nnull_model &lt;- lmer(mean_pupil ~ (1|subject), data = eye, REML=TRUE)\n\nsummary(null_model)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: mean_pupil ~ (1 | subject)\n   Data: eye\n\nREML criterion at convergence: -19811.6\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-5.1411 -0.5530 -0.0463  0.4822 10.8130 \n\nRandom effects:\n Groups   Name        Variance  Std.Dev.\n subject  (Intercept) 0.0001303 0.01142 \n Residual             0.0016840 0.04104 \nNumber of obs: 5609, groups:  subject, 31\n\nFixed effects:\n             Estimate Std. Error        df t value Pr(&gt;|t|)  \n(Intercept)  0.005227   0.002124 29.457784   2.461   0.0199 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "posts/Lab-7/mlm-02.html#calculating-icc",
    "href": "posts/Lab-7/mlm-02.html#calculating-icc",
    "title": "Lab-7",
    "section": "Calculating ICC",
    "text": "Calculating ICC\n\nRun baseline (null) model\nGet intercept variance and residual variance\n\n\\[\\mathrm{ICC}=\\frac{\\text { between-group variability }}{\\text { between-group variability+within-group variability}}\\]\n\\[\nICC=\\frac{\\operatorname{Var}\\left(u_{0 j}\\right)}{\\operatorname{Var}\\left(u_{0 j}\\right)+\\operatorname{Var}\\left(e_{i j}\\right)}=\\frac{\\tau_{00}}{\\tau_{00}+\\sigma^{2}}\n\\]\n\n# easystats \n#adjusted icc just random effects\n#unadjusted fixed effects taken into account\nperformance::icc(null_model)\n\n# Intraclass Correlation Coefficient\n\n    Adjusted ICC: 0.072\n  Unadjusted ICC: 0.072"
  },
  {
    "objectID": "posts/Lab-7/mlm-02.html#maximal-model-fixed-effect-random-intercepts-subject-and-slopes-vocoded-model",
    "href": "posts/Lab-7/mlm-02.html#maximal-model-fixed-effect-random-intercepts-subject-and-slopes-vocoded-model",
    "title": "Lab-7",
    "section": "Maximal model: Fixed effect random intercepts (subject) and slopes (vocoded) model",
    "text": "Maximal model: Fixed effect random intercepts (subject) and slopes (vocoded) model\n\nmax_model &lt;- lmer(mean_pupil ~vocoded +(1+vocoded|subject), data = eye)\n\nsummary(max_model)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: mean_pupil ~ vocoded + (1 + vocoded | subject)\n   Data: eye\n\nREML criterion at convergence: -19813.7\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-5.0296 -0.5509 -0.0467  0.4810 10.7164 \n\nRandom effects:\n Groups   Name        Variance   Std.Dev. Corr \n subject  (Intercept) 0.00013592 0.011658      \n          vocodedV6   0.00002816 0.005307 -0.19\n Residual             0.00167497 0.040926      \nNumber of obs: 5609, groups:  subject, 31\n\nFixed effects:\n             Estimate Std. Error        df t value Pr(&gt;|t|)  \n(Intercept)  0.003643   0.002235 28.852288    1.63   0.1140  \nvocodedV6    0.003124   0.001453 30.471988    2.15   0.0396 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n          (Intr)\nvocodedV6 -0.306"
  },
  {
    "objectID": "posts/Lab-7/mlm-02.html#fixed-effects",
    "href": "posts/Lab-7/mlm-02.html#fixed-effects",
    "title": "Lab-7",
    "section": "Fixed effects",
    "text": "Fixed effects\n\nInterpretation same as lm\n\n\n#grab the fixed effects\nsummary(max_model)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: mean_pupil ~ vocoded + (1 + vocoded | subject)\n   Data: eye\n\nREML criterion at convergence: -19813.7\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-5.0296 -0.5509 -0.0467  0.4810 10.7164 \n\nRandom effects:\n Groups   Name        Variance   Std.Dev. Corr \n subject  (Intercept) 0.00013592 0.011658      \n          vocodedV6   0.00002816 0.005307 -0.19\n Residual             0.00167497 0.040926      \nNumber of obs: 5609, groups:  subject, 31\n\nFixed effects:\n             Estimate Std. Error        df t value Pr(&gt;|t|)  \n(Intercept)  0.003643   0.002235 28.852288    1.63   0.1140  \nvocodedV6    0.003124   0.001453 30.471988    2.15   0.0396 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n          (Intr)\nvocodedV6 -0.306"
  },
  {
    "objectID": "posts/Lab-7/mlm-02.html#degrees-of-freedom-and-p-values",
    "href": "posts/Lab-7/mlm-02.html#degrees-of-freedom-and-p-values",
    "title": "Lab-7",
    "section": "Degrees of freedom and p-values",
    "text": "Degrees of freedom and p-values\n\nDegrees of freedom (denominator) and p-values can be assessed with several methods:\n\nSatterthwaite (default when install lmerTest and then run lmer)\nAsymptotic (Inf) (default behavior lme4)\nKenward-Rogers"
  },
  {
    "objectID": "posts/Lab-7/mlm-02.html#random-effectsvariance-components",
    "href": "posts/Lab-7/mlm-02.html#random-effectsvariance-components",
    "title": "Lab-7",
    "section": "Random effects/variance components",
    "text": "Random effects/variance components\n\nTells us how much variability there is around the fixed intercept/slope\n\nHow much does the average pupil size change between participants\n\n\n\nsummary(max_model)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: mean_pupil ~ vocoded + (1 + vocoded | subject)\n   Data: eye\n\nREML criterion at convergence: -19813.7\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-5.0296 -0.5509 -0.0467  0.4810 10.7164 \n\nRandom effects:\n Groups   Name        Variance   Std.Dev. Corr \n subject  (Intercept) 0.00013592 0.011658      \n          vocodedV6   0.00002816 0.005307 -0.19\n Residual             0.00167497 0.040926      \nNumber of obs: 5609, groups:  subject, 31\n\nFixed effects:\n             Estimate Std. Error        df t value Pr(&gt;|t|)  \n(Intercept)  0.003643   0.002235 28.852288    1.63   0.1140  \nvocodedV6    0.003124   0.001453 30.471988    2.15   0.0396 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n          (Intr)\nvocodedV6 -0.306"
  },
  {
    "objectID": "posts/Lab-7/mlm-02.html#random-effectsvariance-components-1",
    "href": "posts/Lab-7/mlm-02.html#random-effectsvariance-components-1",
    "title": "Lab-7",
    "section": "Random effects/variance components",
    "text": "Random effects/variance components\n\nCorrelation between random intercepts and slopes\n\nNegative correlation\n\nHigher intercept (for normal speech) less of effect (lower slope)\n\n\n\n\n\nParameter1 |  Parameter2 |     r |        95% CI | t(29) |     p\n----------------------------------------------------------------\nvocodedV6  | (Intercept) | -0.10 | [-0.44, 0.26] | -0.57 | 0.576\n\nObservations: 31"
  },
  {
    "objectID": "posts/Lab-7/mlm-02.html#visualize-random-effects",
    "href": "posts/Lab-7/mlm-02.html#visualize-random-effects",
    "title": "Lab-7",
    "section": "Visualize Random Effects",
    "text": "Visualize Random Effects\n\n# use easystats to grab group variance\nrandom &lt;- estimate_grouplevel(max_model)\n\nplot(random) + plot_aes"
  },
  {
    "objectID": "posts/Lab-7/mlm-02.html#model-comparisons",
    "href": "posts/Lab-7/mlm-02.html#model-comparisons",
    "title": "Lab-7",
    "section": "Model comparisons",
    "text": "Model comparisons\n\nCan compare models using anova function or test_likelihoodratio from easystats\n\nWill be refit using ML if interested in fixed effects\n\n\n\n# you try\n\nanova(max_model,null_model)\n\nData: eye\nModels:\nnull_model: mean_pupil ~ (1 | subject)\nmax_model: mean_pupil ~ vocoded + (1 + vocoded | subject)\n           npar    AIC    BIC logLik deviance  Chisq Df Pr(&gt;Chisq)   \nnull_model    3 -19816 -19796 9911.1   -19822                        \nmax_model     6 -19823 -19784 9917.7   -19835 13.269  3    0.00409 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "posts/Lab-7/mlm-02.html#aic",
    "href": "posts/Lab-7/mlm-02.html#aic",
    "title": "Lab-7",
    "section": "AIC",
    "text": "AIC\n\nAIC:\n\n\\[\nD + 2p\n\\]\n\nwhere d = deviance and p = # of parameters in model\nCan compare AICs2:\n\\[\n\\Delta_i = AIC_{i} - AIC_{min}\n\\]\nLess than 2: More parsimonious model is preferred\nBetween 4 and 7: some evidence for lower AIC model\nGreater than 10,: strong evidence for lower AIC"
  },
  {
    "objectID": "posts/Lab-7/mlm-02.html#bic",
    "href": "posts/Lab-7/mlm-02.html#bic",
    "title": "Lab-7",
    "section": "BIC",
    "text": "BIC\n\nBIC:\n\n\\[\nD + ln(n)*p\n\\]\n\nwhere d = deviance, p = # of parameters in model, n = sample size\nChange in BIC:\n\n\\(\\Delta{BIC}\\) &lt;= 2 (No difference)\n\\(\\Delta{BIC}\\) &gt; 3 (evidence for smaller BIC model)"
  },
  {
    "objectID": "posts/Lab-7/mlm-02.html#aicbic-1",
    "href": "posts/Lab-7/mlm-02.html#aicbic-1",
    "title": "Lab-7",
    "section": "AIC/BIC",
    "text": "AIC/BIC\n\nperformance::model_performance(max_model) %&gt;% # easystats\n  kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAIC\nAICc\nBIC\nR2_conditional\nR2_marginal\nICC\nRMSE\nSigma\n\n\n\n\n-19801.66\n-19801.65\n-19761.87\n0.0773469\n0.0013442\n0.076105\n0.0407697\n0.0409264"
  },
  {
    "objectID": "posts/Lab-7/mlm-02.html#hypothesis-testing",
    "href": "posts/Lab-7/mlm-02.html#hypothesis-testing",
    "title": "Lab-7",
    "section": "Hypothesis testing",
    "text": "Hypothesis testing\n\nMultiple options\n\nt/F tests with approximate degrees of freedom (Kenward-Rogers or Satterwaithe)\nParametric bootstrap\nLikelihood ratio test (LRT)\n\n\nCan be interpreted as main effects and interactions\nUse afex package to do that"
  },
  {
    "objectID": "posts/Lab-7/mlm-02.html#hypothesis-testing---afex",
    "href": "posts/Lab-7/mlm-02.html#hypothesis-testing---afex",
    "title": "Lab-7",
    "section": "Hypothesis testing - afex",
    "text": "Hypothesis testing - afex\n\nlibrary(afex) # load afex in \n\nm &lt;- mixed(mean_pupil ~ 1 + vocoded +  (1+vocoded|subject), data =eye, method = \"LRT\") # fit lmer using afex\n\nnice(m) %&gt;%\n  kable()\n\n\n\n\nEffect\ndf\nChisq\np.value\n\n\n\n\nvocoded\n1\n4.47 *\n.034"
  },
  {
    "objectID": "posts/Lab-7/mlm-02.html#using-emmeans",
    "href": "posts/Lab-7/mlm-02.html#using-emmeans",
    "title": "Lab-7",
    "section": "Using emmeans",
    "text": "Using emmeans\n\nGet means and contrasts\n\n\nlibrary(emmeans) # get marginal means \n\nemmeans(max_model, specs = \"vocoded\") %&gt;% \n  kable() # grabs means/SEs for each level of vocode \n\n\n\n\nvocoded\nemmean\nSE\ndf\nasymp.LCL\nasymp.UCL\n\n\n\n\nNS\n0.0036427\n0.0022348\nInf\n-0.0007374\n0.0080229\n\n\nV6\n0.0067668\n0.0022618\nInf\n0.0023337\n0.0111999\n\n\n\n\npairs(emmeans(max_model, specs = \"vocoded\")) %&gt;%\n  confint() %&gt;%\n  kable()\n\n\n\n\ncontrast\nestimate\nSE\ndf\nasymp.LCL\nasymp.UCL\n\n\n\n\nNS - V6\n-0.0031241\n0.0014532\nInf\n-0.0059723\n-0.0002759\n\n\n\n\n# use this to get pariwise compairsons between levels of factors"
  },
  {
    "objectID": "posts/Lab-7/mlm-02.html#check-assumptions",
    "href": "posts/Lab-7/mlm-02.html#check-assumptions",
    "title": "Lab-7",
    "section": "Check assumptions",
    "text": "Check assumptions\n\n\n\nLinearity\nNormality\n\nLevel 1 residuals are normally distributed around zero\nLevel 2 residuals are multivariate-normal with a mean of zero\n\nHomoskedacticity\n\nLevel 1/Level 2 predictors and residuals are homoskedastic\n\n\n\n\nCollinearity\nOutliers"
  },
  {
    "objectID": "posts/Lab-7/mlm-02.html#assumptions-1",
    "href": "posts/Lab-7/mlm-02.html#assumptions-1",
    "title": "Lab-7",
    "section": "Assumptions",
    "text": "Assumptions\n\nlibrary(easystats) # performance package\n\ncheck_model(max_model)"
  },
  {
    "objectID": "posts/Lab-7/mlm-02.html#visualization",
    "href": "posts/Lab-7/mlm-02.html#visualization",
    "title": "Lab-7",
    "section": "Visualization",
    "text": "Visualization"
  },
  {
    "objectID": "posts/Lab-7/mlm-02.html#ggeffects",
    "href": "posts/Lab-7/mlm-02.html#ggeffects",
    "title": "Lab-7",
    "section": "ggeffects",
    "text": "ggeffects\n\nggemmeans(max_model, terms=c(\"vocoded\")) %&gt;% plot()"
  },
  {
    "objectID": "posts/Lab-7/mlm-02.html#effect-size",
    "href": "posts/Lab-7/mlm-02.html#effect-size",
    "title": "Lab-7",
    "section": "Effect size",
    "text": "Effect size\n\nReport pseudo-\\(R^2\\) for marginal (fixed) and conditional model (full model) (Nakagawa et al.¬†2017)\n\n\\[\nR^2_{LMM(c)} = \\frac{\\sigma_f^2\\text{fixed} + \\sigma_a^2\\text{random}}{\\sigma_f^2\\text{fixed} + \\sigma_a^2\\text{random} + \\sigma_e^2\\text{residual}}\n\\]\n\\[\nR^2_{\\text{LMM}(m)} = \\frac{\\sigma_f^2\\text{fixed}}{\\sigma_f^2\\text{fixed} + \\sigma_a^2\\text{random} + \\sigma_e^2\\text{residual}}\n\\]\n\nReport semi-partial \\(R^2\\) for each predictor variable\n\n\\(R^2_\\beta\\)\n\npartR2 package in R does this for you"
  },
  {
    "objectID": "posts/Lab-7/mlm-02.html#effect-size-1",
    "href": "posts/Lab-7/mlm-02.html#effect-size-1",
    "title": "Lab-7",
    "section": "Effect size",
    "text": "Effect size\n\n#get r2 for model with performance from easystats\n\nperformance::r2(max_model) \n\n# R2 for Mixed Models\n\n  Conditional R2: 0.077\n     Marginal R2: 0.001\n\n\n\n# get semi-part\nlibrary(partR2)\n# does not work with random slopes for some reason :/\nR2_3 &lt;- partR2(max_model,data=eye, \n  partvars = c(\"vocoded\"),\n  R2_type = \"marginal\", nboot = 10, CI = 0.95\n)"
  },
  {
    "objectID": "posts/Lab-7/mlm-02.html#effect-size-2",
    "href": "posts/Lab-7/mlm-02.html#effect-size-2",
    "title": "Lab-7",
    "section": "Effect size",
    "text": "Effect size\n\nCohen‚Äôs \\(d\\) for treatment effects/categorical predictions3\n\n\\[\nd = \\frac{\\text{Effect}}{\\sqrt{\\sigma^2_\\text{Intercept} + \\sigma^2_\\text{slope} + \\sigma^2_\\text{residual}}}\n\\]\n\nemmeans(max_model,~ vocoded) %&gt;% \n eff_size(.,sigma=.04, edf=30) # need to calcuate sigma and add dfs\n\n contrast effect.size     SE  df asymp.LCL asymp.UCL\n NS - V6      -0.0781 0.0377 Inf    -0.152  -0.00421\n\nsigma used for effect sizes: 0.04 \nDegrees-of-freedom method: inherited from asymptotic when re-gridding \nConfidence level used: 0.95"
  },
  {
    "objectID": "posts/Lab-7/mlm-02.html#describing-a-mlm-analysis---structure",
    "href": "posts/Lab-7/mlm-02.html#describing-a-mlm-analysis---structure",
    "title": "Lab-7",
    "section": "Describing a MLM analysis - Structure",
    "text": "Describing a MLM analysis - Structure\n\nWhat was the nested data structure (e.g., how many levels; what were the units at each level?)\n‚Ä¢ How many units were in each level, on average?\n‚Ä¢ What was the range of the number of lower-level units in each group/cluster?"
  },
  {
    "objectID": "posts/Lab-7/mlm-02.html#describing-a-mlm-analysis---model",
    "href": "posts/Lab-7/mlm-02.html#describing-a-mlm-analysis---model",
    "title": "Lab-7",
    "section": "Describing a MLM analysis - Model",
    "text": "Describing a MLM analysis - Model\n\n\n\nWhat equation can best represent your model?\nWhat estimation method was used (e.g., ML, REML)?\nIf there were convergence issues, how was this addressed?\nWhat software (and version) was used (when using R, what packages as well)?\n\n\n\nIf degrees of freedom were used, what kind?\nWhat type of models were estimated (i.e., unconditional, random intercept, random slope, max)?\nWhat variables were centered and what kind of centering was used?\nWhat model assumptions were checked and what were the results?"
  },
  {
    "objectID": "posts/Lab-7/mlm-02.html#describing-a-mlm-analysis---results",
    "href": "posts/Lab-7/mlm-02.html#describing-a-mlm-analysis---results",
    "title": "Lab-7",
    "section": "Describing a MLM analysis - Results",
    "text": "Describing a MLM analysis - Results\n\n\n\nWhat was the ICC of the outcome variable?\nAre fixed effects and variance components reported?\nWhat inferential statistics were used (e.g., t-statistics, LRTs)?\nHow precise were the results (report the standard errors and/or confidence intervals)?\n\n\n\nWere model comparisons performed (e.g., AIC, BIC, if using an LRT,report the œá2, degrees of freedom, and p value)?\nWere effect sizes reported for overall model and individual predictors (e.g., Cohen‚Äôs d, \\(R^2\\) )?"
  },
  {
    "objectID": "posts/Lab-7/mlm-02.html#write-up",
    "href": "posts/Lab-7/mlm-02.html#write-up",
    "title": "Lab-7",
    "section": "Write-up",
    "text": "Write-up\n\nreport::report(max_model) # easystats report function\n\nWe fitted a linear mixed model (estimated using REML and nloptwrap optimizer) to predict mean_pupil with vocoded (formula: mean_pupil ~ vocoded). The model included vocoded as random effects (formula: ~1 + vocoded | subject). The model‚Äôs total explanatory power is weak (conditional R2 = 0.08) and the part related to the fixed effects alone (marginal R2) is of 1.34e-03. The model‚Äôs intercept, corresponding to vocoded = NS, is at 3.64e-03 (95% CI [-7.38e-04, 8.02e-03], t(5603) = 1.63, p = 0.103). Within this model:\n\nThe effect of vocoded [V6] is statistically significant and positive (beta = 3.12e-03, 95% CI [2.75e-04, 5.97e-03], t(5603) = 2.15, p = 0.032; Std. beta = 0.07, 95% CI [6.49e-03, 0.14])\n\nStandardized parameters were obtained by fitting the model on a standardized version of the dataset. 95% Confidence Intervals (CIs) and p-values were computed using a Wald t-distribution approximation."
  },
  {
    "objectID": "posts/Lab-7/mlm-02.html#table",
    "href": "posts/Lab-7/mlm-02.html#table",
    "title": "Lab-7",
    "section": "Table",
    "text": "Table\n\nmodelsummary::modelsummary(list(\"max model\" = max_model), output=\"html\") # modelsummary package\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                 \n                max model\n              \n        \n        \n        \n                \n                  (Intercept)\n                  0.004\n                \n                \n                  \n                  (0.002)\n                \n                \n                  vocodedV6\n                  0.003\n                \n                \n                  \n                  (0.001)\n                \n                \n                  SD (Intercept subject)\n                  0.012\n                \n                \n                  SD (vocodedV6 subject)\n                  0.005\n                \n                \n                  Cor (Intercept~vocodedV6 subject)\n                  ‚àí0.195\n                \n                \n                  SD (Observations)\n                  0.041\n                \n                \n                  Num.Obs.\n                  5609\n                \n                \n                  R2 Marg.\n                  0.001\n                \n                \n                  R2 Cond.\n                  0.077\n                \n                \n                  AIC\n                  ‚àí19801.7\n                \n                \n                  BIC\n                  ‚àí19761.9\n                \n                \n                  ICC\n                  0.1\n                \n                \n                  RMSE\n                  0.04"
  },
  {
    "objectID": "posts/Lab-7/mlm-02.html#power",
    "href": "posts/Lab-7/mlm-02.html#power",
    "title": "Lab-7",
    "section": "Power",
    "text": "Power\n\nSimulation-based power analyses\n\nSimulate new data\n\nfaux (https://debruine.github.io/faux/articles/sim_mixed.html)\n\nUse pilot data (what I would do)\n\nmixedpower(https://link.springer.com/article/10.3758/s13428-021-01546-0)\nsimr (https://besjournals.onlinelibrary.wiley.com/doi/full/10.1111/2041-210X.12504)"
  },
  {
    "objectID": "posts/Lab-7/mlm-02.html#footnotes",
    "href": "posts/Lab-7/mlm-02.html#footnotes",
    "title": "Lab-7",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nBarr, D. J., Levy, R., Scheepers, C., & Tily, H. J. (2013). Random effects structure for confirmatory hypothesis testing: Keep it maximal. Journal of memory and language, 68(3), 10.1016/j.jml.2012.11.001. https://doi.org/10.1016/j.jml.2012.11.001‚Ü©Ô∏é\nBURNHAM, ANDERSON, & HUYVAERT (2011)‚Ü©Ô∏é\nBrysbaert, M., & Debeer, D. (2023, September 12). How to run linear mixed effects analysis for pairwise comparisons? A tutorial and a proposal for the calculation of standardized effect sizes. https://doi.org/10.31234/osf.io/esnku‚Ü©Ô∏é"
  },
  {
    "objectID": "posts/Lab-8/Bayes_Lab_1.html",
    "href": "posts/Lab-8/Bayes_Lab_1.html",
    "title": "Lab-8: Bayes",
    "section": "",
    "text": "Here is a worksheet and assignment that combines Bayes (brms) with tidyverse tools. The focus is on the essentials when it comes to simple linear regression with brms.\nPlease read and run through this worksheet and answer the conceptual questions that are interleaved within them. At the end of each part, is a coding exercise based on the material you‚Äôve read until then."
  },
  {
    "objectID": "posts/Lab-8/Bayes_Lab_1.html#packages-and-data",
    "href": "posts/Lab-8/Bayes_Lab_1.html#packages-and-data",
    "title": "Lab-8: Bayes",
    "section": "Packages and data",
    "text": "Packages and data\nLoad the primary packages.\n\nlibrary(pacman)\np_load(tidyverse, ggside, brms, broom, broom.mixed,install = T)\n\noptions(scipen=999) # get rid of sci notation\n\nsetwd(\"~/Library/CloudStorage/GoogleDrive-sm9518@princeton.edu/My Drive/Classes/Stats-blog/posts\")\n### create plot aesthetics \npalette &lt;- c(\n  \"#772e25\", \"#c44536\", \"#ee9b00\", \"#197278\", \"#283d3b\", \n  \"#9CC5A1\", \"#6195C6\", \"#ADA7C9\", \"#4D4861\", \"grey50\",\n  \"#d4a373\", \"#8a5a44\", \"#4a6a74\", \"#5c80a8\", \"#a9c5a0\",\n  \"#7b9b8e\", \"#e1b16a\", \"#a69b7c\", \"#9d94c4\", \"#665c54\"\n)\n\npalette_condition = c(\"#ee9b00\", \"#c44536\",\"#005f73\", \"#283d3b\", \"#9CC5A1\", \"#6195C6\", \"#ADA7C9\", \"#4D4861\")\nplot_aes = theme_minimal() +\n  theme(\n    legend.position = \"top\",\n    legend.text = element_text(size = 12),\n    text = element_text(size = 16, family = \"Futura Medium\"),\n    axis.text = element_text(color = \"black\"),\n    axis.ticks.y = element_blank(),\n    plot.title = element_text(size = 20, hjust = 0.5) # Adjusted title size and centering\n  )\n\nWe‚Äôll use the penguins data set from the palmerpenguins package.\n\ndata(penguins, package = \"palmerpenguins\")\n\n# Any type of looking at data is a part of EDA \nglimpse(penguins)\n\nRows: 344\nColumns: 8\n$ species           &lt;fct&gt; Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adel‚Ä¶\n$ island            &lt;fct&gt; Torgersen, Torgersen, Torgersen, Torgersen, Torgerse‚Ä¶\n$ bill_length_mm    &lt;dbl&gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, ‚Ä¶\n$ bill_depth_mm     &lt;dbl&gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, ‚Ä¶\n$ flipper_length_mm &lt;int&gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186‚Ä¶\n$ body_mass_g       &lt;int&gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, ‚Ä¶\n$ sex               &lt;fct&gt; male, female, female, NA, female, male, female, male‚Ä¶\n$ year              &lt;int&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007‚Ä¶\n\nhead(penguins)\n\n# A tibble: 6 √ó 8\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Adelie  Torgersen           39.1          18.7               181        3750\n2 Adelie  Torgersen           39.5          17.4               186        3800\n3 Adelie  Torgersen           40.3          18                 195        3250\n4 Adelie  Torgersen           NA            NA                  NA          NA\n5 Adelie  Torgersen           36.7          19.3               193        3450\n6 Adelie  Torgersen           39.3          20.6               190        3650\n# ‚Ñπ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\nYou might divide the data set by the three levels of species.\n\npenguins %&gt;% \n  count(species) |&gt; \n  DT::datatable()\n\n\n\n\n\nTo start, we‚Äôll make a subset of the data called chinstrap.\n\nchinstrap &lt;- penguins %&gt;% \n  filter(species == \"Chinstrap\")\n\nglimpse(chinstrap)\n\nRows: 68\nColumns: 8\n$ species           &lt;fct&gt; Chinstrap, Chinstrap, Chinstrap, Chinstrap, Chinstra‚Ä¶\n$ island            &lt;fct&gt; Dream, Dream, Dream, Dream, Dream, Dream, Dream, Dre‚Ä¶\n$ bill_length_mm    &lt;dbl&gt; 46.5, 50.0, 51.3, 45.4, 52.7, 45.2, 46.1, 51.3, 46.0‚Ä¶\n$ bill_depth_mm     &lt;dbl&gt; 17.9, 19.5, 19.2, 18.7, 19.8, 17.8, 18.2, 18.2, 18.9‚Ä¶\n$ flipper_length_mm &lt;int&gt; 192, 196, 193, 188, 197, 198, 178, 197, 195, 198, 19‚Ä¶\n$ body_mass_g       &lt;int&gt; 3500, 3900, 3650, 3525, 3725, 3950, 3250, 3750, 4150‚Ä¶\n$ sex               &lt;fct&gt; female, male, male, female, male, female, female, ma‚Ä¶\n$ year              &lt;int&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007‚Ä¶\n\n\nWe‚Äôve done from a full data set with \\(N = 344\\) rows, to a subset with \\(n = 68\\) rows. (‚Äú$‚Äù signs hold LaTex snippets)"
  },
  {
    "objectID": "posts/Lab-8/Bayes_Lab_1.html#more-exploratory-data-analysis-eda",
    "href": "posts/Lab-8/Bayes_Lab_1.html#more-exploratory-data-analysis-eda",
    "title": "Lab-8: Bayes",
    "section": "More Exploratory data analysis (EDA)",
    "text": "More Exploratory data analysis (EDA)\nOur focal variables will be body_mass_g and bill_length_mm. Here they are in a scatter plot.\n\nchinstrap %&gt;% \n  ggplot(aes(x = body_mass_g, y = bill_length_mm)) +\n  geom_point() +\n  stat_smooth(method = \"lm\", formula = 'y ~ x', se = FALSE) + plot_aes\n\n\n\n\n\n\n\n\nWe can augment the plot with some nice functions from the ggside package.\n\nchinstrap %&gt;% \n  ggplot(aes(x = body_mass_g, y = bill_length_mm)) +\n  geom_point() +\n  stat_smooth(method = \"lm\", formula = 'y ~ x', se = FALSE) +\n  # from ggside\n  geom_xsidehistogram(bins = 30) +\n  geom_ysidehistogram(bins = 30) +\n  scale_xsidey_continuous(breaks = NULL) +\n  scale_ysidex_continuous(breaks = NULL) +\n  theme(ggside.panel.scale = 0.25) + plot_aes\n\n\n\n\n\n\n\n\nIt‚Äôs a good idea to get a sense of the sample statistics. Here are the means and SD‚Äôs for the two variables.\n\nchinstrap %&gt;% \n  summarise(body_mass_g_mean = mean(body_mass_g),\n            body_mass_g_sd = sd(body_mass_g),\n            bill_length_mm_mean = mean(bill_length_mm),\n            bill_length_mm_sd = sd(bill_length_mm)) |&gt;\n  pivot_longer(cols = everything()) |&gt;\n  mutate(name = str_replace(name, \"_\", \" \"),\n         value = round(value, digits = 3)) |&gt;\n  DT::datatable()\n\n\n\n\n\nAnd you know that more efficient way to compute sample statistics for multiple variables is to first convert the data into the long format with pivot_longer(). Then you use a group_by() line before the main event in summarise().\n\nchinstrap %&gt;% \n  pivot_longer(cols = c(body_mass_g, bill_length_mm)) %&gt;% \n  group_by(name) %&gt;% \n  summarise(mean = mean(value),\n            sd = sd(value),\n            # count the missing data (if any)\n            n_missing = sum(is.na(value))) |&gt; \n  mutate(across(c(mean, sd), ~ round(., digits = 3)) ) |&gt;\n  DT::datatable()\n\n\n\n\n\n\nQuestion 1.1: What do the marginal histograms added by ggside tell you about the distribution of body_mass_g and bill_length_mm individually?\n\nThey tell us that hte body_mass_g is right skewed and bill_length_mm is left skewed. But its important to note that these inferences are descriptive since we don‚Äôt have skewness and kurotsis stats."
  },
  {
    "objectID": "posts/Lab-8/Bayes_Lab_1.html#ols",
    "href": "posts/Lab-8/Bayes_Lab_1.html#ols",
    "title": "Lab-8: Bayes",
    "section": "OLS",
    "text": "OLS\nWe‚Äôll fit the model\n\\[\n\\begin{align}\n\\text{bill_length_mm}_i & = \\beta_0 + \\beta_1 \\text{body_mass_g}_i + \\epsilon_i \\\\\n\\epsilon_i & \\sim \\operatorname{Normal}(0, \\sigma_\\epsilon)\n\\end{align}\n\\]\nwhere bill_length_mm is the dependent variable or a response variable. The sole predictor is body_mass_g. Both variables have \\(i\\) subscripts, which indicate they vary across the \\(i\\) rows in the data set. For now, you might think if \\(i\\) as standing for ‚Äúindex.‚Äù The last term in the first line, \\(\\epsilon\\), is often called the error, or noise term. In the second line, we see we‚Äôre making the conventional assumption the ‚Äúerrors‚Äù are normally distributed around the regression line.\nAn alternative and equivalent way to write that equation is\n\\[\n\\begin{align}\n\\text{bill_length_mm}_i & \\sim \\operatorname{Normal}(\\mu_i, \\sigma) \\\\\n\\mu_i & = \\beta_0 + \\beta_1 \\text{body_mass_g}_i,\n\\end{align}\n\\]\nwhich is meant to convey we are modeling bill_length_mm as normally distributed, with a conditional mean. You don‚Äôt tend to see equations written this way in the OLS paradigm. However, this style of notation will serve us better when we start modeling our data with other distributions.\nThis notation grows on you\nFitting the model with the base R lm() function, which uses the OLS algorithm.\n\n# fit\nfit1.ols &lt;- lm(\n  data = chinstrap,\n  bill_length_mm ~ 1 + body_mass_g\n)\n\n# summarize the results\nsummary(fit1.ols)\n\n\nCall:\nlm(formula = bill_length_mm ~ 1 + body_mass_g, data = chinstrap)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-5.8399 -2.2370  0.3247  1.8385  9.3138 \n\nCoefficients:\n              Estimate Std. Error t value          Pr(&gt;|t|)    \n(Intercept) 32.1741929  3.4433623   9.344 0.000000000000107 ***\nbody_mass_g  0.0044627  0.0009176   4.863 0.000007480491992 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.887 on 66 degrees of freedom\nMultiple R-squared:  0.2638,    Adjusted R-squared:  0.2527 \nF-statistic: 23.65 on 1 and 66 DF,  p-value: 0.00000748\n\n\nThe point estimates are in scientific notation. We can pull them with the coef() function.\n\ncoef(fit1.ols) \n\n (Intercept)  body_mass_g \n32.174192865  0.004462694 \n\n\nWe can compute fitted values, or predictions, with the predict() function. Here‚Äôs the default behavior. Modifying to just get the top 6 to keep this concise.\n\npredict(fit1.ols) |&gt; \n  head()\n\n       1        2        3        4        5        6 \n47.79362 49.57870 48.46303 47.90519 48.79773 49.80183 \n\n\nWe get one prediction, one fitted value, for each case in the data set. We can express the uncertainty around those predictions with confidence intervals.\n\npredict(fit1.ols,\n        interval = \"confidence\") %&gt;% \n  head() |&gt; \n  DT::datatable()\n\n\n\n\n\nWe might also ask for a standard error for each prediction.\n\npredict(fit1.ols,\n        se.fit = TRUE) %&gt;% \n  data.frame()\n\n        fit    se.fit df residual.scale\n1  47.79362 0.4102359 66       2.886728\n2  49.57870 0.3821060 66       2.886728\n3  48.46303 0.3582736 66       2.886728\n4  47.90519 0.3987564 66       2.886728\n5  48.79773 0.3501459 66       2.886728\n6  49.80183 0.4026961 66       2.886728\n7  46.67795 0.5648454 66       2.886728\n8  48.90930 0.3504110 66       2.886728\n9  50.69437 0.5185569 66       2.886728\n10 48.68616 0.3513814 66       2.886728\n11 49.13243 0.3554108 66       2.886728\n12 49.02086 0.3521734 66       2.886728\n13 48.68616 0.3513814 66       2.886728\n14 50.24810 0.4550963 66       2.886728\n15 48.12832 0.3789333 66       2.886728\n16 50.24810 0.4550963 66       2.886728\n17 46.90108 0.5296025 66       2.886728\n18 48.68616 0.3513814 66       2.886728\n19 47.57049 0.4359183 66       2.886728\n20 51.81005 0.7050167 66       2.886728\n21 48.23989 0.3707575 66       2.886728\n22 47.34735 0.4647215 66       2.886728\n23 45.11601 0.8407923 66       2.886728\n24 49.13243 0.3554108 66       2.886728\n25 46.90108 0.5296025 66       2.886728\n26 50.69437 0.5185569 66       2.886728\n27 47.34735 0.4647215 66       2.886728\n28 49.13243 0.3554108 66       2.886728\n29 48.68616 0.3513814 66       2.886728\n30 52.47945 0.8273195 66       2.886728\n31 46.45481 0.6015246 66       2.886728\n32 51.36378 0.6270243 66       2.886728\n33 47.12422 0.4961023 66       2.886728\n34 50.47124 0.4856973 66       2.886728\n35 48.23989 0.3707575 66       2.886728\n36 49.57870 0.3821060 66       2.886728\n37 49.35556 0.3661365 66       2.886728\n38 53.59512 1.0397147 66       2.886728\n39 44.22347 1.0105441 66       2.886728\n40 52.25632 0.7859885 66       2.886728\n41 49.80183 0.4026961 66       2.886728\n42 48.46303 0.3582736 66       2.886728\n43 48.01676 0.3882941 66       2.886728\n44 47.79362 0.4102359 66       2.886728\n45 48.57459 0.3541019 66       2.886728\n46 52.03318 0.7451900 66       2.886728\n47 47.34735 0.4647215 66       2.886728\n48 51.36378 0.6270243 66       2.886728\n49 46.67795 0.5648454 66       2.886728\n50 48.57459 0.3541019 66       2.886728\n51 47.01265 0.5126128 66       2.886728\n52 49.80183 0.4026961 66       2.886728\n53 48.23989 0.3707575 66       2.886728\n54 50.24810 0.4550963 66       2.886728\n55 47.12422 0.4961023 66       2.886728\n56 47.57049 0.4359183 66       2.886728\n57 46.67795 0.5648454 66       2.886728\n58 50.24810 0.4550963 66       2.886728\n59 49.13243 0.3554108 66       2.886728\n60 47.90519 0.3987564 66       2.886728\n61 49.80183 0.4026961 66       2.886728\n62 48.46303 0.3582736 66       2.886728\n63 48.46303 0.3582736 66       2.886728\n64 50.02497 0.4272392 66       2.886728\n65 47.34735 0.4647215 66       2.886728\n66 49.02086 0.3521734 66       2.886728\n67 50.47124 0.4856973 66       2.886728\n68 49.02086 0.3521734 66       2.886728\n\n\nInstead of relying on predictions from the values in the data, we might instead define a sequence of values from the predictor variable. We‚Äôll call those nd.\n\nnd &lt;- tibble(body_mass_g = seq(from = min(chinstrap$body_mass_g),\n                               to = max(chinstrap$body_mass_g),\n                               length.out = 50))\n\nglimpse(nd)\n\nRows: 50\nColumns: 1\n$ body_mass_g &lt;dbl&gt; 2700.000, 2742.857, 2785.714, 2828.571, 2871.429, 2914.286‚Ä¶\n\n\nWe can insert our nd data into the newdata argument. Here we are using the model to predict new data\n\npredict(fit1.ols,\n        interval = \"confidence\",\n        newdata = nd) %&gt;% \n  # just the top 6\n  head()\n\n       fit      lwr      upr\n1 44.22347 42.20585 46.24108\n2 44.41473 42.47057 46.35888\n3 44.60598 42.73489 46.47708\n4 44.79724 42.99874 46.59574\n5 44.98850 43.26207 46.71493\n6 45.17976 43.52482 46.83469\n\n\nNow we wrangle those predictions a bit and pump the results right into ggplot().\n\npredict(fit1.ols,\n        interval = \"confidence\",\n        newdata = nd) %&gt;% \n  data.frame() %&gt;% \n  bind_cols(nd) %&gt;% \n  ggplot(aes(x = body_mass_g)) +\n  # 95% confidence interval ribbon\n  geom_ribbon(aes(ymin = lwr, ymax = upr),\n              alpha = 0.2) +\n  # point estimate line\n  geom_line(aes(y = fit)) +\n  geom_point(data = chinstrap,\n             aes(y = bill_length_mm)) + plot_aes\n\n\n\n\n\n\n\n\nIf we wanted to, we could look at the residuals with help from the residuals() function.\n\nresiduals(fit1.ols) |&gt; \n  head()\n\n         1          2          3          4          5          6 \n-1.2936220  0.4213003  2.8369738 -2.5051894  3.9022718 -4.6018344 \n\n\nHere we might put them in a tibble and display them in a plot.\n\n# put them in a tibble\ntibble(r = residuals(fit1.ols)) %&gt;% \n  ggplot(aes(x = r)) +\n  geom_histogram(binwidth = 1) + plot_aes\n\n\n\n\n\n\n\n\n\nQuestion 1.2: Can you predict what the mean value, and standard deviations will be? Why? Calculate it. Compare this against outputs in summary(fit1.ols) and explain. Map the values you find to the latex equations before.\n\nWe can predict that the mean value will be 0 and the standard deviation will be 1. This is because the residuals are the difference between the observed and predicted values."
  },
  {
    "objectID": "posts/Lab-8/Bayes_Lab_1.html#bayes-with-default-settings",
    "href": "posts/Lab-8/Bayes_Lab_1.html#bayes-with-default-settings",
    "title": "Lab-8: Bayes",
    "section": "Bayes with default settings",
    "text": "Bayes with default settings\nWe‚Äôll be fitting our Bayesian models with the brms package. The primary function is brm().\nbrm() can work a lot like the OLS-based lm() function. For example, here‚Äôs how to fit a Bayesian version of our OLS model fit1.ols.\n\nmodel_path &lt;- file.path(\"~/Library/CloudStorage/GoogleDrive-sm9518@princeton.edu/My Drive/Classes/Stats-blog/posts/Lab-8/models/fit1.rds\")\n\nif (!file.exists(model_path)) {\n fit1.b &lt;- brm(\n  data = chinstrap,\n  bill_length_mm ~ 1 + body_mass_g\n)\n  saveRDS(fit1.b, model_path)\n} else {\n  # If the RDS file already exists, load the data from it\n  fit1.b &lt;- readRDS(model_path)\n}\n\nNotice what‚Äôs happening in the console, below. We‚Äôll get into the details of what just happened later. For now, appreciate we just fit our first Bayesian model, and it wasn‚Äôt all that hard.\nSummarize the model.\n\nsummary(fit1.b)\n\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: bill_length_mm ~ 1 + body_mass_g \n   Data: chinstrap (Number of observations: 68) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nRegression Coefficients:\n            Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept      32.17      3.46    25.20    38.77 1.00     5027     2952\nbody_mass_g     0.00      0.00     0.00     0.01 1.00     5128     2545\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     2.92      0.27     2.45     3.51 1.00     1860     1673\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\n\nQuestion 1.3: Contrast the language of in the brm() output from the in the lm() output. Ignore ‚ÄòRhat,‚Äô ‚ÄòBulk_ESS,‚Äô and ‚ÄòTail_ESS‚Äô for now.\nWe can get a quick and dirty plot of the fitted line with the conditional_effects() function.\n\nconditional_effects(fit1.b) \n\n\n\n\n\n\n\n# %&gt;% \n#   plot(points = TRUE)"
  },
  {
    "objectID": "posts/Lab-8/Bayes_Lab_1.html#coefficients-and-coefficient-plots",
    "href": "posts/Lab-8/Bayes_Lab_1.html#coefficients-and-coefficient-plots",
    "title": "Lab-8: Bayes",
    "section": "Coefficients and coefficient plots",
    "text": "Coefficients and coefficient plots\nWe might want to compare the coefficient summaries from the OLS model to those from the Bayesian model. Here‚Äôs the frequentist summary:\n\ncbind(coef(fit1.ols),              # point estimates\n      sqrt(diag(vcov(fit1.ols))),  # standard errors\n      confint(fit1.ols))           # 95% CIs\n\n                                             2.5 %       97.5 %\n(Intercept) 32.174192865 3.4433622902 25.299298235 39.049087495\nbody_mass_g  0.004462694 0.0009176106  0.002630625  0.006294763\n\n\nWe can compute a focused summary of the Bayesian model with the fixef() function.\n\nfixef(fit1.b)\n\n                Estimate    Est.Error         Q2.5        Q97.5\nIntercept   32.171601696 3.4599647320 25.197783898 38.767885598\nbody_mass_g  0.004464182 0.0009227771  0.002668377  0.006304322\n\n\nIn this case, the results are very similar.\nWe can also pull this information from our OLS model with the broom::tidy() function.\n\ntidy(fit1.ols, conf.int = TRUE)\n\n# A tibble: 2 √ó 7\n  term        estimate std.error statistic  p.value conf.low conf.high\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept) 32.2      3.44          9.34 1.07e-13 25.3      39.0    \n2 body_mass_g  0.00446  0.000918      4.86 7.48e- 6  0.00263   0.00629\n\n\nIf you would like to use the tidy() function with your brms models, it will have to be the version of tidy() from the broom.mixed package.\n\ntidy(fit1.b)\n\n# A tibble: 3 √ó 8\n  effect   component group    term         estimate std.error conf.low conf.high\n  &lt;chr&gt;    &lt;chr&gt;     &lt;chr&gt;    &lt;chr&gt;           &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 fixed    cond      &lt;NA&gt;     (Intercept)  32.2      3.46     25.2      38.8    \n2 fixed    cond      &lt;NA&gt;     body_mass_g   0.00446  0.000923  0.00267   0.00630\n3 ran_pars cond      Residual sd__Observa‚Ä¶  2.92     0.266     2.45      3.51   \n\n\nHere‚Äôs how to wrangle and combine these two results into a single data frame. Then we‚Äôll make a coefficient plot.\n\nbind_rows(\n  tidy(fit1.ols, conf.int = TRUE) %&gt;% select(term, estimate, contains(\"conf\")),\n  tidy(fit1.b) %&gt;% select(term, estimate, contains(\"conf\")) %&gt;% filter(term != \"sd__Observation\")\n) %&gt;% \n  mutate(method = rep(c(\"lm()\", \"brm()\"), each = 2)) %&gt;% \n  \n  ggplot(aes(x = estimate, xmin = conf.low, xmax = conf.high, y = method)) +\n  geom_pointrange() +\n  scale_x_continuous(\"parameter space\", expand = expansion(mult = 0.2)) +\n  scale_y_discrete(expand = expansion(mult = 5)) +\n  facet_wrap(~ term, scales = \"free_x\") + plot_aes\n\n\n\n\n\n\n\n\nAt a superficial level for simple conventional regression type models, the results from a Bayesian brm() model will be very similar to those from an OLS lm() model. This will not always be case, and even in this example there are many differences once we look below the surface."
  },
  {
    "objectID": "posts/Lab-8/Bayes_Lab_1.html#more-questionsexercise",
    "href": "posts/Lab-8/Bayes_Lab_1.html#more-questionsexercise",
    "title": "Lab-8: Bayes",
    "section": "More Questions/Exercise",
    "text": "More Questions/Exercise\nGo back to the full penguins data set. This time, make a subset of the data called gentoo, which is only the cases for which species == \"Gentoo\".\n\ngentoo &lt;- penguins %&gt;% \n  filter(species == \"Gentoo\")\n\ngentoo |&gt; \n  head() |&gt; \n  DT::datatable()\n\n\n\n\n\nCan you fit the same OLS model to these data?\n\ngentoo_ols = lm( bill_length_mm ~ 1 + body_mass_g, data = gentoo)\nsummary(gentoo_ols)\n\n\nCall:\nlm(formula = bill_length_mm ~ 1 + body_mass_g, data = gentoo)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-5.8802 -1.5075 -0.0575  1.3118  8.1107 \n\nCoefficients:\n             Estimate Std. Error t value            Pr(&gt;|t|)    \n(Intercept) 26.739549   2.106594  12.693 &lt;0.0000000000000002 ***\nbody_mass_g  0.004091   0.000413   9.905 &lt;0.0000000000000002 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.3 on 121 degrees of freedom\n  (1 observation deleted due to missingness)\nMultiple R-squared:  0.4478,    Adjusted R-squared:  0.4432 \nF-statistic: 98.12 on 1 and 121 DF,  p-value: &lt; 0.00000000000000022\n\n\nHow about plotting the results with predict()?\n\npredict(gentoo_ols,\n        interval = \"confidence\") %&gt;% \n  head() |&gt; \n  DT::datatable()\n\n\n\n\n### create new data \n\nnd_2 &lt;- tibble(body_mass_g = seq(from = min(gentoo$body_mass_g,na.rm = TRUE),\n                               to = max(gentoo$body_mass_g,na.rm = TRUE),\n                               length.out = 1e6))\n\n\n\npredict(gentoo_ols,\n        interval = \"confidence\",\n        newdata = nd_2) %&gt;% \n  bind_cols(nd_2) %&gt;% \n  data.frame() |&gt; \n  ggplot(aes(x = body_mass_g)) +  # Ensure that body_mass_g is available here\n  geom_ribbon(aes(ymin = lwr, ymax = upr),\n              alpha = 0.2) +  \n  # point estimate line\n  geom_line(aes(y = fit)) +\n  # Add points for the original data\n  geom_point(data = gentoo, aes(x = body_mass_g, y = bill_length_mm)) + plot_aes\n\n\n\n\n\n\n\n\nCan you fit the same default Bayesian brm() model to these data?\n\nmodel_path &lt;- file.path(\"~/Library/CloudStorage/GoogleDrive-sm9518@princeton.edu/My Drive/Classes/Stats-blog/posts/Lab-8/models/fit2.rds\")\n\nif (!file.exists(model_path)) {\n fit2 &lt;- brm(\n  data = gentoo,\n  bill_length_mm ~ 1 + body_mass_g\n)\n  saveRDS(fit1.b, model_path)\n} else {\n  # If the RDS file already exists, load the data from it\n  fit2 &lt;- readRDS(model_path)\n}\n\nsummary(fit2)\n\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: bill_length_mm ~ 1 + body_mass_g \n   Data: gentoo (Number of observations: 123) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nRegression Coefficients:\n            Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept      26.77      2.14    22.65    31.06 1.00     4282     2507\nbody_mass_g     0.00      0.00     0.00     0.00 1.00     4325     2620\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     2.32      0.15     2.06     2.64 1.01     1766     1628\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\nHow about plotting the results with conditional_effects()?\n\nconditional_effects(fit2) \n\n\n\n\n\n\n\n\nCan you make a coefficient plot comparing the new OLS and Bayesian beta coefficients?\n\nbind_rows(\n  tidy(gentoo_ols, conf.int = TRUE) %&gt;% select(term, estimate, contains(\"conf\")),\n  tidy(fit2) %&gt;% select(term, estimate, contains(\"conf\")) %&gt;% filter(term != \"sd__Observation\")\n) %&gt;% \n  mutate(method = rep(c(\"lm()\", \"brm()\"), each = 2)) %&gt;% \n  \n  ggplot(aes(x = estimate, xmin = conf.low, xmax = conf.high, y = method)) +\n  geom_pointrange() +\n  scale_x_continuous(\"parameter space\", expand = expansion(mult = 0.2)) +\n  scale_fill_manual(values = palette) +\n  scale_y_discrete(expand = expansion(mult = 5)) +\n  facet_wrap(~ term, scales = \"free_x\") + plot_aes"
  },
  {
    "objectID": "posts/Lab-8/Bayes_Lab_1.html#exploring-model-results",
    "href": "posts/Lab-8/Bayes_Lab_1.html#exploring-model-results",
    "title": "Lab-8: Bayes",
    "section": "Exploring model results",
    "text": "Exploring model results\nWe can extract the posterior draws from our Bayesian models with the as_draws_df() function.\n\nas_draws_df(fit1.b)\n\n# A draws_df: 1000 iterations, 4 chains, and 6 variables\n   b_Intercept b_body_mass_g sigma Intercept lprior lp__\n1           38        0.0030   2.8        49   -4.2 -172\n2           39        0.0025   2.6        49   -4.2 -175\n3           34        0.0039   2.6        49   -4.2 -172\n4           31        0.0046   2.7        49   -4.3 -172\n5           28        0.0054   2.7        49   -4.3 -172\n6           34        0.0040   3.0        49   -4.3 -171\n7           35        0.0038   3.3        49   -4.4 -172\n8           29        0.0052   2.7        48   -4.3 -172\n9           35        0.0038   2.9        49   -4.3 -171\n10          37        0.0032   2.8        49   -4.3 -172\n# ... with 3990 more draws\n# ... hidden reserved variables {'.chain', '.iteration', '.draw'}\n\n\nNote the meta data. We can get a sense of the full posterior distributions of the \\(\\beta\\) parameters with plots.\n\n# wrangle\nas_draws_df(fit1.b) %&gt;% \n  pivot_longer(starts_with(\"b_\")) %&gt;% \n  \n  # plot!\n  ggplot(aes(x = value)) + \n  # geom_density(fill = \"grey20\") +\n  geom_histogram(bins = 40) +\n  facet_wrap(~ name, scales = \"free\") + plot_aes\n\n\n\n\n\n\n\n\nWe might summarize those posterior distributions with basic descriptive statistics, like their means, SD‚Äôs, and inner 95-percentile range.\n\nas_draws_df(fit1.b) %&gt;% \n  pivot_longer(starts_with(\"b_\")) %&gt;% \n  group_by(name) %&gt;% \n  summarise(mean = mean(value),\n            sd = sd(value),\n            ll = quantile(value, probs = 0.025),\n            ul = quantile(value, probs = 0.975)) |&gt; \n  DT::datatable()\n\n\n\n\n\nNotice how these values match up exactly with those from fixef().\n\nfixef(fit1.b)\n\n                Estimate    Est.Error         Q2.5        Q97.5\nIntercept   32.171601696 3.4599647320 25.197783898 38.767885598\nbody_mass_g  0.004464182 0.0009227771  0.002668377  0.006304322\n\n\nThus,\n\nThe Bayesian posterior mean is analogous to the frequentist point estimate.\nThe Bayesian posterior SD is analogous to the frequentist standard error.\nThe Bayesian posterior percentile-based 95% (credible) interval is analogous to the frequentist 95% confidence interval.\n\nThese are not exactly the same, mind you. But they serve similar functions.\nWe can also get a sense of these distributions with the plot() function.\n\nplot(fit1.b)\n\n\n\n\n\n\n\n\nIgnore the trace plots on the right for a moment. And let‚Äôs consider the pairs() plot.\n\npairs(fit1.b)\n\n\n\n\n\n\n\n# we can adjust some of the settings with the off_diag_args argument\npairs(fit1.b, off_diag_args = list(size = 1/4, alpha = 1/4))\n\n\n\n\n\n\n\n\n\nQuestion 2.1 : In the parlance of Probability, do you know what is the term by which the distributions in the diagonal of the above plot are known as? And the distributions in the off-diagonal?\n\nThe distributions in the diagonal are known as the marginal distributions and the distributions in the off-diagonal are known as the joint distributions.\n\nNotice how the two \\(\\beta\\) parameters seem to have a strong negative correlation. We can quantify that correlation with the vcov() function.\n\nvcov(fit1.b)                      # variance/covariance metric\n\n               Intercept      body_mass_g\nIntercept   11.971355947 -0.0031762934154\nbody_mass_g -0.003176293  0.0000008515175\n\nvcov(fit1.b, correlation = TRUE)  # correlation metric\n\n             Intercept body_mass_g\nIntercept    1.0000000  -0.9948375\nbody_mass_g -0.9948375   1.0000000\n\n\nThis correlation/covariance among the parameters is not unique to Bayesian models. Here‚Äôs the vcov() output for the OLS model.\n\nvcov(fit1.ols)  # variance/covariance metric\n\n             (Intercept)      body_mass_g\n(Intercept) 11.856743861 -0.0031432947972\nbody_mass_g -0.003143295  0.0000008420092\n\n\nI‚Äôm not aware of an easy way to get that output in a correlation metric for our OLS model. Here‚Äôs how to compute the correlation by hand.\n\ncov_xy &lt;- vcov(fit1.ols)[2, 1]  # covariance between the intercept and slope\nvar_x  &lt;- vcov(fit1.ols)[1, 1]  # variance for the intercept\nvar_y  &lt;- vcov(fit1.ols)[2, 2]  # variance for the slope\n\n# convert the covariance into a correlation\ncov_xy / (sqrt(var_x) * sqrt(var_y))\n\n[1] -0.9948188\n\n\nThat code follows the definition of a covariance, which can be expressed as\n\\[\n\\text{Cov}(x, y) = \\rho \\sigma_x \\sigma_y,\n\\]\nwhere \\(\\sigma_x\\) is the standard deviation for x, \\(\\sigma_y\\) is the standard deviation for y, and \\(\\rho\\) is their correlation. And thus, you can convert a covariance into a correlation with the formula\n\\[\n\\rho = \\frac{\\sigma_{xy}}{\\sigma_x \\sigma_y},\n\\]\nwhere \\(\\sigma_{xy}\\) is the covariance of x and y."
  },
  {
    "objectID": "posts/Lab-8/Bayes_Lab_1.html#draws",
    "href": "posts/Lab-8/Bayes_Lab_1.html#draws",
    "title": "Lab-8: Bayes",
    "section": "Draws",
    "text": "Draws\nLet‚Äôs save the as_draws_df() output for our model as an object called draws.\n\ndraws &lt;- as_draws_df(fit1.b)\nglimpse(draws)\n\nRows: 4,000\nColumns: 9\n$ b_Intercept   &lt;dbl&gt; 37.92621, 39.29808, 34.15103, 31.39905, 28.47337, 34.143‚Ä¶\n$ b_body_mass_g &lt;dbl&gt; 0.002966134, 0.002510550, 0.003885012, 0.004581258, 0.00‚Ä¶\n$ sigma         &lt;dbl&gt; 2.761649, 2.573020, 2.613326, 2.694444, 2.727092, 3.0373‚Ä¶\n$ Intercept     &lt;dbl&gt; 48.99905, 48.67019, 48.65413, 48.50129, 48.67069, 48.982‚Ä¶\n$ lprior        &lt;dbl&gt; -4.241599, -4.220093, -4.230620, -4.263561, -4.255627, -‚Ä¶\n$ lp__          &lt;dbl&gt; -172.4217, -174.5516, -171.7488, -171.5667, -171.6560, -‚Ä¶\n$ .chain        &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,‚Ä¶\n$ .iteration    &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 1‚Ä¶\n$ .draw         &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 1‚Ä¶\n\n\nFor each parameter in the model, we have 4,000 draws from the posterior.\n\nQuestion 2.2: How does this concept relate to representing uncertainty? Can you anticipate how predictions are made based upon these 4000 draws and the linear regression formula?\n\nThe 4000 draws represent the uncertainty in the model. The predictions are made by using the 4000 draws to calculate the predicted values for each observation in the data set. The linear regression formula is used to calculate the predicted values for each observation in the data set.\n\n\\[\\widehat{\\text{bill_length_mm}}_i = \\beta_0 + \\beta_1 \\text{body_mass_g}_i.\\]\nLet‚Äôs break the 4000 draws down with our draws object.\n\n# adjust the parameter names \ndraws &lt;- draws %&gt;% \n  mutate(beta0 = b_Intercept,\n         beta1 = b_body_mass_g)\n\n# Note: go through this one line at a time\ndraws %&gt;% \n  select(.draw, beta0, beta1) %&gt;% \n  mutate(body_mass_g = mean(chinstrap$body_mass_g)) %&gt;% \n  mutate(y_hat = beta0 + beta1 * body_mass_g) %&gt;% \n  \n  ggplot(aes(x = y_hat)) +\n  geom_density()+ \n  labs(title = \"Bayesians have posterior distributions\",\n       x = expression(hat(italic(y))*'|'*italic(x)==3733.1)) +\n  coord_cartesian(xlim = c(47, 51)) + plot_aes\n\n\n\n\n\n\n\n\nHere‚Äôs what that is for the OLS model.\n\npredict(fit1.ols,\n        newdata = tibble(body_mass_g = mean(chinstrap$body_mass_g)),\n        interval = \"confidence\") %&gt;% \n  data.frame() %&gt;% \n  \n  ggplot(aes(x = fit, xmin = lwr, xmax = upr, y = 0)) +\n  geom_pointrange() +\n  scale_y_continuous(NULL, breaks = NULL) +\n  labs(title = \"Frequentists have point estmates and 95% CI's\",\n       x = expression(hat(italic(y))*'|'*italic(x)==3733.1)) +\n  coord_cartesian(xlim = c(47, 51)) + plot_aes\n\n\n\n\n\n\n\n\nAnother handy way to present a Bayesian posterior is as a density with a point-interval summary below.\n\nlibrary(ggdist) #for stat_half_eye and mean_qi\ndraws %&gt;% \n  mutate(body_mass_g = mean(chinstrap$body_mass_g)) %&gt;% \n  mutate(y_hat = beta0 + beta1 * body_mass_g) %&gt;% \n  \n  ggplot(aes(x = y_hat)) +\n  stat_halfeye(point_interval = mean_qi, .width = .95) +\n  # scale_y_continuous(NULL, breaks = NULL) +\n  labs(title = \"Bayesians have posterior distributions\",\n       x = expression(hat(italic(y))*'|'*italic(x)==3733.1)) +\n  coord_cartesian(xlim = c(47, 51)) + plot_aes\n\n\n\n\n\n\n\n\nThe dot at the base of the plot is the posterior mean, and the horizontal line marks the 95% percentile-based interval. If you‚Äôd like to mark the median instead, set point_interval = median_qi. If you‚Äôre like a different kind of horizontal interval, adjust the .width argument.\n\ndraws %&gt;% \n  mutate(body_mass_g = mean(chinstrap$body_mass_g)) %&gt;% \n  mutate(y_hat = beta0 + beta1 * body_mass_g) %&gt;% \n  \n  ggplot(aes(x = y_hat)) +\n  # note the changes to this line\n  stat_halfeye(point_interval = median_qi, .width = c(.5, .99)) +\n  scale_y_continuous(NULL, breaks = NULL) +\n  labs(title = \"Bayesians have posterior distributions\",\n       subtitle = \"The dot marks the median.\\nThe thicker line marks the 50% interval, and\\nthe thinner line marks the 99% interval.\",\n       x = expression(hat(italic(y))*'|'*italic(x)==3733.1)) +\n  coord_cartesian(xlim = c(47, 51)) + plot_aes"
  },
  {
    "objectID": "posts/Lab-8/Bayes_Lab_1.html#about-those-means-sds-and-intervals.",
    "href": "posts/Lab-8/Bayes_Lab_1.html#about-those-means-sds-and-intervals.",
    "title": "Lab-8: Bayes",
    "section": "About those means, SD‚Äôs, and intervals.",
    "text": "About those means, SD‚Äôs, and intervals.\nYou can describe a Bayesian posterior in a lot of different ways. Earlier we said the posterior mean is the Bayesian point estimate. This isn‚Äôt strictly true. Means are very popular, but you can summarize a posterior by its mean, median, or mode.\nLet‚Äôs see what this looks like in practice. First, we compute and save our statistics for each of our model parameters.\n\npoints &lt;- draws %&gt;% \n  rename(`beta[0]` = beta0,\n         `beta[1]` = beta1) %&gt;% \n  pivot_longer(cols = c(`beta[0]`, `beta[1]`, sigma), \n               names_to = \"parameter\") %&gt;% \n  group_by(parameter) %&gt;% \n  summarise(mean = mean(value),\n            median = median(value),\n            mode = Mode(value)) %&gt;% \n  pivot_longer(starts_with(\"m\"), names_to = \"statistic\")\n\n# what?\npoints\n\n# A tibble: 9 √ó 3\n  parameter statistic    value\n  &lt;chr&gt;     &lt;chr&gt;        &lt;dbl&gt;\n1 beta[0]   mean      32.2    \n2 beta[0]   median    32.2    \n3 beta[0]   mode      32.4    \n4 beta[1]   mean       0.00446\n5 beta[1]   median     0.00446\n6 beta[1]   mode       0.00455\n7 sigma     mean       2.92   \n8 sigma     median     2.90   \n9 sigma     mode       2.85   \n\n\nNow plot.\n\ndraws %&gt;% \n  rename(`beta[0]` = beta0,\n         `beta[1]` = beta1) %&gt;% \n  pivot_longer(cols = c(`beta[0]`, `beta[1]`, sigma), \n               names_to = \"parameter\") %&gt;% \n  \n  ggplot(aes(x = value)) +\n  geom_density() +\n  geom_vline(data = points,\n             aes(xintercept = value, color = statistic),\n             size = 3/4) +\n  scale_color_viridis_d(option = \"A\", end = .8) +\n  scale_y_continuous(NULL, breaks = NULL) +\n  xlab(\"parameter space\") +\n  facet_wrap(~ parameter, labeller = label_parsed, scales = \"free\", ncol = 1) +\n  theme(strip.text = element_text(size = 14)) + plot_aes\n\n\n\n\n\n\n\n\n\nQuestion 2.3: Discuss the skew in \\(\\sigma\\).Why it might arise, etc.?\n\nThe mean is the brms default summary, and McElreath (2015, 2020) defaulted to the mean in his texts.\nThe median is also available for many brms functions, and it‚Äôs what Gelman et al (2020) recommend.\nThe mode can be attractive for very skewed distributions, and it‚Äôs what Kruschke (2015) used in his text.\n\nWith many brms functions, you can request the median by setting robust = TRUE. For example:\n\nfixef(fit1.b)                 # means\n\n                Estimate    Est.Error         Q2.5        Q97.5\nIntercept   32.171601696 3.4599647320 25.197783898 38.767885598\nbody_mass_g  0.004464182 0.0009227771  0.002668377  0.006304322\n\nfixef(fit1.b, robust = TRUE)  # medians\n\n                Estimate    Est.Error         Q2.5        Q97.5\nIntercept   32.207289570 3.4510956069 25.197783898 38.767885598\nbody_mass_g  0.004459851 0.0009074036  0.002668377  0.006304322\n\n\n\n\nQuestion 2.4: Given the skew in sigma and what you know about summary statistics, what might be the implication of using just the mean, median, or mode of posteriors to make a prediction?\n\nSD‚Äôs and MAD SD‚Äôs.\nEarlier we said the posterior SD is the Bayesian standard error. This isn‚Äôt strictly true. You can also use the median absolute deviation (MAD SD). If we let \\(M\\) stand for the median of some variable \\(y\\), which varies across \\(i\\) cases, we can define the MAD SD as\n\\[\\textit{MAD SD} = 1.4826 \\times \\operatorname{median}_{i = 1}^n |y_i - M|,\\]\nwhere \\(1.4826\\) is a constant that scales the MAD SD into a standard-deviation metric. Here‚Äôs what this looks like in practice.\n\n# go through this line by line\ndraws %&gt;% \n  select(beta0) %&gt;% \n  mutate(mdn = median(beta0)) %&gt;% \n  mutate(`|yi - mdn|` = abs(beta0 - mdn)) %&gt;% \n  summarise(MAD_SD = 1.4826 * median(`|yi - mdn|`))\n\n# A tibble: 1 √ó 1\n  MAD_SD\n   &lt;dbl&gt;\n1   3.45\n\n\nBase R also has a mad() function.\n\n?mad\n\nHelp on topic 'mad' was found in the following packages:\n\n  Package               Library\n  posterior             /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library\n  stats                 /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library\n\n\nUsing the first match ...\n\ndraws %&gt;% \n  summarise(MAD_SD = mad(beta0))\n\n# A tibble: 1 √ó 1\n  MAD_SD\n   &lt;dbl&gt;\n1   3.45\n\n\nYou can request the MAD SD from many brms functions by setting robust = TRUE.\n\nfixef(fit1.b)                 # SD\n\n                Estimate    Est.Error         Q2.5        Q97.5\nIntercept   32.171601696 3.4599647320 25.197783898 38.767885598\nbody_mass_g  0.004464182 0.0009227771  0.002668377  0.006304322\n\nfixef(fit1.b, robust = TRUE)  # MAD SD\n\n                Estimate    Est.Error         Q2.5        Q97.5\nIntercept   32.207289570 3.4510956069 25.197783898 38.767885598\nbody_mass_g  0.004459851 0.0009074036  0.002668377  0.006304322\n\n\n\nTo my eye, many authors (e.g., Kruschke, McElreath) just use the SD.\nGelman et al (see Section 5.3) recommend the MAD SD.\n\n\n\nBayesian intervals.\nBayesians describe the widths of their posteriors with intervals. I‚Äôve seen these variously described as confidence intervals, credible intervals, probability intervals, and even uncertainty intervals. My recommendation is just pick a term, and clearly tell your audience what you mean (e.g., at the end of a Method section in a journal article).\nTo my eye, the most popular interval is a 95% percentile-based interval. 95% is conventional, perhaps due to the popularity of the 95% frequentist confidence interval, which is related to the 0.05 alpha level used for the conventional \\(p\\)-value cutoff. However, you can use other percentiles. Some common alternatives are 99%, 89%, 80%, and 50%.\nAlso, Bayesian intervals aren‚Äôt always percentile based. An alternative is the highest posterior density interval (HPDI), which has mathematical properties some find desirable.\nbrms only supports percentile-based intervals, but it does allow for a variety of different ranges via the prob argument. For example, here‚Äôs how to request 80% intervals in summary().\n\nsummary(fit1.b, prob = .80)\n\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: bill_length_mm ~ 1 + body_mass_g \n   Data: chinstrap (Number of observations: 68) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nRegression Coefficients:\n            Estimate Est.Error l-80% CI u-80% CI Rhat Bulk_ESS Tail_ESS\nIntercept      32.17      3.46    27.71    36.76 1.00     5027     2952\nbody_mass_g     0.00      0.00     0.00     0.01 1.00     5128     2545\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-80% CI u-80% CI Rhat Bulk_ESS Tail_ESS\nsigma     2.92      0.27     2.59     3.26 1.00     1860     1673\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\nRegarding interval widths:\n\n95% Intervals are widely used.\nMcElreat likes 89% intervals, and uses them as a default in his rethinking package.\nSome of the bayesplot, ggdist, and tidybayes functions return 80% intervals.\nSome of the ggdist, and tidybayes functions return 66% or 50% intervals.\nI‚Äôve heard Gelman report his fondness for 50% intervals on his blog (https://statmodeling.stat.columbia.edu/2016/11/05/why-i-prefer-50-to-95-intervals/).\n\nRegarding interval types:\n\nPercentile-based intervals are widely used in the Stan ecosystem, and are supported in texts like Gelman et al.\nKruschke has consistently advocates for HPDI‚Äôs in his articles, and in his text.\n\n\n\n\nPosterior summaries with tidybayes.\nMatthew Kay‚Äôs tidybayes package (https://mjskay.github.io/tidybayes/) offers an array of convenience functions for summarizing posterior distributions with points and intervals. See the Point summaries and intervals section of Kay‚Äôs Extracting and visualizing tidy draws from brms models vignette (https://mjskay.github.io/tidybayes/articles/tidy-brms.html#point-summaries-and-intervals) for a detailed breakdown. In short, the family of functions use the naming scheme [median|mean|mode]_[qi|hdi]. Here are a few examples.\n\ndraws %&gt;% mean_qi(beta0)                        # mean and 95% percentile interval\n\n# A tibble: 1 √ó 6\n  beta0 .lower .upper .width .point .interval\n  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;    \n1  32.2   25.2   38.8   0.95 mean   qi       \n\ndraws %&gt;% median_qi(beta0, .width = .80)        # median and 80% percentile interval\n\n# A tibble: 1 √ó 6\n  beta0 .lower .upper .width .point .interval\n  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;    \n1  32.2   27.7   36.8    0.8 median qi       \n\ndraws %&gt;% mode_hdi(beta0, .width = c(.5, .95))  # mode, with 95 and 50% HPDI's\n\n# A tibble: 2 √ó 6\n  beta0 .lower .upper .width .point .interval\n  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;    \n1  32.4   30.5   35.1   0.5  mode   hdi      \n2  32.4   25.1   38.6   0.95 mode   hdi      \n\n\nAs an aside, the Mode() function we used a while back was also from tidybayes.\n\n\nSpaghetti plots.\nRemember how we said the draw was something like 4,000 separate equations for our Bayesian model? Let‚Äôs see that again.\n\ndraws %&gt;% \n  select(.draw, beta0, beta1) %&gt;% \n  mutate(body_mass_g = mean(chinstrap$body_mass_g)) %&gt;% \n  # here's the equation\n  mutate(y_hat = beta0 + beta1 * body_mass_g) %&gt;% \n  # subset the top 6\n  head()\n\n# A tibble: 6 √ó 5\n  .draw beta0   beta1 body_mass_g y_hat\n  &lt;int&gt; &lt;dbl&gt;   &lt;dbl&gt;       &lt;dbl&gt; &lt;dbl&gt;\n1     1  37.9 0.00297       3733.  49.0\n2     2  39.3 0.00251       3733.  48.7\n3     3  34.2 0.00389       3733.  48.7\n4     4  31.4 0.00458       3733.  48.5\n5     5  28.5 0.00541       3733.  48.7\n6     6  34.1 0.00398       3733.  49.0\n\n\nOne way we might emphasize the 4,000 equations is with a spaghetti plot. When we display the fitted line for bill_length_mm over the range of body_mass_g values, we can display a single line for each posterior draw. Here‚Äôs what that can look like.\n\nrange(chinstrap$body_mass_g)\n\n[1] 2700 4800\n\n# Note: go through this one line at a time\ndraws %&gt;% \n  select(.draw, beta0, beta1) %&gt;% \n  expand_grid(body_mass_g = range(chinstrap$body_mass_g)) %&gt;% \n  mutate(y_hat = beta0 + beta1 * body_mass_g) %&gt;% \n  \n  # plot!\n  ggplot(aes(x = body_mass_g, y = y_hat, group = .draw)) +\n  geom_line(linewidth = 1/10, alpha = 1/10) + plot_aes\n\n\n\n\n\n\n\n\nIt might be easier to see what‚Äôs going on with a random subset of, say, 10 of the posterior draws.\n\nset.seed(10)\n\ndraws %&gt;% \n  # take a random sample of 10 rows\n  slice_sample(n = 10) %&gt;% \n  select(.draw, beta0, beta1) %&gt;% \n  expand_grid(body_mass_g = range(chinstrap$body_mass_g)) %&gt;% \n  mutate(y_hat = beta0 + beta1 * body_mass_g) %&gt;% \n  \n  ggplot(aes(x = body_mass_g, y = y_hat, group = .draw)) +\n  geom_line(linewidth = 1/2, alpha = 1/2) + plot_aes\n\n\n\n\n\n\n\n\nWhile we‚Äôre at it, let‚Äôs take 20 draws and do a little color coding.\n\nset.seed(20)\n\ndraws %&gt;% \n  # take a random sample of 20 rows\n  slice_sample(n = 20) %&gt;% \n  select(.draw, beta0, beta1) %&gt;% \n  expand_grid(body_mass_g = range(chinstrap$body_mass_g)) %&gt;% \n  mutate(y_hat = beta0 + beta1 * body_mass_g) %&gt;% \n  \n  ggplot(aes(x = body_mass_g, y = y_hat, group = .draw, color = beta0)) +\n  geom_line() +\n  scale_color_viridis_c(expression(beta[0]~(the~intercept)), end = .9) + plot_aes\n\n\n\n\n\n\n\n\nDo you remember how we said \\(\\beta_0\\) and \\(\\beta_1\\) had a strong negative correlation? Notice how the lines computed by lower \\(\\beta_0\\) values also tend to have higher slopes. This will happen all the time with conventional regression models.\n\n\nQuestion 2.5: We have done all this without yet specifying a prior. What do you think is going on?\n\nThe default prior is being used. The default prior is a weakly informative prior that is centered around 0."
  },
  {
    "objectID": "posts/Lab-8/Bayes_Lab_1.html#questionexercise",
    "href": "posts/Lab-8/Bayes_Lab_1.html#questionexercise",
    "title": "Lab-8: Bayes",
    "section": "Question/Exercise:",
    "text": "Question/Exercise:\nIn the last part, we made a subset of the penguins data called gentoo, which was only the cases for which species == \"Gentoo\". Do that again and refit the Bayesian model to those data. Can you then remake some of the figures in this file with the new version of the model?\n\nmodel_path &lt;- file.path(\"~/Library/CloudStorage/GoogleDrive-sm9518@princeton.edu/My Drive/Classes/Stats-blog/posts/Lab-8/models/fit2.rds\")\n\nif (!file.exists(model_path)) {\n fit2 &lt;- brm(\n  data = gentoo,\n  bill_length_mm ~ 1 + body_mass_g\n)\n  saveRDS(fit1.b, model_path)\n} else {\n  # If the RDS file already exists, load the data from it\n  fit2 &lt;- readRDS(model_path)\n}\n\n\ndraws &lt;- as_draws_df(fit2)\ndraws &lt;- draws %&gt;% \n  mutate(beta0 = b_Intercept,\n         beta1 = b_body_mass_g)\n\ndraws %&gt;% \n  rename(`beta[0]` = beta0,\n         `beta[1]` = beta1) %&gt;% \n  pivot_longer(cols = c(`beta[0]`, `beta[1]`, sigma), \n               names_to = \"parameter\") %&gt;% \n  \n  ggplot(aes(x = value)) +\n  geom_density() +\n  geom_vline(data = points,\n             aes(xintercept = value, color = statistic),\n             size = 3/4) +\n  scale_color_viridis_d(option = \"A\", end = .8) +\n  scale_y_continuous(NULL, breaks = NULL) +\n  xlab(\"parameter space\") +\n  facet_wrap(~ parameter, labeller = label_parsed, scales = \"free\", ncol = 1) +\n  theme(strip.text = element_text(size = 14)) + plot_aes"
  },
  {
    "objectID": "posts/Lab-8/Bayes_Lab_1.html#references",
    "href": "posts/Lab-8/Bayes_Lab_1.html#references",
    "title": "Lab-8: Bayes",
    "section": "References",
    "text": "References\nGelman, A., Hill, J., & Vehtari, A. (2020). Regression and other stories. Cambridge University Press. https://doi.org/10.1017/9781139161879\nKruschke, J. K. (2015). Doing Bayesian data analysis: A tutorial with R, JAGS, and Stan. Academic Press. https://sites.google.com/site/doingbayesiandataanalysis/\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (Second Edition). CRC Press. https://xcelab.net/rm/statistical-rethinking/\nMcElreath, R. (2015). Statistical rethinking: A Bayesian course with examples in R and Stan. CRC press. https://xcelab.net/rm/statistical-rethinking/"
  },
  {
    "objectID": "posts/Lab-8/Bayes_Lab_1.html#session-information",
    "href": "posts/Lab-8/Bayes_Lab_1.html#session-information",
    "title": "Lab-8: Bayes",
    "section": "Session information",
    "text": "Session information\n\nsessionInfo()\n\nR version 4.4.1 (2024-06-14)\nPlatform: aarch64-apple-darwin20\nRunning under: macOS 15.3.2\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: America/New_York\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] ggdist_3.3.2        broom.mixed_0.2.9.5 broom_1.0.7        \n [4] brms_2.21.0         Rcpp_1.0.13         ggside_0.3.1       \n [7] lubridate_1.9.3     forcats_1.0.0       stringr_1.5.1      \n[10] dplyr_1.1.4         purrr_1.0.4         readr_2.1.5        \n[13] tidyr_1.3.1         tibble_3.2.1        ggplot2_3.5.1      \n[16] tidyverse_2.0.0     pacman_0.5.1       \n\nloaded via a namespace (and not attached):\n [1] tidyselect_1.2.1     viridisLite_0.4.2    farver_2.1.2        \n [4] loo_2.8.0            fastmap_1.2.0        tensorA_0.36.2.1    \n [7] digest_0.6.37        timechange_0.3.0     estimability_1.5.1  \n[10] lifecycle_1.0.4      StanHeaders_2.32.10  magrittr_2.0.3      \n[13] posterior_1.6.0      compiler_4.4.1       sass_0.4.9          \n[16] rlang_1.1.5          tools_4.4.1          utf8_1.2.4          \n[19] yaml_2.3.10          knitr_1.48           labeling_0.4.3      \n[22] bridgesampling_1.1-2 htmlwidgets_1.6.4    pkgbuild_1.4.4      \n[25] curl_5.2.2           plyr_1.8.9           abind_1.4-5         \n[28] withr_3.0.1          grid_4.4.1           stats4_4.4.1        \n[31] fansi_1.0.6          xtable_1.8-4         colorspace_2.1-1    \n[34] future_1.34.0        inline_0.3.19        emmeans_1.10.7      \n[37] globals_0.16.3       scales_1.3.0         cli_3.6.4           \n[40] mvtnorm_1.3-1        rmarkdown_2.28       generics_0.1.3      \n[43] RcppParallel_5.1.9   rstudioapi_0.17.1    reshape2_1.4.4      \n[46] tzdb_0.4.0           cachem_1.1.0         rstan_2.32.6        \n[49] splines_4.4.1        bayesplot_1.11.1     parallel_4.4.1      \n[52] matrixStats_1.4.1    vctrs_0.6.5          V8_6.0.1            \n[55] Matrix_1.7-0         jsonlite_1.8.9       hms_1.1.3           \n[58] listenv_0.9.1        crosstalk_1.2.1      jquerylib_0.1.4     \n[61] glue_1.8.0           parallelly_1.38.0    codetools_0.2-20    \n[64] DT_0.33              distributional_0.5.0 stringi_1.8.4       \n[67] gtable_0.3.5         QuickJSR_1.3.1       palmerpenguins_0.1.1\n[70] munsell_0.5.1        pillar_1.9.0         furrr_0.3.1         \n[73] htmltools_0.5.8.1    Brobdingnag_1.2-9    R6_2.5.1            \n[76] evaluate_1.0.0       lattice_0.22-6       backports_1.5.0     \n[79] bslib_0.8.0          rstantools_2.4.0     coda_0.19-4.1       \n[82] gridExtra_2.3        nlme_3.1-164         checkmate_2.3.2     \n[85] mgcv_1.9-1           xfun_0.49            pkgconfig_2.0.3"
  },
  {
    "objectID": "posts/Lab-6/MLM_intro_questions.html",
    "href": "posts/Lab-6/MLM_intro_questions.html",
    "title": "Intro to MLM Exercise/Walkthrough",
    "section": "",
    "text": "New Packages!\n\n\n\n\n\nThese are the main packages we‚Äôre going to use in this block. It might make sense to install them now if you do not have them already\n\ntidyverse : for organising data\n\nlme4 : for fitting generalised linear mixed effects models\nbroom.mixed : tidying methods for mixed models\neffects : for tabulating and graphing effects in linear models\nlmerTest: for quick p-values from mixed models\nparameters: various inferential methods for mixed models"
  },
  {
    "objectID": "posts/Lab-6/MLM_intro_questions.html#footnotes",
    "href": "posts/Lab-6/MLM_intro_questions.html#footnotes",
    "title": "Intro to MLM Exercise/Walkthrough",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nImage sources:http://tophatsasquatch.com/2012-tmnt-classics-action-figures/https://www.dezeen.com/2016/02/01/barbie-dolls-fashionista-collection-mattel-new-body-types/https://www.wish.com/product/5da9bc544ab36314cfa7f70chttps://www.worldwideshoppingmall.co.uk/toys/jumbo-farm-animals.asphttps://www.overstock.com/Sports-Toys/NJ-Croce-Scooby-Doo-5pc.-Bendable-Figure-Set-with-Scooby-Doo-Shaggy-Daphne-Velma-and-Fred/28534567/product.htmlhttps://tvtropes.org/pmwiki/pmwiki.php/Toys/Furbyhttps://www.fun.com/toy-story-4-figure-4-pack.htmlhttps://www.johnlewis.com/lego-minifigures-71027-series-20-pack/p5079461‚Ü©Ô∏é"
  },
  {
    "objectID": "posts/Lab-9/Bayes_Lab_2.html",
    "href": "posts/Lab-9/Bayes_Lab_2.html",
    "title": "Lab 9",
    "section": "",
    "text": "For Lab 1, you had explored the data and looked at models built via lm() and via brms(using default priors). You had also drawn posterior samples after fitting the model.\nFor Lab 2, we continue with the Palmer Penguins. And we will look more at distributions and priors.\nAgain, there will be conceptual questions to answer as you work through this example, and exercises."
  },
  {
    "objectID": "posts/Lab-9/Bayes_Lab_2.html#setup-packages-and-data",
    "href": "posts/Lab-9/Bayes_Lab_2.html#setup-packages-and-data",
    "title": "Lab 9",
    "section": "Setup: Packages and data",
    "text": "Setup: Packages and data\nWe load the primary packages.\n\nlibrary(pacman)\npacman::p_load(tidyverse,brms,tidybayes,ggdist,install = T)\n\npalette &lt;- c(\n  \"#772e25\", \"#c44536\", \"#ee9b00\", \"#197278\", \"#283d3b\", \n  \"#9CC5A1\", \"#6195C6\", \"#ADA7C9\", \"#4D4861\", \"grey50\",\n  \"#d4a373\", \"#8a5a44\", \"#4a6a74\", \"#5c80a8\", \"#a9c5a0\",\n  \"#7b9b8e\", \"#e1b16a\", \"#a69b7c\", \"#9d94c4\", \"#665c54\"\n)\n\npalette_condition = c(\"#ee9b00\", \"#c44536\",\"#005f73\", \"#283d3b\", \"#9CC5A1\", \"#6195C6\", \"#ADA7C9\", \"#4D4861\")\nplot_aes = theme_minimal() +\n  theme(\n    legend.position = \"top\",\n    legend.text = element_text(size = 12),\n    text = element_text(size = 16, family = \"Futura Medium\"),\n    axis.text = element_text(color = \"black\"),\n    axis.ticks.y = element_blank(),\n    plot.title = element_text(size = 20, hjust = 0.5) # Adjusted title size and centering\n  )\n\nWe want the same data set up as in the last lab.\n\n# load the penguins data\ndata(penguins, package = \"palmerpenguins\")\n\n# subset the data\nchinstrap &lt;- penguins %&gt;% \n  filter(species == \"Chinstrap\")\n\nglimpse(chinstrap) |&gt; \n  DT::datatable()\n\nRows: 68\nColumns: 8\n$ species           &lt;fct&gt; Chinstrap, Chinstrap, Chinstrap, Chinstrap, Chinstra‚Ä¶\n$ island            &lt;fct&gt; Dream, Dream, Dream, Dream, Dream, Dream, Dream, Dre‚Ä¶\n$ bill_length_mm    &lt;dbl&gt; 46.5, 50.0, 51.3, 45.4, 52.7, 45.2, 46.1, 51.3, 46.0‚Ä¶\n$ bill_depth_mm     &lt;dbl&gt; 17.9, 19.5, 19.2, 18.7, 19.8, 17.8, 18.2, 18.2, 18.9‚Ä¶\n$ flipper_length_mm &lt;int&gt; 192, 196, 193, 188, 197, 198, 178, 197, 195, 198, 19‚Ä¶\n$ body_mass_g       &lt;int&gt; 3500, 3900, 3650, 3525, 3725, 3950, 3250, 3750, 4150‚Ä¶\n$ sex               &lt;fct&gt; female, male, male, female, male, female, female, ma‚Ä¶\n$ year              &lt;int&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007‚Ä¶"
  },
  {
    "objectID": "posts/Lab-9/Bayes_Lab_2.html#models",
    "href": "posts/Lab-9/Bayes_Lab_2.html#models",
    "title": "Lab 9",
    "section": "Models",
    "text": "Models\nOnce again, we‚Äôll fit the model\n\\[\n\\begin{align}\n\\text{bill_length_mm}_i & = \\beta_0 + \\beta_1 \\text{body_mass_g}_i + \\epsilon_i \\\\\n\\epsilon_i & \\sim \\operatorname{Normal}(0, \\sigma_\\epsilon) ,\n\\end{align}\n\\]\nwith both lm() and brm().\n\n# OLS\nfit1.ols &lt;- lm(\n  data = chinstrap,\n  bill_length_mm ~ 1 + body_mass_g\n)\n\n\n#define model path \n\nmodel_path &lt;- file.path(\"~/Library/CloudStorage/GoogleDrive-sm9518@princeton.edu/My Drive/Classes/Stats-blog/posts/Lab-9/models/fit1b.rds\")\n\nif (!file.exists(model_path)) {\nfit1.b &lt;- brm(\n  data = chinstrap,\n  bill_length_mm ~ 1 + body_mass_g\n)\n  saveRDS(fit1.b, model_path)\n} else {\n  # If the RDS file already exists, load the data from it\n  fit1.b &lt;- readRDS(model_path)\n}"
  },
  {
    "objectID": "posts/Lab-9/Bayes_Lab_2.html#bayesians-have-many-kinds-of-distributions",
    "href": "posts/Lab-9/Bayes_Lab_2.html#bayesians-have-many-kinds-of-distributions",
    "title": "Lab 9",
    "section": "Bayesians have many kinds of distributions",
    "text": "Bayesians have many kinds of distributions\nIn Bayesian statistics, we have at least 6 distributions to keep track of. Those are:\n\nthe likelihood distributions\nthe prior parameter distribution (aka priors)\nthe prior predictive distributions\nthe posterior parameter distributions (aka posteriors)\nthe posterior-predictive distribution\n\nIn many respect, it‚Äôs distributions ‚Äòall the way down,‚Äô with Bayesians. This can be indeed be difficult to keep track of at first. But since this is true for any class of Bayesian models (not just regression), you‚Äôll hopefully get used to it.\n\n\nQUESTION 1: How would you represent these 6 distributions mathematically, using \\(P_0\\)‚Äô\\(P\\), \\(D\\), \\(|\\), and \\(\\theta\\) ?\n\n\n\n\n\n\nTip\n\n\n\nHint 1: Many of these terms were in the Bayes Rule.\n\n\n\n\nAnswer: ‚Ä¶."
  },
  {
    "objectID": "posts/Lab-9/Bayes_Lab_2.html#mathematical-representations",
    "href": "posts/Lab-9/Bayes_Lab_2.html#mathematical-representations",
    "title": "Lab 9",
    "section": "Mathematical Representations",
    "text": "Mathematical Representations\n\nLikelihood Distributions: The likelihood represents the probability of the observed data, given the model parameters: \\(\\[ P(D \\| \\theta) \\]\\)\nPrior Parameter Distribution (Priors): The prior distribution reflects our belief about the parameters before observing the data: \\(\\[ P(\\theta) \\]\\)\nPrior Predictive Distribution: This distribution represents the probability of the data before seeing any observations, based on the prior belief about the parameters: \\(\\[ P(D \\| P(\\theta)) \\]\\)\nPosterior Parameter Distribution (Posteriors): After observing the data, the posterior distribution represents our updated belief about the parameters. Using Bayes‚Äô theorem, it is given by: \\(\\[ P(\\theta \\| D) = \\frac{P(D | \\theta) P(\\theta)}{P(D)} \\]\\)\nPosterior Predictive Distribution: This distribution gives the probability of new data points, based on the posterior distribution of the parameters: \\(\\[ P(D' \\| D) = \\int P(D' \\| \\theta) P(\\theta \\| D) d\\theta \\]\\) We also have some other distributions that follow from these. For example, - the distributions of the model expectations (i.e., the predicted means)\n\n\nLikelihood distributions.\nWe are approaching Bayesian statistics from a likelihood-based perspective. That is, we situate regression models within the greater context of a likelihood function. (There are ways to do non-parametric Bayesian statistics, which don‚Äôt focus on likelihoods. We won‚Äôt get into that right now.)\nSo far, we have been using the conventional Gaussian likelihood. If we have some variable \\(y\\), we can express it as normally distributed by\n\\[\n\\operatorname{Normal}(y \\mid \\mu, \\sigma) = \\frac{1}{\\sqrt{2 \\pi \\sigma}} \\exp \\left( \\frac{1}{2} \\left( \\frac{y - \\mu}{\\sigma}\\right)^2\\right),\n\\]\nwhere \\(\\mu\\) is the mean and \\(\\sigma\\) is the standard deviation. With this likelihood,\n\n\\(\\mu \\in \\mathbb R\\)\n\nthe mean can be any real number, ranging from \\(-\\infty\\) to \\(\\infty\\)\n\n\\(\\sigma \\in \\mathbb R_{&gt; 0}\\)\n\nthe standard deviation can take on any real number greater than zero.\n\n\nIt‚Äôs also the assumption\n\n\\(y \\in \\mathbb R\\)\n\nthe focal variable \\(y\\) can be any real number, ranging from \\(-\\infty\\) to \\(\\infty\\).\n\n\nOne of the ways we wrote our model formula back in the first file was\n\\[\n\\begin{align}\n\\text{bill_length_mm}_i & \\sim \\operatorname{Normal}(\\mu_i, \\sigma) \\\\\n\\mu_i & = \\beta_0 + \\beta_1 \\text{body_mass_g}_i,\n\\end{align}\n\\]\nand further in the discussion, we updated that equation with the posterior means for our three parameters to\n\\[\n\\begin{align}\n\\text{bill_length_mm}_i & \\sim \\operatorname{Normal}(\\mu_i, 2.92) \\\\\n\\mu_i & = 32.2 + 0.004 \\text{body_mass_g}_i.\n\\end{align}\n\\]\nBefore we get into this, though, let‚Äôs back up and consider an intercept-only model of the form\n\\[\n\\begin{align}\n\\text{bill_length_mm}_i & \\sim \\operatorname{Normal}(\\mu_i, \\sigma) \\\\\n\\mu_i & = \\beta_0 ,\n\\end{align}\n\\]\nwhere there is no predictor variable. Here‚Äôs how to fit the model with brm().\n\n# Bayes\n\n\nmodel_path &lt;- file.path(\"~/Library/CloudStorage/GoogleDrive-sm9518@princeton.edu/My Drive/Classes/Stats-blog/posts/Lab-9/models/fit0b.rds\")\n\nif (!file.exists(model_path)) {\nfit0.b &lt;- brm(\n  data = chinstrap,\n  bill_length_mm ~ 1 + body_mass_g\n)\n  saveRDS(fit0.b, model_path)\n} else {\n  # If the RDS file already exists, load the data from it\n  fit0.b &lt;- readRDS(model_path)\n}\n\nLet‚Äôs look at the model summary.\n\nsummary(fit0.b)\n\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: bill_length_mm ~ 1 + body_mass_g \n   Data: chinstrap (Number of observations: 68) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nRegression Coefficients:\n            Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept      32.21      3.49    25.42    38.97 1.00     4595     2924\nbody_mass_g     0.00      0.00     0.00     0.01 1.00     4626     2720\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     2.93      0.25     2.47     3.45 1.00     2010     2020\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\nThe intercept parameter \\(\\beta_0\\) is a stand-in for \\(\\mu\\). The \\(\\sigma\\) parameter is just \\(\\sigma\\). Here they are in a plot.\n\ndraws &lt;- as_draws_df(fit0.b) \n\ndraws %&gt;% \n  rename(`beta[0]==mu` = b_Intercept) %&gt;% \n  pivot_longer(`beta[0]==mu`:sigma, names_to = \"parameter\") %&gt;% \n  \n  ggplot(aes(x = value)) +\n  stat_halfeye(.width = .95, normalize = \"panels\") +\n  scale_y_continuous(NULL, breaks = NULL) +\n  xlab(\"parameter space\") +\n  facet_wrap(~ parameter, scales = \"free\", labeller = label_parsed) + plot_aes + \n  scale_fill_manual(values = palette_condition) \n\n\n\n\n\n\n\n\nHere are the posterior means for those two parameters.\n\nmu &lt;- mean(draws$b_Intercept)\nsigma &lt;- mean(draws$sigma)\n\nmu; sigma\n\n[1] 32.21014\n\n\n[1] 2.925302\n\n\nWe can use dnorm() to compute the shape of \\(\\operatorname{Normal}(48.8, 3.4)\\).\n\ntibble(y = seq(from = 30, to = 70, by = 0.1)) %&gt;% \n  mutate(density = dnorm(x = y, mean = mu, sd = sigma)) %&gt;% \n  \n  ggplot(aes(x = y, y = density)) +\n  geom_line() +\n  xlab(\"bill_length_mm\") + plot_aes\n\n\n\n\n\n\n\n\nWe can compare this to the sample distribution of the bill_length_mm data:\n\nchinstrap %&gt;% \n  ggplot(aes(x = bill_length_mm)) +\n  geom_histogram(aes(y = after_stat(density)),\n                 binwidth = 2.5) +\n  geom_line(data = tibble(bill_length_mm = seq(from = 30, to = 70, by = 0.1)),\n            aes(y = dnorm(x = bill_length_mm, mean = mu, sd = sigma)),\n            color = \"red\") + plot_aes\n\n\n\n\n\n\n\n\nIt‚Äôs not a great fit, but not horrible either.\nNow let‚Äôs see what this means for our univariable model fit1.b. First, let‚Äôs learn about the posterior_summary() function, which we‚Äôll use to save a few posterior means.\n\nposterior_summary(fit1.b)\n\n                   Estimate    Est.Error          Q2.5         Q97.5\nb_Intercept    3.211118e+01 3.4771611651  2.552389e+01  3.902608e+01\nb_body_mass_g  4.479243e-03 0.0009256637  2.642918e-03  6.245207e-03\nsigma          2.932229e+00 0.2496554440  2.499569e+00  3.471021e+00\nIntercept      4.883259e+01 0.3406152809  4.813486e+01  4.948863e+01\nlprior        -4.300245e+00 0.0678611888 -4.450849e+00 -4.187769e+00\nlp__          -1.722437e+02 1.1939186872 -1.753094e+02 -1.708890e+02\n\nb0    &lt;- posterior_summary(fit1.b)[1, 1]\nb1    &lt;- posterior_summary(fit1.b)[2, 1]\nsigma &lt;- posterior_summary(fit1.b)[3, 1]\n\nNow we plot.\n\ncrossing(body_mass_g    = seq(from = 2500, to = 5000, length.out = 200),\n         bill_length_mm = seq(from = 35, to = 60, length.out = 200))  %&gt;% \n  mutate(density = dnorm(x = bill_length_mm, \n                         mean = b0 + b1 * body_mass_g,\n                         sd = sigma)) %&gt;% \n  \n  ggplot(aes(x = body_mass_g, y = bill_length_mm)) +\n  geom_raster(aes(fill = density),\n              interpolate = TRUE) +\n  geom_point(data = chinstrap,\n             shape = 21, color = \"white\", fill = \"black\", stroke = 1/4) +\n  scale_fill_viridis_c(option = \"A\", begin = .15, limits = c(0, NA)) +\n  coord_cartesian(xlim = range(chinstrap$body_mass_g),\n                  ylim = range(chinstrap$bill_length_mm)) + plot_aes\n\n\n\n\n\n\n\n\nOur univariable model fit1.b can be viewed as something like a 3-dimensional Gaussian hill.\n\n\nPrior distributions & Prior predictive distributions.\nLet‚Äôs hold off on this for a bit.\n\n\nParameter distributions.\nUp above, we plotted the posterior distributions for our intercept-only fit0.b model. Here they are again.\n\ndraws %&gt;% \n  rename(`beta[0]==mu` = b_Intercept) %&gt;% \n  pivot_longer(`beta[0]==mu`:sigma, names_to = \"parameter\") %&gt;% \n  \n  ggplot(aes(x = value)) +\n  stat_halfeye(.width = .99, normalize = \"panels\",\n               # customize some of the aesthetics\n               fill = \"lightskyblue1\", color = \"royalblue\", \n               point_color = \"darkorchid4\", point_size = 4, shape = 15) +\n  scale_y_continuous(NULL, breaks = NULL) +\n  labs(title = \"fit0.b\",\n       subtitle = \"This time we used 99% intervals, and got silly with the colors.\",\n       x = \"parameter space\") +\n  facet_wrap(~ parameter, scales = \"free\", labeller = label_parsed) + plot_aes\n\n\n\n\n\n\n\n\nWe might practice making a similar plot for our univariable model fit1.b.\n\nas_draws_df(fit1.b) %&gt;% \n  rename(`beta[0]` = b_Intercept,\n         `beta[1]` = b_body_mass_g) %&gt;% \n  pivot_longer(cols = c(`beta[0]`, `beta[1]`, sigma), \n               names_to = \"parameter\") %&gt;% \n  \n  ggplot(aes(x = value)) +\n  stat_histinterval(.width = .95, normalize = \"panels\") +\n  scale_y_continuous(NULL, breaks = NULL) +\n  labs(title = \"fit1.b\",\n       subtitle = \"Using good old 95% intervals, but switching to histograms\",\n       x = \"parameter space\") +\n  facet_wrap(~ parameter, scales = \"free\", labeller = label_parsed) + plot_aes\n\n\n\n\n\n\n\n\nSome authors, like John Kruschke, have a strong preference for plotting their posteriors with histograms, rather than density plots."
  },
  {
    "objectID": "posts/Lab-9/Bayes_Lab_2.html#distributions-of-the-model-expectations.",
    "href": "posts/Lab-9/Bayes_Lab_2.html#distributions-of-the-model-expectations.",
    "title": "Lab 9",
    "section": "Distributions of the model expectations.",
    "text": "Distributions of the model expectations.\nTake another look at the conditional_effects() plot from earlier.\n\nconditional_effects(fit1.b) %&gt;% \n  plot(points = TRUE)\n\n\n\n\n\n\n\n\nThe blue line is the posterior mean, for the \\(\\mu_i\\), the model-based mean for bill_length_mm, given the value for the predictor body_mass_g. The semitransparent gray ribbon marks the percentile-based interval for the conditional mean.\nWe can make a similar plot with the fitted() function. First we‚Äôll need a predictor grid, we‚Äôll call nd.\n\nnd &lt;- tibble(body_mass_g = seq(\n  from = min(chinstrap$body_mass_g),\n  to = max(chinstrap$body_mass_g),\n  length.out = 100))\n\nglimpse(nd)\n\nRows: 100\nColumns: 1\n$ body_mass_g &lt;dbl&gt; 2700.000, 2721.212, 2742.424, 2763.636, 2784.848, 2806.061‚Ä¶\n\n\nNow pump nd into the fitted() function.\n\nfitted(fit1.b, newdata = nd) %&gt;% \n  # subset the first 6 rows\n  head()\n\n     Estimate Est.Error     Q2.5    Q97.5\n[1,] 44.20513 1.0197075 42.24705 46.17349\n[2,] 44.30015 1.0012213 42.37850 46.23949\n[3,] 44.39516 0.9827796 42.51240 46.29758\n[4,] 44.49018 0.9643851 42.64621 46.35822\n[5,] 44.58519 0.9460405 42.77985 46.42049\n[6,] 44.68020 0.9277487 42.91383 46.49053\n\n\nNow plot.\n\nfitted(fit1.b, newdata = nd) %&gt;% \n  data.frame() %&gt;% \n  bind_cols(nd) %&gt;% \n  ggplot(aes(x = body_mass_g)) +\n  geom_ribbon(aes(ymin = Q2.5, ymax = Q97.5),\n              alpha = 1/3) +\n  geom_line(aes(y = Estimate)) +\n  # add the data\n  geom_point(data = chinstrap,\n             aes(y = bill_length_mm)) + plot_aes\n\n\n\n\n\n\n\n\nLook what happens if we augment the probs argument in fitted().\n\nfitted(fit1.b, \n       newdata = nd,\n       probs = c(.025, .975, .25, .75)) %&gt;% \n  data.frame() %&gt;% \n  bind_cols(nd) %&gt;% \n  ggplot(aes(x = body_mass_g)) +\n  # 95% range\n  geom_ribbon(aes(ymin = Q2.5, ymax = Q97.5),\n              alpha = 1/4) +\n  # 50% range\n  geom_ribbon(aes(ymin = Q25, ymax = Q75),\n              alpha = 1/4) +\n  geom_line(aes(y = Estimate)) +\n  geom_point(data = chinstrap,\n             aes(y = bill_length_mm)) + plot_aes\n\n\n\n\n\n\n\n\nNow look what happens if we set summary = FALSE.\n\nfitted(fit1.b, \n       newdata = nd,\n       summary = FALSE) %&gt;% \n  str()\n\n num [1:4000, 1:100] 44.4 43.9 44.1 44.5 46.7 ...\n\n\nWe get full 4,000 draw posterior distributions for each of the 100 levels of the predictor body_mass_g. Now look at what happens if we wrangle that output a little, and plot with aid from stat_lineribbon() from the ggdist package.\n\nfitted(fit1.b, \n       newdata = nd,\n       summary = F) %&gt;% \n  data.frame() %&gt;% \n  set_names(pull(nd, body_mass_g)) %&gt;% \n  mutate(draw = 1:n()) %&gt;% \n  pivot_longer(-draw) %&gt;% \n  mutate(body_mass_g = as.double(name)) %&gt;%\n  \n  ggplot(aes(x = body_mass_g, y = value)) +\n  stat_lineribbon() +\n  scale_fill_brewer() +\n  coord_cartesian(ylim = range(chinstrap$bill_length_mm)) +\n  plot_aes\n\n\n\n\n\n\n\n\nLook what happens when we request more intervals in the .width argument.\n\nfitted(fit1.b, \n       newdata = nd,\n       summary = F) %&gt;% \n  data.frame() %&gt;% \n  set_names(pull(nd, body_mass_g)) %&gt;% \n  mutate(draw = 1:n()) %&gt;% \n  pivot_longer(-draw) %&gt;% \n  mutate(body_mass_g = as.double(name)) %&gt;%\n  \n  ggplot(aes(x = body_mass_g, y = value)) +\n  # make more ribbons\n  stat_lineribbon(.width = c(.1, .2, .3, .4, .5, .6, .7, .8, .9),\n                  # remove the line\n                  linewidth = 0) +\n  scale_fill_brewer() +\n  coord_cartesian(ylim = range(chinstrap$bill_length_mm)) +\n  plot_aes\n\n\n\n\n\n\n\n\nThe conditional mean, \\(\\mu_i\\), has its own distribution. We can take this visualization approach even further to make a color gradient.\n\nfitted(fit1.b, \n       newdata = nd,\n       summary = F) %&gt;% \n  data.frame() %&gt;% \n  set_names(pull(nd, body_mass_g)) %&gt;% \n  mutate(draw = 1:n()) %&gt;% \n  pivot_longer(-draw) %&gt;% \n  mutate(body_mass_g = as.double(name)) %&gt;%\n  \n  ggplot(aes(x = body_mass_g, y = value, fill = after_stat(.width))) +\n  # make more ribbons\n  stat_lineribbon(.width = ppoints(50)) +\n  scale_fill_distiller(limits = 0:1) +\n  coord_cartesian(ylim = range(chinstrap$bill_length_mm)) +\n  plot_aes\n\n\n\n\n\n\n\n\nFor technical details on this visualization approach, go here: https://mjskay.github.io/ggdist/articles/lineribbon.html#lineribbon-gradients.\nThe ggdist package even has an experimental visualization approach that‚Äôs based on density gradients, rather than interval-width gradients. Since this is experimental, I‚Äôm not going to go into the details. But if you‚Äôre curious and adventurous, you can learn more here: https://mjskay.github.io/ggdist/articles/lineribbon.html#lineribbon-density-gradients.\n\nPosterior-predictive distributions.\nThe last section showed the posterior distributions for the model expectations (i.e., the conditional means). In the context of the Gaussian distribution, that‚Äôs \\(\\mu\\), or \\(\\mu_i\\) in the case of the univariable model fit1.b. But the whole Gaussian distribution includes \\(\\mu\\) and \\(\\sigma\\).\nThis is where the predict() function comes in. First, we compare the fitted() output to predict().\n\nfitted(fit1.b, newdata = nd) %&gt;% \n  # subset the first 6 rows\n  head()\n\n     Estimate Est.Error     Q2.5    Q97.5\n[1,] 44.20513 1.0197075 42.24705 46.17349\n[2,] 44.30015 1.0012213 42.37850 46.23949\n[3,] 44.39516 0.9827796 42.51240 46.29758\n[4,] 44.49018 0.9643851 42.64621 46.35822\n[5,] 44.58519 0.9460405 42.77985 46.42049\n[6,] 44.68020 0.9277487 42.91383 46.49053\n\npredict(fit1.b, newdata = nd) %&gt;% \n  # subset the first 6 rows\n  head()\n\n     Estimate Est.Error     Q2.5    Q97.5\n[1,] 44.17269  3.119825 38.04113 50.21742\n[2,] 44.37479  3.155426 37.96836 50.48929\n[3,] 44.40880  3.071269 38.66573 50.38529\n[4,] 44.46118  3.080088 38.24711 50.43833\n[5,] 44.61212  3.105005 38.47867 50.87375\n[6,] 44.71355  3.103898 38.64486 50.96648\n\n\nThe posterior means (Estimate) are about the same, but the SD‚Äôs (Est.Error) are much larger in the predict() output, and the widths of the 95% intervals are too. Let‚Äôs make a plot.\n\npredict(fit1.b, newdata = nd) %&gt;% \n  data.frame() %&gt;% \n  bind_cols(nd) %&gt;% \n  ggplot(aes(x = body_mass_g)) +\n  geom_ribbon(aes(ymin = Q2.5, ymax = Q97.5),\n              alpha = 1/3) +\n  geom_line(aes(y = Estimate)) +\n  # add the data\n  geom_point(data = chinstrap,\n             aes(y = bill_length_mm)) +\n  coord_cartesian(ylim = range(chinstrap$bill_length_mm)) + plot_aes\n\n\n\n\n\n\n\n\nThe gray band is the 95% interval for the entire posterior predictive distribution, not just the mean. In a good model, about 95% of the data points should be within those bands.\nDiscuss how the jagged lines have to do with the uncertainty in \\(\\sigma\\).\nIf we wanted to, we could integrate the fitted()-based conditional posterior mean, with the predict()-based posterior-predictive distribution.\n\n# save the fitted() results\nf &lt;- fitted(fit1.b, newdata = nd) %&gt;% \n  data.frame() %&gt;% \n  bind_cols(nd) \n\npredict(fit1.b, newdata = nd) %&gt;% \n  data.frame() %&gt;% \n  bind_cols(nd) %&gt;% \n  \n  ggplot(aes(x = body_mass_g)) +\n  # 95% posterior-predictive range\n  geom_ribbon(aes(ymin = Q2.5, ymax = Q97.5),\n              alpha = 1/4) +\n  # 95% conditional mean range\n  geom_ribbon(data = f,\n              aes(ymin = Q2.5, ymax = Q97.5),\n              alpha = 1/4) +\n  # posterior mean of the conditional mean\n  geom_line(data = f,\n            aes(y = Estimate)) +\n  # original data\n  geom_point(data = chinstrap,\n             aes(y = bill_length_mm)) +\n  coord_cartesian(ylim = range(chinstrap$bill_length_mm)) + plot_aes\n\n\n\n\n\n\n\n\nIt‚Äôs the posterior predictive distribution that we use to predict new data points. For example, here‚Äôs what happens if we use predict() without the newdata argument.\n\npredict(fit1.b) %&gt;% \n  head()\n\n     Estimate Est.Error     Q2.5    Q97.5\n[1,] 47.76025  2.949676 42.06117 53.56949\n[2,] 49.59141  2.932069 43.90961 55.37971\n[3,] 48.38616  2.915855 42.66543 54.07587\n[4,] 47.87208  2.971567 41.98423 53.79133\n[5,] 48.81092  2.958257 42.87191 54.60564\n[6,] 49.76666  2.921512 44.09992 55.48069\n\n\nWe get posterior predictive summaries for each of the original data points. Here‚Äôs what happens if we set summary = FALSE.\n\npredict(fit1.b, summary = FALSE) %&gt;% \n  str()\n\n num [1:4000, 1:68] 44.8 46.3 52 47.8 45.2 ...\n - attr(*, \"dimnames\")=List of 2\n  ..$ : NULL\n  ..$ : NULL\n\n\nThis time, we got 4,000 posterior draws for each. We can reduce that output with the ndraws argument.\n\npredict(fit1.b, summary = FALSE, ndraws = 6) %&gt;% \n  str()\n\n num [1:6, 1:68] 46.9 49.2 52 43.6 51.1 ...\n - attr(*, \"dimnames\")=List of 2\n  ..$ : NULL\n  ..$ : NULL\n\n\nNow wrangle and plot.\n\nset.seed(1)\n\npredict(fit1.b, summary = FALSE, ndraws = 6) %&gt;% \n  data.frame() %&gt;% \n  mutate(draw = 1:n()) %&gt;% \n  pivot_longer(-draw) %&gt;% \n  mutate(row = str_remove(name, \"X\") %&gt;% as.double()) %&gt;% \n  left_join(chinstrap %&gt;% \n              mutate(row = 1:n()),\n            by = join_by(row)) %&gt;% \n  \n  ggplot(aes(x = body_mass_g, y = value)) + \n  geom_point() +\n  ylab(\"bill_length_mm\") +\n  facet_wrap(~ draw, labeller = label_both) + plot_aes\n\n\n\n\n\n\n\n\nWith predict(), we can use the entire posterior-predictive distribution to simulate new data based on the values of our predictor variable(s). To give you a better sense of what‚Äôs happening under the hood, here‚Äôs an as_draws_df() based alternative.\n\nset.seed(1)\n\n# walk this code through\nas_draws_df(fit1.b) %&gt;% \n  rename(beta0 = b_Intercept,\n         beta1 = b_body_mass_g) %&gt;% \n  select(.draw, beta0, beta1, sigma) %&gt;% \n  slice_sample(n = 6) %&gt;% \n  expand_grid(chinstrap %&gt;% select(body_mass_g)) %&gt;% \n  mutate(bill_length_mm = rnorm(n = n(),\n                                mean = beta0 + beta1 * body_mass_g,\n                                sd = sigma)) %&gt;% \n  \n  ggplot(aes(x = body_mass_g, y = bill_length_mm)) + \n  geom_point() +\n  facet_wrap(~ .draw, labeller = label_both) + plot_aes\n\n\n\n\n\n\n\n\nNow take a look at what happens when we plot the densities of several simulated draws.\n\nset.seed(1)\n\nas_draws_df(fit1.b) %&gt;% \n  rename(beta0 = b_Intercept,\n         beta1 = b_body_mass_g) %&gt;% \n  select(.draw, beta0, beta1, sigma) %&gt;% \n  slice_sample(n = 50) %&gt;%  # increase the number of random draws\n  expand_grid(chinstrap %&gt;% select(body_mass_g)) %&gt;% \n  mutate(bill_length_mm = rnorm(n = n(),\n                                mean = beta0 + beta1 * body_mass_g,\n                                sd = sigma)) %&gt;% \n  \n  ggplot(aes(x = bill_length_mm, group = .draw)) + \n  geom_density(size = 1/4, color = alpha(\"black\", 1/2)) +\n  coord_cartesian(xlim = range(chinstrap$bill_length_mm) + c(-2, 2)) + plot_aes\n\n\n\n\n\n\n\n\nThe similarities and differences among the individual density lines give you a sense of the (un)certainty of the posterior-predictive distribution.\nThis may be a good time for you to work on Exercise 1 (see end of the document)\n#Part 4: Beginning to look at priors"
  },
  {
    "objectID": "posts/Lab-9/Bayes_Lab_2.html#bayes-rule",
    "href": "posts/Lab-9/Bayes_Lab_2.html#bayes-rule",
    "title": "Lab 9",
    "section": "Bayes‚Äô rule",
    "text": "Bayes‚Äô rule\nBayes‚Äô theorem will allow us to determine the plausibility of various values of our parameter(s) of interest, \\(\\theta\\), given the data \\(d\\), which we can express formally as \\(\\Pr(\\theta \\mid d)\\). Bayes‚Äô rule takes on the form\n\\[\n\\Pr(\\theta \\mid d) = \\frac{\\Pr(d \\mid \\theta) \\Pr(\\theta)}{\\Pr(d)}.\n\\]\nwhere\n\n\\(\\Pr(d \\mid \\theta)\\) is the likelihood,\n\\(\\Pr(\\theta)\\) is the prior,\n\\(\\Pr(d)\\) is the average probability of the data, and\n\\(\\Pr(\\theta \\mid d)\\) is the posterior.\n\nWe can express this in words as\n\\[\n\\text{Posterior} = \\frac{\\text{Probability of the data} \\times \\text{Prior}}{\\text{Average probability of the data}}.\n\\]\nThe denominator \\(\\Pr(d)\\) is a normalizing constant, and dividing by this constant is what converts the posterior \\(\\Pr(\\theta \\mid d)\\) into a probability metric."
  },
  {
    "objectID": "posts/Lab-9/Bayes_Lab_2.html#default-priors",
    "href": "posts/Lab-9/Bayes_Lab_2.html#default-priors",
    "title": "Lab 9",
    "section": "Default priors",
    "text": "Default priors\nTo set your priors with brms, the brm() function has a prior argument. If you don‚Äôt explicitly use the prior argument, brm() will use default priors. This is what happened with our fit1.b model from above. We used default priors. If you‚Äôd like to see what those priors are, execute fit1.b$prior.\n\n# maybe show str(fit1.b)\nfit1.b$prior\n\n                   prior     class        coef group resp dpar nlpar lb ub\n                  (flat)         b                                        \n                  (flat)         b body_mass_g                            \n student_t(3, 49.5, 3.6) Intercept                                        \n    student_t(3, 0, 3.6)     sigma                                    0   \n       source\n      default\n (vectorized)\n      default\n      default\n\n\nThus, a fuller expression of our model is\n\\[\n\\begin{align}\n\\text{bill_length_mm}_i & \\sim \\operatorname{Normal}(\\mu_i, \\sigma) \\\\\n\\mu_i & = \\beta_0 + \\beta_1 \\text{body_mass_g}_i \\\\\n\\beta_0 & \\sim \\operatorname{Student-t}(3, 49.5, 3.6) \\\\\n\\beta_1 & \\sim \\operatorname{Uniform}(-\\infty, \\infty) \\\\\n\\sigma & \\sim \\operatorname{Student-t}^+(3, 0, 3.6).\n\\end{align}\n\\]\nIf we had wanted to see the brm() defaults before fitting the model, we could have used the get_prior() function.\n\nget_prior(\n  data = chinstrap,\n  bill_length_mm ~ 1 + body_mass_g\n)\n\n                   prior     class        coef group resp dpar nlpar lb ub\n                  (flat)         b                                        \n                  (flat)         b body_mass_g                            \n student_t(3, 49.5, 3.6) Intercept                                        \n    student_t(3, 0, 3.6)     sigma                                    0   \n       source\n      default\n (vectorized)\n      default\n      default\n\n\nIf you recall, the normal distribution is a member of the Student-t family, where the \\(\\nu\\) (aka degrees of freedom or normality parameter) is set to \\(\\infty\\). To give you a sense, here are the densities of three members of the Student-t family, with varying \\(\\nu\\) values.\n\ncrossing(theta = seq(from = -4.5, to = 4.5, length.out = 200),\n         nu = c(3, 10, Inf)) %&gt;% \n  mutate(density = dt(x = theta, df = nu)) %&gt;% \n  \n  ggplot(aes(x = theta, y = density, color = factor(nu))) +\n  geom_line(linewidth = 1) +\n  scale_color_viridis_d(expression(nu), option = \"A\", end = .7) +\n  labs(title = \"3 members of the Student-t family\",\n       x = expression(theta)) +\n  coord_cartesian(xlim = c(-4, 4)) + plot_aes\n\n\n\n\n\n\n\n\nThus, Student-t distributions have thicker tails when they have smaller \\(\\nu\\) parameters. In the case where \\(\\nu = 3\\), the tails are pretty thick, which means they are more tolerant of more extreme values. And thus priors with small-\\(\\nu\\) parameters will be weaker (i.e., more permissive) than their Gaussian counterparts.\nWe can visualize functions from ggdist to visualize the default brm() priors. We‚Äôll start with the student_t(3, 49.5, 3.6) \\(\\beta_0\\) prior, and also take the opportunity to compare that with a slightly stronger normal(49.5, 3.6) alternative.\n\nc(prior(student_t(3, 49.5, 3.6)),\n  prior(normal(49.5, 3.6))) %&gt;% \n  parse_dist() %&gt;% \n  \n  ggplot(aes(xdist = .dist_obj, y = prior)) + \n  stat_halfeye() +\n  labs(x = expression(italic(p)(beta[0])),\n       y = NULL) +\n  coord_cartesian(xlim = c(25, 75)) + plot_aes\n\n\n\n\n\n\n\n\nSee how that \\(n = 3\\) parameter in the default prior let do much thicker tails than it‚Äôs Gaussian counterpart. We can make the same kind of plot for our default \\(\\sigma\\) prior and its half-Gaussian counterpart.\n\nc(prior(student_t(3, 0, 3.6), lb = 0),  # note our use of the lb = 0 argument\n  prior(normal(0, 3.6), lb = 0)) %&gt;% \n  parse_dist() %&gt;% \n  \n  ggplot(aes(xdist = .dist_obj, y = prior)) + \n  stat_halfeye(point_interval = mean_qi, .width = c(.90, .99)) +\n  labs(x = expression(italic(p)(sigma)),\n       y = NULL) +\n  coord_cartesian(xlim = c(0, 30)) + plot_aes\n\n\n\n\n\n\n\n\nHere‚Äôs how we could have explicitly set our priors by hand.\n\nmodel_path &lt;- file.path(\"~/Library/CloudStorage/GoogleDrive-sm9518@princeton.edu/My Drive/Classes/Stats-blog/posts/Lab-9/models/fit2b.rds\")\n\nif (!file.exists(model_path)) {\nfit2.b &lt;- brm(\n  data = chinstrap,\n  bill_length_mm ~ 1 + body_mass_g,\n  prior = prior(student_t(3, 49.5, 3.6), class = Intercept) +\n    prior(student_t(3, 0, 3.6), class = sigma, lb = 0)\n)\n  saveRDS(fit2.b, model_path)\n} else {\n  # If the RDS file already exists, load the data from it\n  fit2.b &lt;- readRDS(model_path)\n}\n\nCompare the results.\n\nsummary(fit1.b)\n\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: bill_length_mm ~ 1 + body_mass_g \n   Data: chinstrap (Number of observations: 68) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nRegression Coefficients:\n            Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept      32.11      3.48    25.52    39.03 1.00     5495     2845\nbody_mass_g     0.00      0.00     0.00     0.01 1.00     5628     2873\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     2.93      0.25     2.50     3.47 1.00     1796     1802\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\nsummary(fit2.b)\n\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: bill_length_mm ~ 1 + body_mass_g \n   Data: chinstrap (Number of observations: 68) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nRegression Coefficients:\n            Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept      32.22      3.48    25.26    38.86 1.00     4587     2988\nbody_mass_g     0.00      0.00     0.00     0.01 1.00     4608     2999\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     2.94      0.27     2.47     3.52 1.00     1894     1547\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1)."
  },
  {
    "objectID": "posts/Lab-9/Bayes_Lab_2.html#question-2-are-the-priors-the-same-what-do-you-think-is-going-on",
    "href": "posts/Lab-9/Bayes_Lab_2.html#question-2-are-the-priors-the-same-what-do-you-think-is-going-on",
    "title": "Lab 9",
    "section": "QUESTION 2 Are the priors the same? What do you think is going on?",
    "text": "QUESTION 2 Are the priors the same? What do you think is going on?\n\nAnswer: ‚Ä¶.\n\n\n\n\n\n\nThe priors are not the same. The default priors for the intercept and sigma parameters in the fit1.b model are Student-t distributions with 3 degrees of freedom, while the fit2.b model has a normal distribution for the intercept and a half-normal distribution for sigma. The choice of priors can significantly affect the posterior distributions, especially when the sample size is small or when there are outliers in the data.\n\n\n\nIf you want to learn more about the default prior settings for brms, read through the set_prior section of the brms reference manual (https://CRAN.R-project.org/package=brms/brms.pdf)."
  },
  {
    "objectID": "posts/Lab-9/Bayes_Lab_2.html#references",
    "href": "posts/Lab-9/Bayes_Lab_2.html#references",
    "title": "Lab 9",
    "section": "References",
    "text": "References\nKruschke, J. K. (2015). Doing Bayesian data analysis: A tutorial with R, JAGS, and Stan. Academic Press. https://sites.google.com/site/doingbayesiandataanalysis/"
  },
  {
    "objectID": "posts/Lab-9/Bayes_Lab_2.html#session-information",
    "href": "posts/Lab-9/Bayes_Lab_2.html#session-information",
    "title": "Lab 9",
    "section": "Session information",
    "text": "Session information"
  },
  {
    "objectID": "posts/Lab-2/index.html",
    "href": "posts/Lab-2/index.html",
    "title": "Lab 2: Logistic Regression",
    "section": "",
    "text": "Assignment requirements:\n\nIf you are using Github (recommended), make sure to commit and push your work to GitHub regularly, at least after each exercise. Write short and informative commit messages, and share the link to your assignment with me. If not, you can also send me the rmd & rendered file via Canvas.\nIn this assignment, you will not need to code from scratch. Rather, you‚Äôll need to fill in code where needed. This assignment has a logisitic regression implementation for a scenario from EDA down to model comparison (and would be useful for whenever you may encounter such a situation in the future).\nI want the assignments to begin reflecting a bit more of how you‚Äôd be doing things on your own, where you have some prior knowledge and you figure other things out (by referring to documentation, etc.) . In addition to the rmd, I also want you to submit to me notes of anything new that you learn while finishing the assignment. And any pain-points, and we‚Äôll discuss more.\n\nNote:\n\nIf you are fitting a model, display the model output in a neatly formatted table. (The gt tidy and kable functions can help!). Modelsummary also looks good(https://vincentarelbundock.github.io/modelsummary/articles/modelsummary.html)\nMake sure that your plots are clearly labeled ‚Äì for all axes, titles, etc."
  },
  {
    "objectID": "posts/Lab-2/index.html#data-general-social-survey",
    "href": "posts/Lab-2/index.html#data-general-social-survey",
    "title": "Lab 2: Logistic Regression",
    "section": "Data: General Social Survey",
    "text": "Data: General Social Survey\nThe General Social Survey (GSS) has been used to measure trends in attitudes and behaviors in American society since 1972. In addition to collecting demographic information, the survey includes questions used to gauge attitudes about government spending priorities, confidence in institutions, lifestyle, and many other topics. A full description of the survey may be found here.\nThe data for this lab are from the 2016 General Social Survey. The original data set contains 2867 observations and 935 variables. We will use and abbreviated data set that includes the following variables:\nnatmass: Respondent‚Äôs answer to the following prompt:\n‚ÄúWe are faced with many problems in this country, none of which can be solved easily or inexpensively. I‚Äôm going to name some of these problems, and for each one I‚Äôd like you to tell me whether you think we‚Äôre spending too much money on it, too little money, or about the right amount‚Ä¶are we spending too much, too little, or about the right amount on mass transportation?‚Äù\nage: Age in years.\nsex: Sex recorded as male or female\nsei10: Socioeconomic index from 0 to 100\nregion: Region where interview took place\npolviews: Respondent‚Äôs answer to the following prompt:\n‚ÄúWe hear a lot of talk these days about liberals and conservatives. I‚Äôm going to show you a seven-point scale on which the political views that people might hold are arranged from extremely liberal - point 1 - to extremely conservative - point 7. Where would you place yourself on this scale?‚Äù\nThe data are in gss2016.csv in the data folder."
  },
  {
    "objectID": "posts/Lab-2/index.html#eda",
    "href": "posts/Lab-2/index.html#eda",
    "title": "Lab 2: Logistic Regression",
    "section": "EDA",
    "text": "EDA\n\nLet‚Äôs begin by making a binary variable for respondents‚Äô views on spending on mass transportation. Create a new variable that is equal to ‚Äú1‚Äù if a respondent said spending on mass transportation is about right and ‚Äú0‚Äù otherwise. Then plot the proportion of the response variable, using informative labels for each category.\n\nFill in the ‚Äú____‚Äù below to encode the binary variable\n\ndata &lt;- read.csv(\"gss2016.csv\")\n\ndata = data |&gt; \n  mutate(mass_trans_spend_right = if_else(natmass == \"About right\", 1, 0))\n\ndata |&gt; \n  DT::datatable()\n\n\n\n\n\n\n#Get proportions\nmass_spend_summary &lt;- data %&gt;%\n  count(mass_trans_spend_right) %&gt;%\n  mutate(proportion = n / sum(n))\n\n#Look at the dataframe structure. And make sure it's in a format that you can use for plotting.\n#Change structure if needed\nmass_spend_long &lt;- mass_spend_summary %&gt;%\n  mutate(category = if_else(mass_trans_spend_right == 1, \"About right\", \"Not right\")) \n\n#Factorise for plot\nmass_spend_long$mass_trans_spend_right &lt;- as.factor(mass_spend_long$mass_trans_spend_right)\n\n#Make plot\n#Hint: geom_bar lets you make stacked bar charts\nggplot(mass_spend_summary, aes(x = factor(mass_trans_spend_right), y = proportion, fill = factor(mass_trans_spend_right))) +\n  geom_bar(stat = \"identity\") +\n  scale_fill_manual(values = c(\"#E69F00\", \"#56B4E9\"),\n                   labels = c(\"Not right\", \"About right\")) +\n  labs(title = \"Proportion of Responses on Mass Transportation Spending\",\n       x = \"Response\",\n       y = \"Proportion\",\n       fill = \"Spending View\") +\n  scale_x_discrete(labels = c(\"Not right\", \"About right\")) +\n  plot_aes\n\n\n\n\n\n\n\n\n\nRecode polviews so it is a factor with levels that are in an order that is consistent with question on the survey. Note how the categories are spelled in the data.\n\n\ndata &lt;- data %&gt;%\n  mutate(polviews = factor(polviews,\n                           levels = c(\"Extremely liberal\", \"Liberal\", \"Slightly liberal\", \n                                      \"Moderate\", \"Slghtly conservative\", \"Conservative\", \n                                      \"Extrmly conservative\"),\n                           ordered = TRUE))\n\n\nMake a plot of the distribution of polviews\n\n\n#Get proportions, format, and produce a plot like you did previously for mass_trans_spend_right\n\npol_view_summary &lt;- data %&gt;%\n  count(polviews) %&gt;%\n  mutate(proportion = n / sum(n))\n\nggplot(pol_view_summary, aes(x = polviews, y = proportion, fill = polviews)) +\n  geom_bar(stat = \"identity\") +\n  scale_fill_manual(values = palette) +  # Removed extra parenthesis\n  labs(title = \"Proportion of Responses on Mass Transportation Spending\",\n       x = \"Response\",\n       y = \"Proportion\",\n       fill = \"Spending View\") +\n  plot_aes\n\n\n\n\n\n\n\n\n\nWhich political view occurs most frequently in this data set?\n_____\n\n\nMake a plot displaying the relationship between satisfaction with mass transportation spending and political views. Use the plot to describe the relationship the two variables.\n\n\ndata |&gt; \n  group_by(polviews) |&gt; \n  summarize(prop_satisfied = mean(mass_trans_spend_right), na.rn = T) |&gt; \n  ggplot(aes(x = polviews, y = prop_satisfied, fill = polviews)) + \n  geom_bar(stat = \"identity\") +\n  scale_fill_manual(values = palette_condition) +  \n  labs(title = \"Proportion of Responses on Mass Transportation Spending\",\n       x = \"Political Views\",\n       y = \"Proportion\\nSatisfied with Spending\",\n       fill = \"Spending View\") +\n  plot_aes\n\n\n\n\n\n\n\n\nThe more conservative one‚Äôs political views are the more they think the amount of spending on mass transportation is correct.\n\nWe‚Äôd like to use age as a quantitative variable in your model; however, it is currently a character data type because some observations are coded as ‚Äú89 or older‚Äù.\n\n\nRecode age so that is a numeric variable. Note: Before making the variable numeric, you will need to replace the values ‚Äú89 or older‚Äù with a single value.\n\n\ndata = data |&gt; \n  mutate(age = if_else(age == \"89 or older\", \"89\", age)) |&gt; \n  mutate(age = as.numeric(age))\n\n\nPlot the frequency distribution of age.\n\n\ndata |&gt; \n  ggplot(aes(x = age)) + \n  geom_density(binwidth = 5, fill = \"#6195C6\") + \n  labs(title = \"Frequency Distribution of Age\",\n       x = \"Age\",\n       y = \"Frequency\") +\n  plot_aes"
  },
  {
    "objectID": "posts/Lab-2/index.html#logistic-regression",
    "href": "posts/Lab-2/index.html#logistic-regression",
    "title": "Lab 2: Logistic Regression",
    "section": "Logistic regression",
    "text": "Logistic regression\n\nLet‚Äôs start by fitting a logistic regression model with just the intercept\n\n\nintercept_only_model &lt;- glm(mass_trans_spend_right ~ 1, data = data, family = binomial(link = \"logit\"))\n\nintercept_only_model %&gt;% \n  tidy() %&gt;%\n  DT::datatable()\n\n\n\n\n\n\nInterpret the intercept in the context of the data. You can do this by converting the \\(\\beta_0\\) parameter out of the log-odds metric to the probability metric. Make sure to include the 95% confidence intervals. Then interpret the results in a sentence or two‚Äìwhat is the basic thing this probability tells us about?\n\n\nb0 &lt;- coef(intercept_only_model)[\"(Intercept)\"]\n\n# Logistic transformation of the intercept (log-odds to probability)\nb0_transformed &lt;- exp(b0) / (1 + exp(b0)) \n\n# Compute the 95% confidence intervals on the log-odds scale\nci_lower &lt;- b0 - 1.96 * 0.0393685\nci_upper &lt;- b0 + 1.96 * 0.0393685\n\n# Transform the confidence intervals into probabilities\np_lower &lt;- exp(ci_lower) / (1 + exp(ci_lower))\np_upper &lt;- exp(ci_upper) / (1 + exp(ci_upper))\n\n# Print results\ncat(\"Intercept (probability):\", round(b0_transformed, 3), \"\\n\")\n\nIntercept (probability): 0.53 \n\ncat(\"95% CI (probability): [\", round(p_lower, 3), \",\", round(p_upper, 3), \"]\\n\")\n\n95% CI (probability): [ 0.51 , 0.549 ]\n\n\n\nThe the baseline probability of supporting the policy is 53%.\n\n\nNow let‚Äôs fit a model using the demographic factors - age,sex, sei10 - to predict the odds a person is satisfied with spending on mass transportation. Make any necessary adjustments to the variables so the intercept will have a meaningful interpretation. Neatly display the model coefficients (do not display the summary output)\n\n\n#make sure that sex is a factor (i.e. to make sure R knows it's binary/categorical, and not continuous)\n\ndata &lt;- data |&gt; \n  mutate(sex = as.factor(sex)) \ndata$sex &lt;- relevel(data$sex, ref = \"Male\")\n\n\nm1 &lt;- glm(mass_trans_spend_right ~ age +sex + sei10, data = data, family = binomial(link = \"logit\"))\n\nm1 %&gt;% \n  tidy() %&gt;%\n  DT::datatable()\n\n\n\n\n\n\nConsider the relationship between sex and one‚Äôs opinion about spending on mass transportation. Interpret the coefficient of sex in terms of the logs odds and OR of being satisfied with spending on mass transportation. What are the predicted probabilities for males and females on support for spending on mass transportation? Please include the 95% CIs around each estimate.\n\n\nlist(\n  \"Model Coefficients\" = m1 %&gt;% tidy(),\n  \"Exponentiated Coefficients\" = m1 %&gt;% tidy(exponentiate = TRUE)\n) %&gt;%\n  purrr::map(DT::datatable)\n\n$`Model Coefficients`\n\n$`Exponentiated Coefficients`\n\n# Calculate confidence intervals for sexFemale coefficient\nbsex &lt;- coef(m1)[\"sexFemale\"]\nci_lower_lo &lt;- bsex - 1.96 * 0.0798020\nci_upper_lo &lt;- bsex + 1.96 * 0.0798020\n\n# Convert to odds ratios and calculate confidence intervals\nci_lower_or &lt;- exp(bsex - 1.96 * 0.0798020)\nci_upper_or &lt;- exp(bsex + 1.96 * 0.0798020)\n\n# Output the results\nlist(\n  \"CI for log-odds\" = c(ci_lower_lo, ci_upper_lo),\n  \"CI for Odds Ratio\" = c(ci_lower_or, ci_upper_or)\n)\n\n$`CI for log-odds`\n sexFemale  sexFemale \n0.09933194 0.41215578 \n\n$`CI for Odds Ratio`\nsexFemale sexFemale \n 1.104433  1.510070 \n\nemm_sex &lt;- emmeans(m1, \"sex\", type = \"response\")\n\nemm_sex \n\n sex     prob     SE  df asymp.LCL asymp.UCL\n Male   0.495 0.0147 Inf     0.467     0.524\n Female 0.559 0.0133 Inf     0.533     0.585\n\nConfidence level used: 0.95 \nIntervals are back-transformed from the logit scale \n\n\nIf you did this right, you‚Äôll find that being female (as compared to male) is associated with an increase in the log-odds of being satisfied with spending on mass transportation by 0.2557439 units (95% CI [0.09, 0.41]), holding all other variables constant. This equates to the odds of thinking the spending amount is right in females being 1.29 times the odds of thinking this in men (95% CI [1.13, 1.44]).\nThe predicted probability for females to be satisfied with spending on mass transportation is 55.9% (95% CI [53.3%, 58.5%]) and that of males is 49.5% (95% CI [46.7%, 52.4%]).\n\nVerify this.\n\nNext, consider the relationship between age and one‚Äôs opinion about spending on mass transportation. Interpret the coefficient of age in terms of the logs odds and OR of being satisfied with spending on mass transportation. Please include the 95% CIs around each estimate.\n\n\n# Get the coefficient for age\nb_age &lt;- coef(m1)[\"age\"]\n\n# Compute the 95% CI for the coefficient of age in log-odds\nage_se &lt;- summary(m1)$coefficients[\"age\", \"Std. Error\"]\nci_lower_log_odds &lt;- b_age - 1.96 * age_se\nci_upper_log_odds &lt;- b_age + 1.96 * age_se\n\n# Convert log-odds to odds ratio (OR) by applying the logistic transformation\nor_age &lt;- exp(b_age)\n\n# Compute the 95% CI for the odds ratio\nci_lower_or &lt;- exp(ci_lower_log_odds)\nci_upper_or &lt;- exp(ci_upper_log_odds)\n\n# Create a data frame with the results\nresult_df &lt;- data.frame(\n  Metric = c(\"Coefficient (log-odds)\", \"95% CI for log-odds\", \"Odds Ratio\", \"95% CI for Odds Ratio\"),\n  Estimate = c(b_age, paste(round(ci_lower_log_odds, 3), \"to\", round(ci_upper_log_odds, 3)),\n               round(or_age, 3), paste(round(ci_lower_or, 3), \"to\", round(ci_upper_or, 3)))\n)\n\n# Display the results in an interactive datatable\nDT::datatable(result_df, options = list(pageLength = 5))\n\n\n\n\n\nA one unit increase in age is associated with a decrease in the log-odds of being satisfied with spending on mass transportation by -0.0062, holding all other variables constant. The odds ratio is 0.994, which confirms the negative relationship implied by the log-odds coefficient. Specifically, for each additional unit of age, the odds of being satisfied with mass transportation spending decrease by a factor of about 0.994, or approximately 0.6% per unit increase in age, holding other factors constant.\n\nConsider the relationship between SES and one‚Äôs opinion about spending on mass transportation. Interpret the coefficient of SES in terms of the logs odds and OR of being satisfied with spending on mass transportation. Please include the 95% CIs around each estimate. √ü\n\n\nbses &lt;- coef(m1)[\"sei10\"]\n\n\n# Compute the 95% CI for the coefficient of age in log-odds\nses_se &lt;- summary(m1)$coefficients[\"sei10\", \"Std. Error\"]\nci_lower_log_odds &lt;- bses - 1.96 * age_se\nci_upper_log_odds &lt;- bses + 1.96 * age_se\n\n# Convert log-odds to odds ratio (OR) by applying the logistic transformation\nor_age &lt;- exp(bses)\n\n# Compute the 95% CI for the odds ratio\nci_lower_or &lt;- exp(ci_lower_log_odds)\nci_upper_or &lt;- exp(ci_upper_log_odds)\n\n# Create a data frame with the results\nresult_df &lt;- data.frame(\n  Metric = c(\"Coefficient (log-odds)\", \"95% CI for log-odds\", \"Odds Ratio\", \"95% CI for Odds Ratio\"),\n  Estimate = c(b_age, paste(round(ci_lower_log_odds, 3), \"to\", round(ci_upper_log_odds, 3)),\n               round(or_age, 3), paste(round(ci_lower_or, 3), \"to\", round(ci_upper_or, 3)))\n)\n\n# Display the results in an interactive datatable\nDT::datatable(result_df, options = list(pageLength = 5))\n\n\n\n\n\nA one unit increase in SES index is associated with a decrease in the log-odds of being satisfied with spending on mass transportation by 0.0062 units (95% CI [-0.0107, -0.0017]), holding all other variables constant. The odds ratio is less than 1 (0.9937922), which confirms the negative relationship implied by the log-odds coefficient. Specifically, for each additional unit of SES index, the odds of being satisfied with mass transportation spending decrease by a factor of about 0.993, or approximately 0.7% per unit increase in SES index, holding other factors constant (95% CI [0.989, 0.998])."
  },
  {
    "objectID": "posts/Lab-2/index.html#marginal-effects",
    "href": "posts/Lab-2/index.html#marginal-effects",
    "title": "Lab 2: Logistic Regression",
    "section": "Marginal effects",
    "text": "Marginal effects\n\nLet‚Äôs examine the results on the probability scale.\n\n\nCalculate the marginal effects of sex, age, and SES on mass transportation spending. You can use the margins package function margins discussed in your textbook or you can use the marginaleffects package avg_slope avg_comparisons discussed in lecture. Interpret each estimate.\n\n\navg_comparisons(m1, comparison = \"difference\") %&gt;% \n  DT::datatable()\n\n\n\n\n\n\nThe marginal effect of age is -0.0015 (95% CI [-0.0026, -0.0004]). So, for each additional unit increase of age, the probability of being satisfied with mass transportation spending decreases by approximately 0.15 percentage points, holding other factors constant (p = 0.0066).\nThe marginal effect of SES is -0.0015 (95% CI [-0.0023, -0.0007]). For each one-unit increase in the socioeconomic index, the probability of being satisfied with mass transportation spending decreases by approximately 0.15 percentage points, holding other variables constant.\nThe marginal effect for being female compared to male is 0.0631 (95% CI [0.0263, 0.1000]). This indicates that females are, on average, about 6.31 percentage points more likely than males to be satisfied with mass transportation spending, holding other factors constant."
  },
  {
    "objectID": "posts/Lab-2/index.html#model-comparison",
    "href": "posts/Lab-2/index.html#model-comparison",
    "title": "Lab 2: Logistic Regression",
    "section": "Model comparison",
    "text": "Model comparison\n\nNow let‚Äôs see whether a person‚Äôs political views has a significant impact on their odds of being satisfied with spending on mass transportation, after accounting for the demographic factors.\n\n\nConduct a drop-in-deviance/likelihood ratio test to determine if polviews is a significant predictor of attitude towards spending on mass transportation. Name these two models fit2 and fit3, respectively. Compare the two models.\n\n\nfit2 &lt;- glm(mass_trans_spend_right ~age + sex + sei10, data = data, family = binomial(link = \"logit\"))\nfit3 &lt;- glm(mass_trans_spend_right ~ polviews + age + sex + sei10, data = data, family = binomial(link = \"logit\"))\n\ntest_likelihoodratio(fit2, fit3) %&gt;% kable()\n\n\n\n\n\nName\nModel\ndf\ndf_diff\nChi2\np\n\n\n\n\nfit2\nfit2\nglm\n4\nNA\nNA\nNA\n\n\nfit3\nfit3\nglm\n10\n6\n63.02844\n0\n\n\n\n\n\n\nIs the model with polviews better than the model without?\n\n\nYes. The model with polviews is significantly better than the model without it, as indicated by the likelihood ratio test (p &lt; 0.001)."
  },
  {
    "objectID": "posts/Lab-2/index.html#visualization",
    "href": "posts/Lab-2/index.html#visualization",
    "title": "Lab 2: Logistic Regression",
    "section": "Visualization",
    "text": "Visualization\n\nLet‚Äôs plot the results\nWe next use the model to produce visualizations:\n\nGiven the code below, interpet what is being plotted:\n\npol_plot : people that are extremely conservative are more likely to support mass transit spending\nsex_plot : women are more likely to support mass transit spending than men\nses_plot: people of lower ses are more likely to support mass transit spending\n\n\n\n\n\n\n\n\nTip\n\n\n\n\nadjust the various settings in your plot to make it look professional.\nYou can use ggeffects to get the predicted probabilities for these models.\n\n\n\n\n\nlibrary(ggeffects)\n\n\n# Load the gridExtra package for arranging plots\nlibrary(gridExtra)\n\n# Plot for political views\npp_pol &lt;- ggemmeans(fit3, terms = c(\"polviews\"))\npol_plot &lt;- ggplot(pp_pol, aes(x = x, y = predicted, color = x)) +\n  geom_point(size = 2) +\n  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.2) +\n  scale_color_manual(values = palette) +\n  labs(title = \"Effect of Political Views on Satisfaction with Mass Transportation\",\n       x = \"Political Views\", y = \"Predicted Probability\",\n       color = \"Political Views\") +\n  plot_aes\n\n# Plot for sex\npp_sex &lt;- ggemmeans(fit3, terms = c(\"sex\"))\nsex_plot &lt;- ggplot(pp_sex, aes(x = x, y = predicted, color = x)) +\n  geom_point(size = 2) +\n  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.2) +\n  labs(title = \"Effect of Sex on Satisfaction with Mass Transportation\",\n       x = \"Sex\", y = \"Predicted Probability\",\n       color = \"Sex\") +\n  plot_aes\n\n# Plot for socioeconomic status\npp_ses &lt;- ggemmeans(fit3, terms = \"sei10\")\nses_plot &lt;- ggplot(pp_ses, aes(x = x, y = predicted)) +\n  geom_line(color = \"red4\", size = 1) + \n  geom_ribbon(aes(ymin = conf.low, ymax = conf.high), fill = \"red4\", alpha = 0.2) +\n  labs(title = \"Effect of SES on Satisfaction with Mass Transportation\",\n       x = \"Socioeconomic Status\", y = \"Predicted Probability\") +\n  plot_aes + theme(legend.position = \"none\")\n\n# Arrange the plots using grid.arrange\ngrid.arrange(pol_plot, sex_plot, ses_plot, ncol = 1)"
  },
  {
    "objectID": "posts/Lab-2/index.html#model-assumptions",
    "href": "posts/Lab-2/index.html#model-assumptions",
    "title": "Lab 2: Logistic Regression",
    "section": "Model Assumptions",
    "text": "Model Assumptions\n\nIs the logistic model a good choice for this data?\n\n\nbinned_residuals(fit2)\n\nWarning: About 86% of the residuals are inside the error bounds (~95% or higher would be good).\n\n\n\n\n\n\n\n\nNote\n\n\n\nAnswer: No, because only 86% of the residuals are inside the error bounds (~95% or higher would be good)."
  },
  {
    "objectID": "posts/Lab-2/index.html#model-fit",
    "href": "posts/Lab-2/index.html#model-fit",
    "title": "Lab 2: Logistic Regression",
    "section": "Model fit",
    "text": "Model fit\n\nCalculate the \\(R^2\\) for this model\n\n\nr2_mcfadden(fit2)\n\n# R2 for Generalized Linear Regression\n       R2: 0.010\n  adj. R2: 0.009\n\n\n\nR2 interpretation: The model accounts for 0.01% of the variance in the outcome variable, which is very low.\nNext, Take a look at the binned residual plots for each continuous predictor variable and look at linearity. Is there a predictor that sticks out? What can we do to improve model fit in this case?\n\n\nbinned_residuals(fit2, term=\"sei10\")\n\nWarning: About 88% of the residuals are inside the error bounds (~95% or higher would be good).\n\nbinned_residuals(fit2, term=\"age\")\n\nOk: About 98% of the residuals are inside the error bounds.\n\nbinned_residuals(fit2, term=\"sei10\") %&gt;% plot(show_dots=TRUE)\n\n\n\n\n\n\n\nbinned_residuals(fit2, term=\"age\") %&gt;% plot(show_dots=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nYes, there are a few predictors that stick out. The residuals for the socioeconomic index (sei10) are not evenly distributed across the bins, indicating a non-linear relationship. To improve model fit, we could consider transforming the variable or using a different model that can capture non-linear relationships."
  },
  {
    "objectID": "posts/Lab-2/index.html#testing-polviews",
    "href": "posts/Lab-2/index.html#testing-polviews",
    "title": "Lab 2: Logistic Regression",
    "section": "Testing Polviews",
    "text": "Testing Polviews\n\nemmeans(fit3, \"polviews\") %&gt;% pairs() %&gt;% as.data.frame() %&gt;% filter(p.value &lt; .05)\n\n contrast                                   estimate        SE  df z.ratio\n Extremely liberal - Moderate             -0.9266262 0.1950664 Inf  -4.750\n Extremely liberal - Slghtly conservative -0.8487137 0.2127293 Inf  -3.990\n Extremely liberal - Conservative         -0.9935486 0.2108369 Inf  -4.712\n Extremely liberal - Extrmly conservative -1.3402621 0.2792876 Inf  -4.799\n Liberal - Moderate                       -0.7090022 0.1308520 Inf  -5.418\n Liberal - Slghtly conservative           -0.6310897 0.1555805 Inf  -4.056\n Liberal - Conservative                   -0.7759246 0.1532081 Inf  -5.065\n Liberal - Extrmly conservative           -1.1226380 0.2392048 Inf  -4.693\n Slightly liberal - Extrmly conservative  -0.7334002 0.2412625 Inf  -3.040\n p.value\n  &lt;.0001\n  0.0013\n  0.0001\n  &lt;.0001\n  &lt;.0001\n  0.0010\n  &lt;.0001\n  0.0001\n  0.0382\n\nResults are averaged over the levels of: sex \nResults are given on the log odds ratio (not the response) scale. \nP value adjustment: tukey method for comparing a family of 7 estimates \n\nemmeans(fit3, \"polviews\", type=\"response\") %&gt;% pairs() %&gt;% as.data.frame() %&gt;% filter(p.value &lt; .05)\n\n contrast                                 odds.ratio         SE  df null\n Extremely liberal / Moderate              0.3958871 0.07722426 Inf    1\n Extremely liberal / Slghtly conservative  0.4279651 0.09104070 Inf    1\n Extremely liberal / Conservative          0.3702605 0.07806458 Inf    1\n Extremely liberal / Extrmly conservative  0.2617771 0.07311109 Inf    1\n Liberal / Moderate                        0.4921350 0.06439684 Inf    1\n Liberal / Slghtly conservative            0.5320118 0.08277063 Inf    1\n Liberal / Conservative                    0.4602780 0.07051835 Inf    1\n Liberal / Extrmly conservative            0.3254202 0.07784206 Inf    1\n Slightly liberal / Extrmly conservative   0.4802732 0.11587191 Inf    1\n z.ratio p.value\n  -4.750  &lt;.0001\n  -3.990  0.0013\n  -4.712  0.0001\n  -4.799  &lt;.0001\n  -5.418  &lt;.0001\n  -4.056  0.0010\n  -5.065  &lt;.0001\n  -4.693  0.0001\n  -3.040  0.0382\n\nResults are averaged over the levels of: sex \nP value adjustment: tukey method for comparing a family of 7 estimates \nTests are performed on the log odds ratio scale \n\n\n\nConservatives are 0.37 times more likely to support mass transit spending compared to extremely liberals and 0.46 times more likely to support mass transit than liberals.\n\nExtreme liberals are 2.70 times more likely to support spending compared to conservatives, 2.53 times compared to moderates, and 2.34 times compared to slightly conservatives.\n\nExtremely conservatives are 3.82 times less likely to support mass spending than liberals and 2.08 times less likely than slightly liberals.\n\nLiberals are 2.03 times more likely to support spending than moderates and 1.88 times more likely than slightly conservatives.\n\n\nHow These Numbers Were Derived The reported odds ratios in the original output describe how much less likely a group is to support spending compared to another group. To express how much more likely one group is compared to another, we compute the inverse of the odds ratio:\n\n[ = ]"
  },
  {
    "objectID": "posts/Lab-2/index.html#conclusion",
    "href": "posts/Lab-2/index.html#conclusion",
    "title": "Lab 2: Logistic Regression",
    "section": "Conclusion",
    "text": "Conclusion\nPolitical views have the strongest effect on the dependent variable, given the largest deviance reduction. Age and sex also have a significant impact, with similar deviance reductions. Socioeconomic status (sei10) matters but has a smaller effect compared to other predictors.\n\n\nTable 1\n\n\n\n\n\nFigure 1: Effect of Sex on Satisfaction with Mass Transportation\n\n\n\n\n\n\n\n\n\nFigure 2: Effect of SES on Satisfaction with Mass Transportation\n\n\n\n\n\n\n\n\n\nFigure 3: Effect of Political Views on Satisfaction with Mass Transportation"
  },
  {
    "objectID": "posts/Lab-4/Lab4_multinom_Questions-1.html",
    "href": "posts/Lab-4/Lab4_multinom_Questions-1.html",
    "title": "Lab 4: Multinomial Regression",
    "section": "",
    "text": "Lab Goal: Predict voting frequency using demographic variables Data source: FiveThirtyEight ‚ÄúWhy Many Americans Don‚Äôt Vote‚Äù survey Method: Multinomial logistic regression"
  },
  {
    "objectID": "posts/Lab-4/Lab4_multinom_Questions-1.html#data",
    "href": "posts/Lab-4/Lab4_multinom_Questions-1.html#data",
    "title": "Lab 4: Multinomial Regression",
    "section": "Data",
    "text": "Data\nThe data for this assignment comes from an online Ipsos survey that was conducted for the FiveThirtyEight article ‚ÄúWhy Many Americans Don‚Äôt Vote‚Äù. You can read more about the survey design and respondents in the README of the GitHub repo for the data.\nRespondents were asked a variety of questions about their political beliefs, thoughts on multiple issues, and voting behavior. We will focus on using the demographic variables and someone‚Äôs party identification to understand whether a person is a probable voter.\nThe variables we‚Äôll focus on were (definitions from the codebook in data set GitHub repo):\n\nppage: Age of respondent\neduc: Highest educational attainment category.\n\nrace: Race of respondent, census categories. Note: all categories except Hispanic were non-Hispanic.\ngender: Gender of respondent\nincome_cat: Household income category of respondent\nQ30: Response to the question ‚ÄúGenerally speaking, do you think of yourself as a‚Ä¶‚Äù\n\n1: Republican\n2: Democrat\n3: Independent\n4: Another party, please specify\n5: No preference\n-1: No response\n\nvoter_category: past voting behavior:\n\nalways: respondent voted in all or all-but-one of the elections they were eligible in\nsporadic: respondent voted in at least two, but fewer than all-but-one of the elections they were eligible in\nrarely/never: respondent voted in 0 or 1 of the elections they were eligible in\n\n\nYou can read in the data directly from the GitHub repo:\n\nlibrary(pacman)\npacman::p_load(nnet,car,tidyverse,emmeans,ggeffects,knitr,patchwork,broom,parameters,easystats,install = T)\n\npalette &lt;- c(\n  \"#772e25\", \"#c44536\", \"#ee9b00\", \"#197278\", \"#283d3b\", \n  \"#9CC5A1\", \"#6195C6\", \"#ADA7C9\", \"#4D4861\", \"grey50\",\n  \"#d4a373\", \"#8a5a44\", \"#4a6a74\", \"#5c80a8\", \"#a9c5a0\",\n  \"#7b9b8e\", \"#e1b16a\", \"#a69b7c\", \"#9d94c4\", \"#665c54\"\n)\n\npalette_condition = c(\"#ee9b00\", \"#c44536\",\"#005f73\", \"#283d3b\", \"#9CC5A1\", \"#6195C6\", \"#ADA7C9\", \"#4D4861\")\nplot_aes = theme_minimal() +\n  theme(\n    legend.position = \"top\",\n    legend.text = element_text(size = 12),\n    text = element_text(size = 16, family = \"Futura Medium\"),\n    axis.text = element_text(color = \"black\"),\n    axis.ticks.y = element_blank(),\n    plot.title = element_text(size = 20, hjust = 0.5) # Adjusted title size and centering\n  )\n\n\nvoter_data &lt;- read_csv(\"https://raw.githubusercontent.com/fivethirtyeight/data/master/non-voters/nonvoters_data.csv\")\n\nvoter_data |&gt; \n  head() |&gt; \n  DT::datatable()"
  },
  {
    "objectID": "posts/Lab-4/Lab4_multinom_Questions-1.html#lrt",
    "href": "posts/Lab-4/Lab4_multinom_Questions-1.html#lrt",
    "title": "Lab 4: Multinomial Regression",
    "section": "LRT",
    "text": "LRT\n\nRun the full model and report overall significance of each of the terms\n\n\nvoter_model_expanded |&gt; \n  tidy(conf.int = TRUE )|&gt; \n  mutate(across(where(is.numeric), round, 3)) |&gt; \nDT::datatable(options = list(pageLength = 10, scrollX = TRUE))"
  },
  {
    "objectID": "posts/Lab-4/Lab4_multinom_Questions-1.html#marginal-effects-political-group---emmeans",
    "href": "posts/Lab-4/Lab4_multinom_Questions-1.html#marginal-effects-political-group---emmeans",
    "title": "Lab 4: Multinomial Regression",
    "section": "Marginal Effects Political Group - Emmeans",
    "text": "Marginal Effects Political Group - Emmeans\n\n#Get estimated marginal means from the model\n\n#using \nmultinomial_id&lt;- emmeans(voter_model_expanded, ~ pol_ident_new|voter_category)\n\n\ncoefs = contrast(regrid(multinomial_id, \"log\"),\"trt.vs.ctrl1\",  by=\"pol_ident_new\")\n# you can add a parameter to the above command, ref = newbaseline, if you want to change baseline\n\nupdate(coefs, by = \"contrast\")  \n\ncontrast = sporadic - (rarely/never):\n pol_ident_new estimate     SE df t.ratio p.value\n Dem             0.9613 0.0701 28  13.722  &lt;.0001\n Indep           0.5909 0.0773 28   7.643  &lt;.0001\n Other           0.0782 0.0868 28   0.902  0.7475\n Rep             0.8832 0.0844 28  10.469  &lt;.0001\n\ncontrast = always - (rarely/never):\n pol_ident_new estimate     SE df t.ratio p.value\n Dem             0.4797 0.0738 28   6.498  &lt;.0001\n Indep          -0.0494 0.0838 28  -0.590  0.8999\n Other          -0.8353 0.1100 28  -7.577  &lt;.0001\n Rep             0.3269 0.0890 28   3.672  0.0037\n\nResults are averaged over the levels of: race, gender, income_cat, educ \nResults are given on the log (not the response) scale. \nP value adjustment: dunnettx method for 4 tests"
  },
  {
    "objectID": "posts/Lab-4/Lab4_multinom_Questions-1.html#marginal-effects-of-education---emmeans",
    "href": "posts/Lab-4/Lab4_multinom_Questions-1.html#marginal-effects-of-education---emmeans",
    "title": "Lab 4: Multinomial Regression",
    "section": "Marginal Effects of Education - Emmeans",
    "text": "Marginal Effects of Education - Emmeans\n\n#Enter code\nmultinomial_edu &lt;- emmeans(voter_model_expanded, ~ educ|voter_category)\n\n\ncoefs = contrast(regrid(multinomial_edu, \"log\"),\"trt.vs.ctrl1\",  by=\"educ\")\n# you can add a parameter to the above command, ref = newbaseline, if you want to change baseline\n\nupdate(coefs, by = \"contrast\") \n\ncontrast = sporadic - (rarely/never):\n educ                estimate     SE df t.ratio p.value\n College                0.986 0.0764 28  12.904  &lt;.0001\n High school or less    0.187 0.0691 28   2.705  0.0313\n Some college           0.707 0.0744 28   9.512  &lt;.0001\n\ncontrast = always - (rarely/never):\n educ                estimate     SE df t.ratio p.value\n College                0.477 0.0800 28   5.960  &lt;.0001\n High school or less   -0.711 0.0800 28  -8.883  &lt;.0001\n Some college           0.167 0.0791 28   2.114  0.1117\n\nResults are averaged over the levels of: race, gender, income_cat, pol_ident_new \nResults are given on the log (not the response) scale. \nP value adjustment: dunnettx method for 3 tests \n\n\n\nNext, plot the predicted probabilities of voter category as a function of Age and Party ID\n\n\npredictions &lt;- ggemmeans(voter_model_expanded, terms = c(\"age_centered\", \"pol_ident_new\"))\n\n# Create the plot with facets for each party ID category.\nggplot(predictions, aes(x = x, y = predicted, fill = response.level)) +\n  geom_area() +\n  geom_rug(sides = \"b\", position = \"jitter\", alpha = 0.5) +\n  labs(\n    x = \"\\nAge\",\n    y = \"Predicted Probability\\n\",\n    title = \"Predicted Probabilities of Voting Frequency by Age and Party ID\"\n  ) +\n  facet_wrap(~ group, labeller = label_both) +  # Facet by Party ID\n  scale_fill_manual(\n    name = NULL,\n    values = c(\"always\" = \"#F6B533\", \"sporadic\" = \"#D07EA2\", \"rarely/never\" = \"#9854F7\"),\n    labels = c(\"RARELY OR NEVER VOTE\", \"SOMETIMES VOTE\", \"ALMOST ALWAYS VOTE\"),\n    breaks = c(\"rarely/never\", \"sporadic\", \"always\")\n  ) +\n  plot_aes\n\n\n\n\n\n\n\n\nPlot predicted probabilities as a function of education and voting frequency.\n\npredictions &lt;- ggemmeans(voter_model_expanded, terms = c(\"educ\"))\n\n# Create the plot with facets for each party ID category.\nggplot(predictions, aes(x = x, y = predicted, fill = response.level)) +\n  geom_bar(stat = \"identity\", position = \"dodge\", alpha = 0.7) +  # Use stat = \"identity\" for bar heights\n  labs(\n    x = \"\\nEducation\",\n    y = \"Predicted Probability\\n\",\n    title = \"Predicted Probabilities of Voting Frequency by Age and Party ID\"\n  ) +\n  facet_wrap(~ group, labeller = label_both) +  # Facet by Party ID\n  scale_fill_manual(\n    name = NULL,\n    values = c(\"always\" = \"#F6B533\", \"sporadic\" = \"#D07EA2\", \"rarely/never\" = \"#9854F7\"),\n    labels = c(\"RARELY OR NEVER VOTE\", \"SOMETIMES VOTE\", \"ALMOST ALWAYS VOTE\"),\n    breaks = c(\"rarely/never\", \"sporadic\", \"always\")\n  ) +\n  plot_aes"
  },
  {
    "objectID": "posts/Lab-4/Lab4_multinom_Questions-1.html#write-up",
    "href": "posts/Lab-4/Lab4_multinom_Questions-1.html#write-up",
    "title": "Lab 4: Multinomial Regression",
    "section": "Write-up",
    "text": "Write-up\n\nAge: The older people get the less likely they are to note vote, regardless of political idenitiy. However, younger, Independents are the least likely to vote the Education: People with a college education are more likely to sometimes and always vote that than counterpart, and less likely to never vote. On the other hand, people with a high school education or less are more likely to not engage in voting than their counterparts\n\n\nDifferences between political groups and voting behavior - Emmeans\n\nmulti_an &lt;- emmeans(voter_model_expanded, ~  pol_ident_new|voter_category)\n\ncoefs = contrast(regrid(multi_an, \"log\"),\"trt.vs.ctrl1\",  by=\"pol_ident_new\")\n\nupdate(coefs, by = \"contrast\") %&gt;% \n  kable(format = \"markdown\", digits = 3)\n\n\n\n\n\n\n\n\n\n\n\n\n\ncontrast\npol_ident_new\nestimate\nSE\ndf\nt.ratio\np.value\n\n\n\n\nsporadic - (rarely/never)\nDem\n0.961\n0.070\n28\n13.722\n0.000\n\n\nalways - (rarely/never)\nDem\n0.480\n0.074\n28\n6.498\n0.000\n\n\nsporadic - (rarely/never)\nIndep\n0.591\n0.077\n28\n7.643\n0.000\n\n\nalways - (rarely/never)\nIndep\n-0.049\n0.084\n28\n-0.590\n0.900\n\n\nsporadic - (rarely/never)\nOther\n0.078\n0.087\n28\n0.902\n0.747\n\n\nalways - (rarely/never)\nOther\n-0.835\n0.110\n28\n-7.577\n0.000\n\n\nsporadic - (rarely/never)\nRep\n0.883\n0.084\n28\n10.469\n0.000\n\n\nalways - (rarely/never)\nRep\n0.327\n0.089\n28\n3.672\n0.004\n\n\n\n\n# get difference between yes-no and fair-excellent\ncontrast(coefs, \"revpairwise\", by = \"contrast\") %&gt;%\n  kable(format = \"markdown\", digits = 3)\n\n\n\n\n\n\n\n\n\n\n\n\n\ncontrast1\ncontrast\nestimate\nSE\ndf\nt.ratio\np.value\n\n\n\n\nIndep - Dem\nsporadic - (rarely/never)\n-0.370\n0.094\n28\n-3.933\n0.003\n\n\nOther - Dem\nsporadic - (rarely/never)\n-0.883\n0.103\n28\n-8.578\n0.000\n\n\nOther - Indep\nsporadic - (rarely/never)\n-0.513\n0.107\n28\n-4.807\n0.000\n\n\nRep - Dem\nsporadic - (rarely/never)\n-0.078\n0.099\n28\n-0.787\n0.860\n\n\nRep - Indep\nsporadic - (rarely/never)\n0.292\n0.099\n28\n2.965\n0.029\n\n\nRep - Other\nsporadic - (rarely/never)\n0.805\n0.109\n28\n7.404\n0.000\n\n\nIndep - Dem\nalways - (rarely/never)\n-0.529\n0.101\n28\n-5.255\n0.000\n\n\nOther - Dem\nalways - (rarely/never)\n-1.315\n0.125\n28\n-10.508\n0.000\n\n\nOther - Indep\nalways - (rarely/never)\n-0.786\n0.129\n28\n-6.072\n0.000\n\n\nRep - Dem\nalways - (rarely/never)\n-0.153\n0.104\n28\n-1.470\n0.468\n\n\nRep - Indep\nalways - (rarely/never)\n0.376\n0.104\n28\n3.605\n0.006\n\n\nRep - Other\nalways - (rarely/never)\n1.162\n0.130\n28\n8.969\n0.000\n\n\n\n\n\n\n\nDifferences between education level and voting behavior - Emmeans\nLast part of the assignment: Interpret the results from running the following code for your model\n\nmulti_an &lt;- emmeans(voter_model_expanded, ~ educ|voter_category)\n\ncoefs = contrast(regrid(multi_an, \"log\"),\"trt.vs.ctrl1\",  by=\"educ\")\n\nupdate(coefs, by = \"contrast\") %&gt;% \n  kable(format = \"markdown\", digits = 3)\n\n\n\n\n\n\n\n\n\n\n\n\n\ncontrast\neduc\nestimate\nSE\ndf\nt.ratio\np.value\n\n\n\n\nsporadic - (rarely/never)\nCollege\n0.986\n0.076\n28\n12.904\n0.000\n\n\nalways - (rarely/never)\nCollege\n0.477\n0.080\n28\n5.960\n0.000\n\n\nsporadic - (rarely/never)\nHigh school or less\n0.187\n0.069\n28\n2.705\n0.031\n\n\nalways - (rarely/never)\nHigh school or less\n-0.711\n0.080\n28\n-8.883\n0.000\n\n\nsporadic - (rarely/never)\nSome college\n0.707\n0.074\n28\n9.512\n0.000\n\n\nalways - (rarely/never)\nSome college\n0.167\n0.079\n28\n2.114\n0.112\n\n\n\n\n# get difference between yes-no and fair-excellent\ncontrast(coefs, \"revpairwise\", by = \"contrast\") %&gt;%\n  kable(format = \"markdown\", digits = 3)\n\n\n\n\n\n\n\n\n\n\n\n\n\ncontrast1\ncontrast\nestimate\nSE\ndf\nt.ratio\np.value\n\n\n\n\nHigh school or less - College\nsporadic - (rarely/never)\n-0.799\n0.095\n28\n-8.416\n0.000\n\n\nSome college - College\nsporadic - (rarely/never)\n-0.278\n0.092\n28\n-3.030\n0.014\n\n\nSome college - High school or less\nsporadic - (rarely/never)\n0.520\n0.088\n28\n5.920\n0.000\n\n\nHigh school or less - College\nalways - (rarely/never)\n-1.188\n0.104\n28\n-11.394\n0.000\n\n\nSome college - College\nalways - (rarely/never)\n-0.310\n0.097\n28\n-3.207\n0.009\n\n\nSome college - High school or less\nalways - (rarely/never)\n0.878\n0.098\n28\n8.995\n0.000\n\n\n\n\n\nEnter your interpretation here: &gt; The contrast analysis reveals significant differences in voting frequency based on educational attainment. Individuals with a high school education or less are less likely to vote sporadically or always compared to those with a college education. Those with some college education show mixed results; they are less likely to vote always compared to college graduates but more likely to vote sporadically than those with a high school education or less. Overall, these findings highlight the significant impact of education on voting behavior, indicating that higher educational attainment is associated with increased likelihood of electoral participation."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Stats-blog (PSY-504)",
    "section": "",
    "text": "Lab-8: Bayes\n\n\nPrinceton University\n\n\n\nLab\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\nSteven Mesquiti\n\n\n\n\n\n\n\n\n\n\n\n\nIntro to MLM Exercise/Walkthrough\n\n\nPrinceton University\n\n\n\nLab\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\nSteven Mesquiti\n\n\n\n\n\n\n\n\n\n\n\n\nLab-7\n\n\nPrinceton University\n\n\n\nLab\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\nSteven Mesquiti\n\n\n\n\n\n\n\n\n\n\n\n\nLab 9\n\n\nPrinceton University\n\n\n\nLab\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\nSteven Mesquiti\n\n\n\n\n\n\n\n\n\n\n\n\nFinal Project\n\n\nPrinceton University\n\n\n\nFinal-Project\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\nSteven Mesquiti\n\n\n\n\n\n\n\n\n\n\n\n\nLab 2: Logistic Regression\n\n\nPrinceton University\n\n\n\nLab\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\nSteven Mesquiti\n\n\n\n\n\n\n\n\n\n\n\n\nPoisson Lab Answers\n\n\nPrinceton University\n\n\n\n\n\n\n\n\nSteven Mesquiti\n\n\n\n\n\n\n\n\n\n\n\n\nLab 4: Multinomial Regression\n\n\nPrinceton University\n\n\n\nLab\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\nSteven Mesquiti\n\n\n\n\n\n\n\n\n\n\n\n\nOrdinal Regression Lab Answers\n\n\nPrinceton University\n\n\n\nLab\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\nSteven Mesquiti\n\n\n\n\n\n\nNo matching items"
  }
]